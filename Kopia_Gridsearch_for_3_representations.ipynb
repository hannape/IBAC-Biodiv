{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kopia Gridsearch for 3 representations. ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hannape/IBAC-Biodiv/blob/master/Kopia_Gridsearch_for_3_representations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mq81jmxhMYV",
        "colab_type": "text"
      },
      "source": [
        "Gridsearch dla każdej reprezentacji osobno. Bo na IBACu wszystkie 3 reprezentacje były puszczone na architekturę z mel-spectrogramu (chyba?)\n",
        "\n",
        "Na podstawie hania.dldisc: cnn_gridsearch.ipynb , 03 CNN fit and predict (I2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65s8txmrhL7Y",
        "colab_type": "code",
        "outputId": "bc5b394b-ca30-4300-9802-d950ab7625b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from __future__ import print_function"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CddWh85JjLPZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import keras\n",
        "import numpy\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras import backend as K\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "import numpy\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from matplotlib import pyplot\n",
        "#K.set_image_dim_ordering('th')\n",
        "K.tensorflow_backend.set_image_dim_ordering('th')\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from keras.datasets import mnist\n",
        "import glob\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from functools import partial, update_wrapper\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAjy6F71jTVn",
        "colab_type": "code",
        "outputId": "2baf9d86-ba24-486e-f86d-19f978dddc7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(667)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(667)\n",
        "import random\n",
        "random.seed()\n",
        "\n",
        "'''\n",
        "#################### Rep 1 - spektro ####################\n",
        "# rep 1  ------- 63 x 148 ------ TRAIN 17.3k\n",
        "X_train1 = numpy.load('drive/My Drive/rep IBAC/rep1/X_train_rep1.npy', allow_pickle=True) # 1 and 0 in order\n",
        "y_train1 = numpy.load('drive/My Drive/rep IBAC/rep1/y_train.npy', allow_pickle=True)\n",
        "'''\n",
        "# rep 1V2 ------- 63 x 148 ------ TRAIN 15.9\n",
        "X_train1 = numpy.load('drive/My Drive/rep IBAC/rep1V2/X_train_rep1.npy', allow_pickle=True) # 1 and 0 in order\n",
        "y_train1 = numpy.load('drive/My Drive/rep IBAC/rep1V2/y_train_rep1.npy', allow_pickle=True)\n",
        "'''\n",
        "# rep 1b ------- 63 x 63 ------\n",
        "X_train1 = numpy.load('drive/My Drive/rep IBAC/rep1b/X_train_rep1b.npy', allow_pickle=True) # 1 and 0 in order\n",
        "y_train1 = numpy.load('drive/My Drive/rep IBAC/rep1b/y_train_rep1b.npy', allow_pickle=True)\n",
        "\n",
        "#################### Rep 3 - mel-spektro ####################\n",
        "\n",
        "# rep 3 ------- 60 x 111 ------ TRAIN 17.3k\n",
        "X_train1 = numpy.load('drive/My Drive/rep IBAC/rep3/X_train_rep3.npy', allow_pickle=True) # 1 and 0 in order\n",
        "y_train1 = numpy.load('drive/My Drive/rep IBAC/rep3/y_train.npy', allow_pickle=True)\n",
        "\n",
        "# rep 3V2 ------- 60 x 111 ------ TRAIN 15.9\n",
        "X_train1 = numpy.load('drive/My Drive/rep IBAC/rep3V2/X_train_rep3.npy', allow_pickle=True) # 1 and 0 in order\n",
        "y_train1 = numpy.load('drive/My Drive/rep IBAC/rep3V2/y_train_rep3.npy', allow_pickle=True)\n",
        "\n",
        "# rep 3b ------- 60 x 63 ------\n",
        "X_train1 = numpy.load('drive/My Drive/rep IBAC/rep3b/X_train_rep3b.npy', allow_pickle=True) # 1 and 0 in order\n",
        "y_train1 = numpy.load('drive/My Drive/rep IBAC/rep3b/y_train_rep3b.npy', allow_pickle=True)\n",
        "\n",
        "# rep 3V3 ------- 60 x 148 ------\n",
        "X_train1 = numpy.load('drive/My Drive/rep IBAC/rep3V3/X_train_rep3V3.npy', allow_pickle=True) # 1 and 0 in order\n",
        "y_train1 = numpy.load('drive/My Drive/rep IBAC/rep3V3/y_train_rep3V3.npy', allow_pickle=True)\n",
        "\n",
        "#################### Rep 5 - mel-spektro ####################\n",
        "\n",
        "# rep 5 ------- 64 x 61 ------ TRAIN 17.3k\n",
        "X_train1 = numpy.load('drive/My Drive/rep IBAC/rep5/X_train_rep5.npy', allow_pickle=True) # 1 and 0 in order\n",
        "y_train1 = numpy.load('drive/My Drive/rep IBAC/rep5/y_train.npy', allow_pickle=True)\n",
        "\n",
        "# rep 5V2 ------- 64 x 61 ------ TRAIN 15.9\n",
        "X_train1 = numpy.load('drive/My Drive/rep IBAC/rep5V2/X_train_rep5.npy', allow_pickle=True) # 1 and 0 in order\n",
        "y_train1 = numpy.load('drive/My Drive/rep IBAC/rep5V2/y_train_rep5.npy', allow_pickle=True)\n",
        "\n",
        "# rep 5b ------- 64 x 149 ------\n",
        "X_train1 = numpy.load('drive/My Drive/rep IBAC/rep5b/X_train_rep5b.npy', allow_pickle=True) # 1 and 0 in order\n",
        "y_train1 = numpy.load('drive/My Drive/rep IBAC/rep5b/y_train_rep5b.npy', allow_pickle=True)\n",
        "'''\n",
        "\n",
        "print('Training set size:')\n",
        "print(np.shape(X_train1))\n",
        "print(np.shape(y_train1))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set size:\n",
            "(15904, 63, 148)\n",
            "(15904,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ST0WDnQSxeLD",
        "colab_type": "code",
        "outputId": "f964a53a-4883-4650-e3ba-6513bb6d40e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "r = np.shape(X_train1)[1]\n",
        "s = np.shape(X_train1)[2]\n",
        "y_train = y_train1\n",
        "X_train = X_train1.reshape(X_train1.shape[0], 1, r, s).astype('float32')\n",
        "print('Training set size:')\n",
        "print(np.shape(X_train))\n",
        "print(np.shape(y_train))\n",
        "input_shape = (1, r, s)\n",
        "print(input_shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set size:\n",
            "(15904, 1, 63, 148)\n",
            "(15904,)\n",
            "(1, 63, 148)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j27RDs6YmWqD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://github.com/keras-team/keras/issues/2115\n",
        "\n",
        "### definiowanie wag \n",
        "for_zeros = 0.1\n",
        "for_ones = 0.9\n",
        "###\n",
        "\n",
        "### SCORERS\n",
        "\n",
        "#def binary_crossentropy_weigted(y_true, y_pred, class_weights):\n",
        "#\ty_pred = K.clip(y_pred, K.epsilon(), 1.0 - K.epsilon())\n",
        "#  \n",
        "#\tloss = K.mean(class_weights*(-y_true * K.log(y_pred) - (1.0 - y_true) * K.log(1.0 - y_pred)),axis=-1)\n",
        "#\treturn loss\n",
        "\n",
        "def weighted_binary_crossentropy( y_true, y_pred, weights_10) :\n",
        "    y_pred = K.clip(y_pred, K.epsilon(), 1.0 - K.epsilon())\n",
        "    logloss = -(y_true * K.log(y_pred) * weights_10[0] + (1 - y_true) * K.log(1 - y_pred) * weights_10[1])\n",
        "    return K.mean(logloss, axis=-1)\n",
        "\n",
        "#custom_loss1 = partial(binary_crossentropy_weigted, class_weights=np.array([for_zeros,for_ones])) ## scoring for model.compile\n",
        "#custom_loss1.__name__ ='binary_crossentropy_weigted'\n",
        "\n",
        "custom_loss2 = partial(weighted_binary_crossentropy, weights_10=np.array([for_ones,for_zeros])) ## scoring for model.compile\n",
        "custom_loss2.__name__ ='weighted_binary_crossentropy'\n",
        "\n",
        "## AUC METRIC\n",
        "def as_keras_metric(method):\n",
        "    import functools\n",
        "    from keras import backend as K\n",
        "    \n",
        "    @functools.wraps(method)\n",
        "    def wrapper(self, args, **kwargs):\n",
        "        \"\"\" Wrapper for turning tensorflow metrics into keras metrics \"\"\"\n",
        "        value, update_op = method(self, args, **kwargs)\n",
        "        K.get_session().run(tf.local_variables_initializer())\n",
        "        with tf.control_dependencies([update_op]):\n",
        "            value = tf.identity(value)\n",
        "        return value\n",
        "    return wrapper\n",
        "  \n",
        "auc_roc = as_keras_metric(tf.metrics.auc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Oq0VwYupNmM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def search_model(dense_layer_sizes, filters, kernel_size, pool_size, hidden_layers, loss_function):\n",
        "   \n",
        "    #hidden_layers = 1\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters, kernel_size,input_shape=input_shape, activation='relu', data_format='channels_first'))\n",
        "    model.add(MaxPooling2D(pool_size=pool_size))\n",
        "    #model.add(Conv2D(filters, kernel_size, activation='relu'))\n",
        "    #model.add(MaxPooling2D(pool_size=pool_size))\n",
        "    #model.add(Conv2D(filters, kernel_size, activation='relu'))\n",
        "    #model.add(MaxPooling2D(pool_size=pool_size))\n",
        "   \n",
        "    for i in range(0,hidden_layers):\n",
        "      # Add one hidden layer\n",
        "      print('Warstwa '+ str(i+1))\n",
        "      model.add(Conv2D(filters, kernel_size, activation='relu'))\n",
        "      model.add(MaxPooling2D(pool_size=pool_size))\n",
        "  \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(dense_layer_sizes, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss=loss_function,\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy',auc_roc])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NUxERPzqK4I",
        "colab_type": "code",
        "outputId": "4f374079-8b82-4a47-9687-b9def8914d6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "hidden_layers= 2\n",
        "for i in range(hidden_layers):\n",
        "  print(i)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5svLHOfqjgDp",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "\n",
        "  \n",
        "def make_model_modified(dense_layer_sizes, filters, kernel_size, pool_size):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters, kernel_size,input_shape=input_shape, activation='relu', data_format='channels_first')) # \"channels_first\" corresponds to inputs with shape (batch, channels, height, width)\n",
        "    model.add(MaxPooling2D(pool_size=pool_size))\n",
        "    model.add(Conv2D(filters, kernel_size, activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=pool_size))\n",
        "    model.add(Conv2D(filters, kernel_size, activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=pool_size))\n",
        "   \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(dense_layer_sizes, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "  \n",
        "def probny_model(dense_layer_sizes):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(10, (3,3),input_shape=input_shape, activation='relu', data_format='channels_first')) # \"channels_first\" corresponds to inputs with shape (batch, channels, height, width)\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "   \n",
        "    model.add(Dense(dense_layer_sizes, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model  \n",
        "  \n",
        "def make_model(dense_layer_sizes, filters, kernel_size, pool_size):\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters, kernel_size,\n",
        "                     padding='valid',\n",
        "                     input_shape=input_shape, data_format='channels_first'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(filters, kernel_size))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=pool_size))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    for layer_size in dense_layer_sizes:\n",
        "        model.add(Dense(layer_size))\n",
        "        model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1))#(num_classes))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', #'categorical_crossentropy',\n",
        "                  optimizer='adadelta',\n",
        "                  metrics=['accuracy'])\n",
        "    return model  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYsSf-Oucqxl",
        "colab_type": "code",
        "outputId": "d988406c-758c-4989-dfa4-fe8543228078",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "y=y_train.astype('int')\n",
        "print(np.shape(X_train))\n",
        "print(np.shape(y_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15904, 1, 63, 148)\n",
            "(15904,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRdAp3bGb7RJ",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "my_classifier3 = KerasClassifier(make_model)\n",
        "validator3 = GridSearchCV(my_classifier3,\n",
        "                         param_grid={'dense_layer_sizes': [128]}, \n",
        "                         scoring='neg_log_loss')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76411ZmN85od",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "dense_size_candidates = [[32], [64]] #, [32, 32], [64, 64]]\n",
        "my_classifier = KerasClassifier(make_model, batch_size=32)\n",
        "\n",
        "validator = GridSearchCV(my_classifier,\n",
        "                         param_grid={'dense_layer_sizes': [[32], [64]],\n",
        "                                     # epochs is avail for tuning even when not\n",
        "                                     # an argument to model building function\n",
        "                                     'epochs': [1],\n",
        "                                     'filters': [8],\n",
        "                                     'kernel_size': [3],\n",
        "                                     'pool_size': [2]},\n",
        "                         scoring='neg_log_loss',\n",
        "                         n_jobs=1)\n",
        "#y2=y_train.astype('int')\n",
        "validator.fit(X_train, y) #_binary)\n",
        "\n",
        "print('The parameters of the best model are: ')\n",
        "print(validator.best_params_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MadBqOqYbAo4",
        "colab_type": "code",
        "outputId": "e8b97ffd-e1cb-4259-f61a-d363722b0c35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "my_classifier66 = KerasClassifier(search_model)\n",
        "validator66 = GridSearchCV(my_classifier66,\n",
        "                         param_grid={'dense_layer_sizes': [128],\n",
        "                                     # epochs is avail for tuning even when not\n",
        "                                     # an argument to model building function\n",
        "                                     'epochs': [15], #[10, 30, 50],\n",
        "                                     'filters': [10,20], #[10, 20],\n",
        "                                     'kernel_size': [(3,3)], #[(3,3)],\n",
        "                                     'pool_size': [(2,2)],#[(2,2)],\n",
        "                                     'hidden_layers': [2,3],\n",
        "                                     'loss_function': ['binary_crossentropy', custom_loss2],\n",
        "                                     'batch_size': [32,64], #[32, 64]\n",
        "                                     }, \n",
        "                         #scoring='neg_log_loss',\n",
        "                         cv = StratifiedKFold(n_splits = 5, random_state=667, shuffle = True))\n",
        "#y=y_train.astype('int')\n",
        "'''\n",
        "validator66 = GridSearchCV(my_classifier66,\n",
        "                         param_grid={'dense_layer_sizes': [128, 256],\n",
        "                                     # epochs is avail for tuning even when not\n",
        "                                     # an argument to model building function\n",
        "                                     'epochs': [10,30], #[10, 30, 50],\n",
        "                                     'filters': [10,20], #[10, 20],\n",
        "                                     'kernel_size': [(3,3)], #[(3,3)],\n",
        "                                     'pool_size': [(2,2)],#[(2,2)],\n",
        "                                     'hidden_layers': [2,3],\n",
        "                                     'loss_function': ['binary_crossentropy', custom_loss2],\n",
        "                                     'batch_size': [32,64], #[32, 64]\n",
        "                                     }, \n",
        "                         scoring='neg_log_loss', cv = StratifiedKFold(n_splits =4, random_state=667, shuffle = True))\n",
        "'''\n",
        "grid_result = validator66.fit(X_train, y)\n",
        "print('The parameters of the best model are: ')\n",
        "print(validator66.best_params_)\n",
        "\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 11s 897us/step - loss: 0.6419 - acc: 0.6564 - auc: 0.5784\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 4s 305us/step - loss: 0.4475 - acc: 0.8033 - auc: 0.7470\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 4s 312us/step - loss: 0.3901 - acc: 0.8352 - auc: 0.8034\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 4s 316us/step - loss: 0.3576 - acc: 0.8553 - auc: 0.8321\n",
            "Epoch 5/15\n",
            "12723/12723 [==============================] - 4s 314us/step - loss: 0.3319 - acc: 0.8683 - auc: 0.8515\n",
            "Epoch 6/15\n",
            "12723/12723 [==============================] - 4s 316us/step - loss: 0.3177 - acc: 0.8735 - auc: 0.8658\n",
            "Epoch 7/15\n",
            "12723/12723 [==============================] - 4s 322us/step - loss: 0.2993 - acc: 0.8806 - auc: 0.8759\n",
            "Epoch 8/15\n",
            "12723/12723 [==============================] - 4s 325us/step - loss: 0.2849 - acc: 0.8885 - auc: 0.8845\n",
            "Epoch 9/15\n",
            "12723/12723 [==============================] - 4s 319us/step - loss: 0.2683 - acc: 0.8972 - auc: 0.8921\n",
            "Epoch 10/15\n",
            "12723/12723 [==============================] - 4s 313us/step - loss: 0.2603 - acc: 0.9007 - auc: 0.8984\n",
            "Epoch 11/15\n",
            "12723/12723 [==============================] - 4s 320us/step - loss: 0.2476 - acc: 0.9054 - auc: 0.9041\n",
            "Epoch 12/15\n",
            "12723/12723 [==============================] - 4s 318us/step - loss: 0.2329 - acc: 0.9134 - auc: 0.9093\n",
            "Epoch 13/15\n",
            "12723/12723 [==============================] - 4s 315us/step - loss: 0.2261 - acc: 0.9170 - auc: 0.9141\n",
            "Epoch 14/15\n",
            "12723/12723 [==============================] - 4s 312us/step - loss: 0.2161 - acc: 0.9205 - auc: 0.9183\n",
            "Epoch 15/15\n",
            "12723/12723 [==============================] - 4s 311us/step - loss: 0.2128 - acc: 0.9223 - auc: 0.9220\n",
            "3181/3181 [==============================] - 4s 1ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 11s 900us/step - loss: 0.7316 - acc: 0.5573 - auc: 0.5127\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 4s 313us/step - loss: 0.6726 - acc: 0.5880 - auc: 0.5155\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 4s 312us/step - loss: 0.5607 - acc: 0.7168 - auc: 0.5832\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 4s 313us/step - loss: 0.4825 - acc: 0.7787 - auc: 0.6614\n",
            "Epoch 5/15\n",
            "12723/12723 [==============================] - 4s 328us/step - loss: 0.4453 - acc: 0.8037 - auc: 0.7121\n",
            "Epoch 6/15\n",
            "12723/12723 [==============================] - 4s 314us/step - loss: 0.4045 - acc: 0.8297 - auc: 0.7482\n",
            "Epoch 7/15\n",
            "12723/12723 [==============================] - 4s 317us/step - loss: 0.3977 - acc: 0.8330 - auc: 0.7738\n",
            "Epoch 8/15\n",
            "12723/12723 [==============================] - 4s 308us/step - loss: 0.3462 - acc: 0.8638 - auc: 0.7944\n",
            "Epoch 9/15\n",
            "12723/12723 [==============================] - 4s 309us/step - loss: 0.3310 - acc: 0.8709 - auc: 0.8127\n",
            "Epoch 10/15\n",
            "12723/12723 [==============================] - 4s 305us/step - loss: 0.3226 - acc: 0.8749 - auc: 0.8278\n",
            "Epoch 11/15\n",
            "12723/12723 [==============================] - 4s 311us/step - loss: 0.3004 - acc: 0.8861 - auc: 0.8397\n",
            "Epoch 12/15\n",
            "12723/12723 [==============================] - 4s 307us/step - loss: 0.2872 - acc: 0.8893 - auc: 0.8502\n",
            "Epoch 13/15\n",
            "12723/12723 [==============================] - 4s 319us/step - loss: 0.2859 - acc: 0.8915 - auc: 0.8589\n",
            "Epoch 14/15\n",
            "12723/12723 [==============================] - 4s 297us/step - loss: 0.2699 - acc: 0.9005 - auc: 0.8667\n",
            "Epoch 15/15\n",
            "12723/12723 [==============================] - 4s 311us/step - loss: 0.2600 - acc: 0.9021 - auc: 0.8736\n",
            "3181/3181 [==============================] - 4s 1ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 12s 905us/step - loss: 1.1920 - acc: 0.6198 - auc: 0.5526\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 4s 311us/step - loss: 0.5111 - acc: 0.7598 - auc: 0.6738\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 4s 304us/step - loss: 0.4335 - acc: 0.8117 - auc: 0.7401\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 4s 314us/step - loss: 0.3932 - acc: 0.8322 - auc: 0.7809\n",
            "Epoch 5/15\n",
            "12723/12723 [==============================] - 4s 310us/step - loss: 0.3723 - acc: 0.8466 - auc: 0.8064\n",
            "Epoch 6/15\n",
            "12723/12723 [==============================] - 4s 314us/step - loss: 0.3584 - acc: 0.8531 - auc: 0.8241\n",
            "Epoch 7/15\n",
            "12723/12723 [==============================] - 4s 315us/step - loss: 0.3367 - acc: 0.8648 - auc: 0.8381\n",
            "Epoch 8/15\n",
            "12723/12723 [==============================] - 4s 313us/step - loss: 0.3274 - acc: 0.8687 - auc: 0.8487\n",
            "Epoch 9/15\n",
            "12723/12723 [==============================] - 4s 318us/step - loss: 0.3099 - acc: 0.8770 - auc: 0.8584\n",
            "Epoch 10/15\n",
            "12723/12723 [==============================] - 4s 311us/step - loss: 0.2945 - acc: 0.8848 - auc: 0.8668\n",
            "Epoch 11/15\n",
            "12723/12723 [==============================] - 4s 303us/step - loss: 0.2884 - acc: 0.8887 - auc: 0.8741\n",
            "Epoch 12/15\n",
            "12723/12723 [==============================] - 4s 308us/step - loss: 0.2810 - acc: 0.8911 - auc: 0.8800\n",
            "Epoch 13/15\n",
            "12723/12723 [==============================] - 4s 302us/step - loss: 0.2615 - acc: 0.9009 - auc: 0.8859\n",
            "Epoch 14/15\n",
            "12723/12723 [==============================] - 4s 312us/step - loss: 0.2518 - acc: 0.9045 - auc: 0.8914\n",
            "Epoch 15/15\n",
            "12723/12723 [==============================] - 4s 309us/step - loss: 0.2546 - acc: 0.9015 - auc: 0.8961\n",
            "3181/3181 [==============================] - 4s 1ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 12s 915us/step - loss: 0.6425 - acc: 0.7083 - auc: 0.6100\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 4s 301us/step - loss: 0.4089 - acc: 0.8330 - auc: 0.7835\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 4s 303us/step - loss: 0.3536 - acc: 0.8603 - auc: 0.8326\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 4s 305us/step - loss: 0.3459 - acc: 0.8628 - auc: 0.8553\n",
            "Epoch 5/15\n",
            "12723/12723 [==============================] - 4s 308us/step - loss: 0.3099 - acc: 0.8815 - auc: 0.8705\n",
            "Epoch 6/15\n",
            "12723/12723 [==============================] - 4s 304us/step - loss: 0.3037 - acc: 0.8859 - auc: 0.8814\n",
            "Epoch 7/15\n",
            "12723/12723 [==============================] - 4s 320us/step - loss: 0.2838 - acc: 0.8937 - auc: 0.8890\n",
            "Epoch 8/15\n",
            "12723/12723 [==============================] - 4s 315us/step - loss: 0.2719 - acc: 0.8982 - auc: 0.8961\n",
            "Epoch 9/15\n",
            "12723/12723 [==============================] - 4s 306us/step - loss: 0.2582 - acc: 0.9042 - auc: 0.9023\n",
            "Epoch 10/15\n",
            "12723/12723 [==============================] - 4s 311us/step - loss: 0.2485 - acc: 0.9077 - auc: 0.9077\n",
            "Epoch 11/15\n",
            "12723/12723 [==============================] - 4s 301us/step - loss: 0.2438 - acc: 0.9090 - auc: 0.9122\n",
            "Epoch 12/15\n",
            "12723/12723 [==============================] - 4s 302us/step - loss: 0.2277 - acc: 0.9176 - auc: 0.9163\n",
            "Epoch 13/15\n",
            "12723/12723 [==============================] - 4s 307us/step - loss: 0.2194 - acc: 0.9230 - auc: 0.9205\n",
            "Epoch 14/15\n",
            "12723/12723 [==============================] - 4s 300us/step - loss: 0.2105 - acc: 0.9244 - auc: 0.9239\n",
            "Epoch 15/15\n",
            "12723/12723 [==============================] - 4s 306us/step - loss: 0.1971 - acc: 0.9291 - auc: 0.9274\n",
            "3181/3181 [==============================] - 4s 1ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Epoch 1/15\n",
            "12724/12724 [==============================] - 12s 937us/step - loss: 0.6644 - acc: 0.6975 - auc: 0.6045\n",
            "Epoch 2/15\n",
            "12724/12724 [==============================] - 4s 299us/step - loss: 0.4486 - acc: 0.8023 - auc: 0.7629\n",
            "Epoch 3/15\n",
            "12724/12724 [==============================] - 4s 306us/step - loss: 0.4044 - acc: 0.8301 - auc: 0.8027\n",
            "Epoch 4/15\n",
            "12724/12724 [==============================] - 4s 305us/step - loss: 0.3712 - acc: 0.8470 - auc: 0.8270\n",
            "Epoch 5/15\n",
            "12724/12724 [==============================] - 4s 311us/step - loss: 0.3448 - acc: 0.8606 - auc: 0.8444\n",
            "Epoch 6/15\n",
            "12724/12724 [==============================] - 4s 310us/step - loss: 0.3233 - acc: 0.8701 - auc: 0.8583\n",
            "Epoch 7/15\n",
            "12724/12724 [==============================] - 4s 313us/step - loss: 0.3185 - acc: 0.8750 - auc: 0.8686\n",
            "Epoch 8/15\n",
            "12724/12724 [==============================] - 4s 301us/step - loss: 0.2983 - acc: 0.8831 - auc: 0.8770\n",
            "Epoch 9/15\n",
            "12724/12724 [==============================] - 4s 309us/step - loss: 0.2858 - acc: 0.8904 - auc: 0.8848\n",
            "Epoch 10/15\n",
            "12724/12724 [==============================] - 4s 302us/step - loss: 0.2701 - acc: 0.8969 - auc: 0.8915\n",
            "Epoch 11/15\n",
            "12724/12724 [==============================] - 4s 313us/step - loss: 0.2608 - acc: 0.9006 - auc: 0.8973\n",
            "Epoch 12/15\n",
            "12724/12724 [==============================] - 4s 308us/step - loss: 0.2448 - acc: 0.9086 - auc: 0.9028\n",
            "Epoch 13/15\n",
            "12724/12724 [==============================] - 4s 300us/step - loss: 0.2255 - acc: 0.9152 - auc: 0.9080\n",
            "Epoch 14/15\n",
            "12724/12724 [==============================] - 4s 304us/step - loss: 0.2129 - acc: 0.9192 - auc: 0.9130\n",
            "Epoch 15/15\n",
            "12724/12724 [==============================] - 4s 306us/step - loss: 0.2009 - acc: 0.9250 - auc: 0.9177\n",
            "3180/3180 [==============================] - 4s 1ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 12s 941us/step - loss: 0.1883 - acc: 0.4501 - auc: 0.5332\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 4s 305us/step - loss: 0.1421 - acc: 0.4517 - auc: 0.6434\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 4s 307us/step - loss: 0.1237 - acc: 0.4514 - auc: 0.7311\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 4s 306us/step - loss: 0.1128 - acc: 0.4533 - auc: 0.7825\n",
            "Epoch 5/15\n",
            "12723/12723 [==============================] - 4s 308us/step - loss: 0.1057 - acc: 0.4523 - auc: 0.8141\n",
            "Epoch 6/15\n",
            "12723/12723 [==============================] - 4s 311us/step - loss: 0.0993 - acc: 0.4664 - auc: 0.8371\n",
            "Epoch 7/15\n",
            "12723/12723 [==============================] - 4s 301us/step - loss: 0.0971 - acc: 0.5261 - auc: 0.8539\n",
            "Epoch 8/15\n",
            "12723/12723 [==============================] - 4s 310us/step - loss: 0.0962 - acc: 0.5780 - auc: 0.8657\n",
            "Epoch 9/15\n",
            "12723/12723 [==============================] - 4s 300us/step - loss: 0.0917 - acc: 0.6447 - auc: 0.8754\n",
            "Epoch 10/15\n",
            "12723/12723 [==============================] - 4s 290us/step - loss: 0.0862 - acc: 0.7179 - auc: 0.8838\n",
            "Epoch 11/15\n",
            "12723/12723 [==============================] - 4s 295us/step - loss: 0.0857 - acc: 0.7277 - auc: 0.8908\n",
            "Epoch 12/15\n",
            "12723/12723 [==============================] - 4s 293us/step - loss: 0.0817 - acc: 0.7498 - auc: 0.8969\n",
            "Epoch 13/15\n",
            "12723/12723 [==============================] - 4s 298us/step - loss: 0.0769 - acc: 0.7780 - auc: 0.9025\n",
            "Epoch 14/15\n",
            "12723/12723 [==============================] - 4s 308us/step - loss: 0.0737 - acc: 0.7988 - auc: 0.9078\n",
            "Epoch 15/15\n",
            "12723/12723 [==============================] - 4s 311us/step - loss: 0.0724 - acc: 0.8099 - auc: 0.9124\n",
            "3181/3181 [==============================] - 4s 1ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 12s 955us/step - loss: 0.8880 - acc: 0.4456 - auc: 0.4990\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 4s 304us/step - loss: 0.8841 - acc: 0.4454 - auc: 0.4997\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 4s 302us/step - loss: 0.8841 - acc: 0.4454 - auc: 0.4998\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 4s 304us/step - loss: 0.8920 - acc: 0.4449 - auc: 0.4997\n",
            "Epoch 5/15\n",
            "12723/12723 [==============================] - 4s 301us/step - loss: 0.8841 - acc: 0.4454 - auc: 0.4996\n",
            "Epoch 6/15\n",
            "12723/12723 [==============================] - 4s 304us/step - loss: 0.8841 - acc: 0.4454 - auc: 0.4997\n",
            "Epoch 7/15\n",
            "12723/12723 [==============================] - 4s 316us/step - loss: 0.8934 - acc: 0.4452 - auc: 0.4997\n",
            "Epoch 8/15\n",
            "12723/12723 [==============================] - 4s 303us/step - loss: 0.8841 - acc: 0.4454 - auc: 0.4997\n",
            "Epoch 9/15\n",
            "12723/12723 [==============================] - 4s 307us/step - loss: 0.8840 - acc: 0.4455 - auc: 0.4998\n",
            "Epoch 10/15\n",
            "12723/12723 [==============================] - 4s 304us/step - loss: 0.8841 - acc: 0.4454 - auc: 0.4998\n",
            "Epoch 11/15\n",
            "12723/12723 [==============================] - 4s 302us/step - loss: 0.8841 - acc: 0.4454 - auc: 0.4998\n",
            "Epoch 12/15\n",
            "12723/12723 [==============================] - 4s 297us/step - loss: 0.8841 - acc: 0.4454 - auc: 0.4998\n",
            "Epoch 13/15\n",
            "12723/12723 [==============================] - 4s 295us/step - loss: 0.8841 - acc: 0.4454 - auc: 0.4998\n",
            "Epoch 14/15\n",
            "12723/12723 [==============================] - 4s 294us/step - loss: 0.8841 - acc: 0.4454 - auc: 0.4998\n",
            "Epoch 15/15\n",
            "12723/12723 [==============================] - 4s 305us/step - loss: 0.8840 - acc: 0.4454 - auc: 0.4999\n",
            "3181/3181 [==============================] - 4s 1ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 12s 971us/step - loss: 0.2131 - acc: 0.4492 - auc: 0.5172\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 4s 313us/step - loss: 0.1669 - acc: 0.4460 - auc: 0.5209\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 4s 301us/step - loss: 0.1379 - acc: 0.4528 - auc: 0.6104\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 4s 305us/step - loss: 0.1211 - acc: 0.4543 - auc: 0.6948\n",
            "Epoch 5/15\n",
            "12723/12723 [==============================] - 4s 303us/step - loss: 0.1128 - acc: 0.4564 - auc: 0.7496\n",
            "Epoch 6/15\n",
            "12723/12723 [==============================] - 4s 308us/step - loss: 0.1091 - acc: 0.4558 - auc: 0.7843\n",
            "Epoch 7/15\n",
            "12723/12723 [==============================] - 4s 316us/step - loss: 0.1047 - acc: 0.4578 - auc: 0.8084\n",
            "Epoch 8/15\n",
            "12723/12723 [==============================] - 4s 308us/step - loss: 0.1016 - acc: 0.4620 - auc: 0.8269\n",
            "Epoch 9/15\n",
            "12723/12723 [==============================] - 4s 310us/step - loss: 0.0967 - acc: 0.4757 - auc: 0.8407\n",
            "Epoch 10/15\n",
            "12723/12723 [==============================] - 4s 304us/step - loss: 0.0961 - acc: 0.5171 - auc: 0.8525\n",
            "Epoch 11/15\n",
            "12723/12723 [==============================] - 4s 298us/step - loss: 0.0933 - acc: 0.5701 - auc: 0.8620\n",
            "Epoch 12/15\n",
            "12723/12723 [==============================] - 4s 316us/step - loss: 0.0899 - acc: 0.6425 - auc: 0.8699\n",
            "Epoch 13/15\n",
            "12723/12723 [==============================] - 4s 307us/step - loss: 0.0867 - acc: 0.6851 - auc: 0.8770\n",
            "Epoch 14/15\n",
            "12723/12723 [==============================] - 4s 304us/step - loss: 0.0814 - acc: 0.7417 - auc: 0.8838\n",
            "Epoch 15/15\n",
            "12723/12723 [==============================] - 4s 302us/step - loss: 0.0800 - acc: 0.7579 - auc: 0.8896\n",
            "3181/3181 [==============================] - 4s 1ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 12s 981us/step - loss: 0.2024 - acc: 0.4512 - auc: 0.5213\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 4s 305us/step - loss: 0.1535 - acc: 0.4475 - auc: 0.5845\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 4s 303us/step - loss: 0.1276 - acc: 0.4517 - auc: 0.6811\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 4s 306us/step - loss: 0.1180 - acc: 0.4537 - auc: 0.7466\n",
            "Epoch 5/15\n",
            "12723/12723 [==============================] - 4s 307us/step - loss: 0.1119 - acc: 0.4523 - auc: 0.7854\n",
            "Epoch 6/15\n",
            "12723/12723 [==============================] - 4s 306us/step - loss: 0.1069 - acc: 0.4540 - auc: 0.8119\n",
            "Epoch 7/15\n",
            "12723/12723 [==============================] - 4s 306us/step - loss: 0.1034 - acc: 0.4562 - auc: 0.8308\n",
            "Epoch 8/15\n",
            "12723/12723 [==============================] - 4s 308us/step - loss: 0.1010 - acc: 0.4739 - auc: 0.8448\n",
            "Epoch 9/15\n",
            "12723/12723 [==============================] - 4s 305us/step - loss: 0.0999 - acc: 0.4799 - auc: 0.8552\n",
            "Epoch 10/15\n",
            "12723/12723 [==============================] - 4s 300us/step - loss: 0.0962 - acc: 0.5564 - auc: 0.8639\n",
            "Epoch 11/15\n",
            "12723/12723 [==============================] - 4s 303us/step - loss: 0.0935 - acc: 0.5865 - auc: 0.8712\n",
            "Epoch 12/15\n",
            "12723/12723 [==============================] - 4s 307us/step - loss: 0.1016 - acc: 0.5939 - auc: 0.8772\n",
            "Epoch 13/15\n",
            "12723/12723 [==============================] - 4s 304us/step - loss: 0.0937 - acc: 0.6157 - auc: 0.8815\n",
            "Epoch 14/15\n",
            "12723/12723 [==============================] - 4s 298us/step - loss: 0.0893 - acc: 0.6819 - auc: 0.8863\n",
            "Epoch 15/15\n",
            "12723/12723 [==============================] - 4s 305us/step - loss: 0.0878 - acc: 0.7060 - auc: 0.8908\n",
            "3181/3181 [==============================] - 4s 1ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Epoch 1/15\n",
            "12724/12724 [==============================] - 13s 985us/step - loss: 0.1833 - acc: 0.4474 - auc: 0.5293\n",
            "Epoch 2/15\n",
            "12724/12724 [==============================] - 4s 300us/step - loss: 0.1364 - acc: 0.4522 - auc: 0.6497\n",
            "Epoch 3/15\n",
            "12724/12724 [==============================] - 4s 291us/step - loss: 0.1138 - acc: 0.4572 - auc: 0.7555\n",
            "Epoch 4/15\n",
            "12724/12724 [==============================] - 4s 306us/step - loss: 0.1045 - acc: 0.4580 - auc: 0.8078\n",
            "Epoch 5/15\n",
            "12724/12724 [==============================] - 4s 305us/step - loss: 0.0980 - acc: 0.4699 - auc: 0.8389\n",
            "Epoch 6/15\n",
            "12724/12724 [==============================] - 4s 298us/step - loss: 0.0930 - acc: 0.5512 - auc: 0.8598\n",
            "Epoch 7/15\n",
            "12724/12724 [==============================] - 4s 305us/step - loss: 0.0888 - acc: 0.6463 - auc: 0.8750\n",
            "Epoch 8/15\n",
            "12724/12724 [==============================] - 4s 302us/step - loss: 0.0855 - acc: 0.7084 - auc: 0.8862\n",
            "Epoch 9/15\n",
            "12724/12724 [==============================] - 4s 304us/step - loss: 0.0842 - acc: 0.7213 - auc: 0.8949\n",
            "Epoch 10/15\n",
            "12724/12724 [==============================] - 4s 325us/step - loss: 0.0769 - acc: 0.7749 - auc: 0.9025\n",
            "Epoch 11/15\n",
            "12724/12724 [==============================] - 4s 313us/step - loss: 0.0731 - acc: 0.7946 - auc: 0.9093\n",
            "Epoch 12/15\n",
            "12724/12724 [==============================] - 4s 314us/step - loss: 0.0724 - acc: 0.8114 - auc: 0.9154\n",
            "Epoch 13/15\n",
            "12724/12724 [==============================] - 4s 304us/step - loss: 0.0676 - acc: 0.8223 - auc: 0.9203\n",
            "Epoch 14/15\n",
            "12724/12724 [==============================] - 4s 315us/step - loss: 0.0607 - acc: 0.8515 - auc: 0.9251\n",
            "Epoch 15/15\n",
            "12724/12724 [==============================] - 4s 292us/step - loss: 0.0567 - acc: 0.8684 - auc: 0.9296\n",
            "3180/3180 [==============================] - 4s 1ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Warstwa 3\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 13s 1ms/step - loss: 0.7178 - acc: 0.5492 - auc: 0.5035\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 4s 319us/step - loss: 0.6874 - acc: 0.5546 - auc: 0.5022\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 4s 319us/step - loss: 0.6865 - acc: 0.5546 - auc: 0.5009\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 4s 322us/step - loss: 0.6890 - acc: 0.5531 - auc: 0.5006\n",
            "Epoch 5/15\n",
            "12723/12723 [==============================] - 4s 318us/step - loss: 0.6868 - acc: 0.5544 - auc: 0.4998\n",
            "Epoch 6/15\n",
            "12723/12723 [==============================] - 4s 312us/step - loss: 0.6868 - acc: 0.5545 - auc: 0.4996\n",
            "Epoch 7/15\n",
            "12723/12723 [==============================] - 4s 317us/step - loss: 0.6863 - acc: 0.5546 - auc: 0.5003\n",
            "Epoch 8/15\n",
            "12723/12723 [==============================] - 4s 316us/step - loss: 0.6864 - acc: 0.5546 - auc: 0.5003\n",
            "Epoch 9/15\n",
            "12723/12723 [==============================] - 4s 321us/step - loss: 0.6864 - acc: 0.5546 - auc: 0.4999\n",
            "Epoch 10/15\n",
            "12723/12723 [==============================] - 4s 316us/step - loss: 0.6865 - acc: 0.5546 - auc: 0.5003\n",
            "Epoch 11/15\n",
            "12723/12723 [==============================] - 4s 319us/step - loss: 0.6875 - acc: 0.5544 - auc: 0.4999\n",
            "Epoch 12/15\n",
            "12723/12723 [==============================] - 4s 320us/step - loss: 0.6904 - acc: 0.5547 - auc: 0.5000\n",
            "Epoch 13/15\n",
            "12723/12723 [==============================] - 4s 317us/step - loss: 0.6866 - acc: 0.5546 - auc: 0.4998\n",
            "Epoch 14/15\n",
            "12723/12723 [==============================] - 4s 327us/step - loss: 0.6937 - acc: 0.5543 - auc: 0.4998\n",
            "Epoch 15/15\n",
            "12723/12723 [==============================] - 4s 327us/step - loss: 0.6866 - acc: 0.5546 - auc: 0.4997\n",
            "3181/3181 [==============================] - 4s 1ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Warstwa 3\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 13s 1ms/step - loss: 0.7183 - acc: 0.5532 - auc: 0.4950\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 4s 326us/step - loss: 0.6872 - acc: 0.5533 - auc: 0.5014\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 4s 325us/step - loss: 0.6871 - acc: 0.5553 - auc: 0.5009\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 4s 318us/step - loss: 0.6868 - acc: 0.5546 - auc: 0.5006\n",
            "Epoch 5/15\n",
            "12723/12723 [==============================] - 4s 319us/step - loss: 0.6871 - acc: 0.5562 - auc: 0.5008\n",
            "Epoch 6/15\n",
            "12723/12723 [==============================] - 4s 331us/step - loss: 0.6869 - acc: 0.5548 - auc: 0.5005\n",
            "Epoch 7/15\n",
            "12723/12723 [==============================] - 4s 320us/step - loss: 0.6865 - acc: 0.5548 - auc: 0.4994\n",
            "Epoch 8/15\n",
            "12723/12723 [==============================] - 4s 317us/step - loss: 0.6859 - acc: 0.5565 - auc: 0.4994\n",
            "Epoch 9/15\n",
            "12723/12723 [==============================] - 4s 319us/step - loss: 0.6873 - acc: 0.5546 - auc: 0.4994\n",
            "Epoch 10/15\n",
            "12723/12723 [==============================] - 4s 319us/step - loss: 0.6875 - acc: 0.5546 - auc: 0.4996\n",
            "Epoch 11/15\n",
            "12723/12723 [==============================] - 4s 321us/step - loss: 0.6874 - acc: 0.5546 - auc: 0.4996\n",
            "Epoch 12/15\n",
            "12723/12723 [==============================] - 4s 318us/step - loss: 0.6875 - acc: 0.5546 - auc: 0.4994\n",
            "Epoch 13/15\n",
            "12723/12723 [==============================] - 4s 332us/step - loss: 0.6873 - acc: 0.5546 - auc: 0.4990\n",
            "Epoch 14/15\n",
            "12723/12723 [==============================] - 4s 323us/step - loss: 0.6873 - acc: 0.5546 - auc: 0.4990\n",
            "Epoch 15/15\n",
            "12723/12723 [==============================] - 4s 330us/step - loss: 0.6874 - acc: 0.5546 - auc: 0.4989\n",
            "3181/3181 [==============================] - 4s 1ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Warstwa 3\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 14s 1ms/step - loss: 0.7019 - acc: 0.5448 - auc: 0.5160\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 4s 339us/step - loss: 0.6858 - acc: 0.5554 - auc: 0.5147\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 4s 321us/step - loss: 0.6554 - acc: 0.6089 - auc: 0.5280\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 4s 321us/step - loss: 0.6832 - acc: 0.5663 - auc: 0.5494\n",
            "Epoch 5/15\n",
            "12723/12723 [==============================] - 4s 328us/step - loss: 0.6868 - acc: 0.5547 - auc: 0.5407\n",
            "Epoch 6/15\n",
            "12723/12723 [==============================] - 4s 327us/step - loss: 0.6831 - acc: 0.5599 - auc: 0.5358\n",
            "Epoch 7/15\n",
            "12723/12723 [==============================] - 4s 321us/step - loss: 0.6857 - acc: 0.5552 - auc: 0.5316\n",
            "Epoch 8/15\n",
            "12723/12723 [==============================] - 4s 314us/step - loss: 0.6406 - acc: 0.6274 - auc: 0.5339\n",
            "Epoch 9/15\n",
            "12723/12723 [==============================] - 4s 320us/step - loss: 0.5112 - acc: 0.7586 - auc: 0.5649\n",
            "Epoch 10/15\n",
            "12723/12723 [==============================] - 4s 321us/step - loss: 0.4288 - acc: 0.8136 - auc: 0.6070\n",
            "Epoch 11/15\n",
            "12723/12723 [==============================] - 4s 323us/step - loss: 0.3924 - acc: 0.8357 - auc: 0.6457\n",
            "Epoch 12/15\n",
            "12723/12723 [==============================] - 4s 313us/step - loss: 0.3617 - acc: 0.8529 - auc: 0.6786\n",
            "Epoch 13/15\n",
            "12723/12723 [==============================] - 4s 331us/step - loss: 0.3465 - acc: 0.8601 - auc: 0.7061\n",
            "Epoch 14/15\n",
            "12723/12723 [==============================] - 4s 323us/step - loss: 0.3302 - acc: 0.8685 - auc: 0.7291\n",
            "Epoch 15/15\n",
            "12723/12723 [==============================] - 4s 321us/step - loss: 0.3202 - acc: 0.8753 - auc: 0.7487\n",
            "3181/3181 [==============================] - 5s 1ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Warstwa 3\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 14s 1ms/step - loss: 0.6593 - acc: 0.6079 - auc: 0.5170\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 4s 344us/step - loss: 0.4449 - acc: 0.7999 - auc: 0.7080\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 4s 328us/step - loss: 0.3898 - acc: 0.8368 - auc: 0.7880\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 4s 323us/step - loss: 0.3711 - acc: 0.8490 - auc: 0.8237\n",
            "Epoch 5/15\n",
            "12723/12723 [==============================] - 4s 336us/step - loss: 0.3560 - acc: 0.8566 - auc: 0.8421\n",
            "Epoch 6/15\n",
            "12723/12723 [==============================] - 4s 320us/step - loss: 0.3463 - acc: 0.8606 - auc: 0.8541\n",
            "Epoch 7/15\n",
            "12723/12723 [==============================] - 4s 321us/step - loss: 0.3271 - acc: 0.8700 - auc: 0.8639\n",
            "Epoch 8/15\n",
            "12723/12723 [==============================] - 4s 311us/step - loss: 0.3197 - acc: 0.8742 - auc: 0.8716\n",
            "Epoch 9/15\n",
            "12723/12723 [==============================] - 4s 306us/step - loss: 0.3143 - acc: 0.8776 - auc: 0.8778\n",
            "Epoch 10/15\n",
            "12723/12723 [==============================] - 4s 308us/step - loss: 0.3060 - acc: 0.8809 - auc: 0.8829\n",
            "Epoch 11/15\n",
            "12723/12723 [==============================] - 4s 313us/step - loss: 0.2993 - acc: 0.8834 - auc: 0.8871\n",
            "Epoch 12/15\n",
            "12723/12723 [==============================] - 4s 312us/step - loss: 0.2930 - acc: 0.8895 - auc: 0.8911\n",
            "Epoch 13/15\n",
            "12723/12723 [==============================] - 4s 308us/step - loss: 0.2859 - acc: 0.8893 - auc: 0.8948\n",
            "Epoch 14/15\n",
            "12723/12723 [==============================] - 4s 324us/step - loss: 0.2794 - acc: 0.8945 - auc: 0.8979\n",
            "Epoch 15/15\n",
            "12723/12723 [==============================] - 4s 309us/step - loss: 0.2729 - acc: 0.8944 - auc: 0.9009\n",
            "3181/3181 [==============================] - 4s 1ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Warstwa 3\n",
            "Epoch 1/15\n",
            "12724/12724 [==============================] - 13s 1ms/step - loss: 0.5982 - acc: 0.6672 - auc: 0.5832\n",
            "Epoch 2/15\n",
            "12724/12724 [==============================] - 4s 312us/step - loss: 0.4088 - acc: 0.8282 - auc: 0.7619\n",
            "Epoch 3/15\n",
            "12724/12724 [==============================] - 4s 312us/step - loss: 0.3687 - acc: 0.8524 - auc: 0.8240\n",
            "Epoch 4/15\n",
            "12724/12724 [==============================] - 4s 321us/step - loss: 0.3422 - acc: 0.8645 - auc: 0.8490\n",
            "Epoch 5/15\n",
            "12724/12724 [==============================] - 4s 320us/step - loss: 0.3267 - acc: 0.8750 - auc: 0.8656\n",
            "Epoch 6/15\n",
            "12724/12724 [==============================] - 4s 318us/step - loss: 0.3134 - acc: 0.8780 - auc: 0.8763\n",
            "Epoch 7/15\n",
            "12724/12724 [==============================] - 4s 335us/step - loss: 0.3083 - acc: 0.8825 - auc: 0.8840\n",
            "Epoch 8/15\n",
            "12724/12724 [==============================] - 4s 331us/step - loss: 0.2945 - acc: 0.8871 - auc: 0.8901\n",
            "Epoch 9/15\n",
            "12724/12724 [==============================] - 4s 333us/step - loss: 0.2914 - acc: 0.8915 - auc: 0.8952\n",
            "Epoch 10/15\n",
            "12724/12724 [==============================] - 4s 331us/step - loss: 0.2814 - acc: 0.8942 - auc: 0.8989\n",
            "Epoch 11/15\n",
            "12724/12724 [==============================] - 4s 331us/step - loss: 0.2861 - acc: 0.8912 - auc: 0.9025\n",
            "Epoch 12/15\n",
            "12724/12724 [==============================] - 4s 342us/step - loss: 0.2756 - acc: 0.8971 - auc: 0.9052\n",
            "Epoch 13/15\n",
            "12724/12724 [==============================] - 4s 323us/step - loss: 0.2714 - acc: 0.8978 - auc: 0.9079\n",
            "Epoch 14/15\n",
            "12724/12724 [==============================] - 4s 310us/step - loss: 0.2663 - acc: 0.9007 - auc: 0.9104\n",
            "Epoch 15/15\n",
            "12724/12724 [==============================] - 4s 317us/step - loss: 0.2579 - acc: 0.9025 - auc: 0.9127\n",
            "3180/3180 [==============================] - 5s 1ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Warstwa 3\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 14s 1ms/step - loss: 0.1833 - acc: 0.4501 - auc: 0.5286\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 4s 323us/step - loss: 0.1374 - acc: 0.4459 - auc: 0.6485\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 4s 319us/step - loss: 0.1193 - acc: 0.4458 - auc: 0.7443\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 4s 325us/step - loss: 0.1114 - acc: 0.4526 - auc: 0.7935\n",
            "Epoch 5/15\n",
            "12723/12723 [==============================] - 4s 319us/step - loss: 0.1065 - acc: 0.4552 - auc: 0.8229\n",
            "Epoch 6/15\n",
            "12723/12723 [==============================] - 4s 314us/step - loss: 0.1035 - acc: 0.4587 - auc: 0.8420\n",
            "Epoch 7/15\n",
            "12723/12723 [==============================] - 4s 316us/step - loss: 0.1003 - acc: 0.4824 - auc: 0.8559\n",
            "Epoch 8/15\n",
            "12723/12723 [==============================] - 4s 331us/step - loss: 0.0994 - acc: 0.5415 - auc: 0.8664\n",
            "Epoch 9/15\n",
            "12723/12723 [==============================] - 4s 321us/step - loss: 0.0966 - acc: 0.5936 - auc: 0.8740\n",
            "Epoch 10/15\n",
            "12723/12723 [==============================] - 4s 324us/step - loss: 0.0961 - acc: 0.5826 - auc: 0.8805\n",
            "Epoch 11/15\n",
            "12723/12723 [==============================] - 4s 325us/step - loss: 0.0935 - acc: 0.6357 - auc: 0.8856\n",
            "Epoch 12/15\n",
            "12723/12723 [==============================] - 4s 322us/step - loss: 0.0943 - acc: 0.6446 - auc: 0.8900\n",
            "Epoch 13/15\n",
            "12723/12723 [==============================] - 4s 325us/step - loss: 0.0923 - acc: 0.6695 - auc: 0.8939\n",
            "Epoch 14/15\n",
            "12723/12723 [==============================] - 4s 325us/step - loss: 0.0908 - acc: 0.6894 - auc: 0.8972\n",
            "Epoch 15/15\n",
            "12723/12723 [==============================] - 4s 320us/step - loss: 0.0885 - acc: 0.7146 - auc: 0.9005\n",
            "3181/3181 [==============================] - 5s 1ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Warstwa 3\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 14s 1ms/step - loss: 0.1488 - acc: 0.4524 - auc: 0.6255\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 4s 323us/step - loss: 0.1126 - acc: 0.4497 - auc: 0.8016\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 4s 327us/step - loss: 0.1044 - acc: 0.4541 - auc: 0.8504\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 4s 337us/step - loss: 0.0985 - acc: 0.4879 - auc: 0.8718\n",
            "Epoch 5/15\n",
            "12723/12723 [==============================] - 4s 337us/step - loss: 0.0958 - acc: 0.5317 - auc: 0.8848\n",
            "Epoch 6/15\n",
            "12723/12723 [==============================] - 4s 333us/step - loss: 0.0939 - acc: 0.6063 - auc: 0.8938\n",
            "Epoch 7/15\n",
            "12723/12723 [==============================] - 4s 329us/step - loss: 0.0916 - acc: 0.6459 - auc: 0.9003\n",
            "Epoch 8/15\n",
            "12723/12723 [==============================] - 4s 331us/step - loss: 0.0866 - acc: 0.6978 - auc: 0.9057\n",
            "Epoch 9/15\n",
            "12723/12723 [==============================] - 4s 340us/step - loss: 0.0859 - acc: 0.7272 - auc: 0.9105\n",
            "Epoch 10/15\n",
            "12723/12723 [==============================] - 4s 337us/step - loss: 0.0829 - acc: 0.7458 - auc: 0.9145\n",
            "Epoch 11/15\n",
            "12723/12723 [==============================] - 4s 352us/step - loss: 0.0818 - acc: 0.7622 - auc: 0.9180\n",
            "Epoch 12/15\n",
            "12723/12723 [==============================] - 4s 342us/step - loss: 0.0789 - acc: 0.7716 - auc: 0.9212\n",
            "Epoch 13/15\n",
            "12723/12723 [==============================] - 4s 332us/step - loss: 0.0790 - acc: 0.7827 - auc: 0.9241\n",
            "Epoch 14/15\n",
            "12723/12723 [==============================] - 4s 325us/step - loss: 0.0758 - acc: 0.7960 - auc: 0.9267\n",
            "Epoch 15/15\n",
            "12723/12723 [==============================] - 4s 328us/step - loss: 0.0752 - acc: 0.7956 - auc: 0.9290\n",
            "3181/3181 [==============================] - 5s 2ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Warstwa 3\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 14s 1ms/step - loss: 0.1978 - acc: 0.4469 - auc: 0.5072\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 4s 331us/step - loss: 0.1494 - acc: 0.4456 - auc: 0.5723\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 4s 320us/step - loss: 0.1222 - acc: 0.4479 - auc: 0.6915\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 4s 323us/step - loss: 0.1140 - acc: 0.4475 - auc: 0.7630\n",
            "Epoch 5/15\n",
            "12723/12723 [==============================] - 4s 320us/step - loss: 0.1069 - acc: 0.4463 - auc: 0.8023\n",
            "Epoch 6/15\n",
            "12723/12723 [==============================] - 4s 320us/step - loss: 0.1029 - acc: 0.4477 - auc: 0.8275\n",
            "Epoch 7/15\n",
            "12723/12723 [==============================] - 4s 323us/step - loss: 0.1000 - acc: 0.4546 - auc: 0.8448\n",
            "Epoch 8/15\n",
            "12723/12723 [==============================] - 4s 325us/step - loss: 0.0974 - acc: 0.5272 - auc: 0.8577\n",
            "Epoch 9/15\n",
            "12723/12723 [==============================] - 4s 321us/step - loss: 0.0961 - acc: 0.5905 - auc: 0.8680\n",
            "Epoch 10/15\n",
            "12723/12723 [==============================] - 4s 318us/step - loss: 0.0921 - acc: 0.6287 - auc: 0.8756\n",
            "Epoch 11/15\n",
            "12723/12723 [==============================] - 4s 338us/step - loss: 0.0907 - acc: 0.6553 - auc: 0.8824\n",
            "Epoch 12/15\n",
            "12723/12723 [==============================] - 4s 321us/step - loss: 0.0901 - acc: 0.6868 - auc: 0.8883\n",
            "Epoch 13/15\n",
            "12723/12723 [==============================] - 4s 317us/step - loss: 0.0875 - acc: 0.7097 - auc: 0.8931\n",
            "Epoch 14/15\n",
            "12723/12723 [==============================] - 4s 328us/step - loss: 0.0841 - acc: 0.7402 - auc: 0.8974\n",
            "Epoch 15/15\n",
            "12723/12723 [==============================] - 4s 323us/step - loss: 0.0838 - acc: 0.7483 - auc: 0.9016\n",
            "3181/3181 [==============================] - 5s 2ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Warstwa 3\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 14s 1ms/step - loss: 0.1630 - acc: 0.4490 - auc: 0.5367\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 4s 329us/step - loss: 0.1181 - acc: 0.4540 - auc: 0.7397\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 4s 329us/step - loss: 0.1061 - acc: 0.4533 - auc: 0.8191\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 4s 329us/step - loss: 0.0994 - acc: 0.4622 - auc: 0.8531\n",
            "Epoch 5/15\n",
            "12723/12723 [==============================] - 4s 340us/step - loss: 0.0978 - acc: 0.5261 - auc: 0.8722\n",
            "Epoch 6/15\n",
            "12723/12723 [==============================] - 4s 333us/step - loss: 0.0940 - acc: 0.5782 - auc: 0.8841\n",
            "Epoch 7/15\n",
            "12723/12723 [==============================] - 4s 333us/step - loss: 0.0925 - acc: 0.6342 - auc: 0.8924\n",
            "Epoch 8/15\n",
            "12723/12723 [==============================] - 4s 325us/step - loss: 0.0903 - acc: 0.6853 - auc: 0.8991\n",
            "Epoch 9/15\n",
            "12723/12723 [==============================] - 4s 329us/step - loss: 0.0876 - acc: 0.7055 - auc: 0.9045\n",
            "Epoch 10/15\n",
            "12723/12723 [==============================] - 4s 324us/step - loss: 0.0862 - acc: 0.7403 - auc: 0.9090\n",
            "Epoch 11/15\n",
            "12723/12723 [==============================] - 4s 331us/step - loss: 0.0847 - acc: 0.7488 - auc: 0.9128\n",
            "Epoch 12/15\n",
            "12723/12723 [==============================] - 4s 325us/step - loss: 0.0858 - acc: 0.7455 - auc: 0.9156\n",
            "Epoch 13/15\n",
            "12723/12723 [==============================] - 4s 324us/step - loss: 0.0815 - acc: 0.7632 - auc: 0.9185\n",
            "Epoch 14/15\n",
            "12723/12723 [==============================] - 4s 326us/step - loss: 0.0797 - acc: 0.7834 - auc: 0.9211\n",
            "Epoch 15/15\n",
            "12723/12723 [==============================] - 4s 327us/step - loss: 0.0792 - acc: 0.7929 - auc: 0.9237\n",
            "3181/3181 [==============================] - 5s 2ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Warstwa 3\n",
            "Epoch 1/15\n",
            "12724/12724 [==============================] - 15s 1ms/step - loss: 0.1840 - acc: 0.4466 - auc: 0.4901\n",
            "Epoch 2/15\n",
            "12724/12724 [==============================] - 4s 327us/step - loss: 0.1614 - acc: 0.4470 - auc: 0.5358\n",
            "Epoch 3/15\n",
            "12724/12724 [==============================] - 4s 319us/step - loss: 0.1284 - acc: 0.4462 - auc: 0.6444\n",
            "Epoch 4/15\n",
            "12724/12724 [==============================] - 4s 323us/step - loss: 0.1142 - acc: 0.4491 - auc: 0.7318\n",
            "Epoch 5/15\n",
            "12724/12724 [==============================] - 4s 318us/step - loss: 0.1090 - acc: 0.4500 - auc: 0.7803\n",
            "Epoch 6/15\n",
            "12724/12724 [==============================] - 4s 317us/step - loss: 0.1050 - acc: 0.4495 - auc: 0.8110\n",
            "Epoch 7/15\n",
            "12724/12724 [==============================] - 4s 323us/step - loss: 0.1045 - acc: 0.4497 - auc: 0.8309\n",
            "Epoch 8/15\n",
            "12724/12724 [==============================] - 4s 331us/step - loss: 0.1001 - acc: 0.4553 - auc: 0.8444\n",
            "Epoch 9/15\n",
            "12724/12724 [==============================] - 4s 329us/step - loss: 0.0990 - acc: 0.4551 - auc: 0.8560\n",
            "Epoch 10/15\n",
            "12724/12724 [==============================] - 4s 327us/step - loss: 0.0971 - acc: 0.4827 - auc: 0.8647\n",
            "Epoch 11/15\n",
            "12724/12724 [==============================] - 4s 318us/step - loss: 0.0958 - acc: 0.5035 - auc: 0.8714\n",
            "Epoch 12/15\n",
            "12724/12724 [==============================] - 4s 326us/step - loss: 0.0941 - acc: 0.6136 - auc: 0.8777\n",
            "Epoch 13/15\n",
            "12724/12724 [==============================] - 4s 314us/step - loss: 0.0919 - acc: 0.6410 - auc: 0.8829\n",
            "Epoch 14/15\n",
            "12724/12724 [==============================] - 4s 317us/step - loss: 0.0916 - acc: 0.6486 - auc: 0.8875\n",
            "Epoch 15/15\n",
            "12724/12724 [==============================] - 4s 317us/step - loss: 0.0903 - acc: 0.6760 - auc: 0.8914\n",
            "3180/3180 [==============================] - 5s 2ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 15s 1ms/step - loss: 0.7276 - acc: 0.5625 - auc: 0.5181\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 4s 319us/step - loss: 0.6874 - acc: 0.5609 - auc: 0.5210\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 4s 322us/step - loss: 0.6916 - acc: 0.5582 - auc: 0.5157\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 4s 321us/step - loss: 0.6883 - acc: 0.5548 - auc: 0.5131\n",
            "Epoch 5/15\n",
            "12723/12723 [==============================] - 4s 321us/step - loss: 0.7000 - acc: 0.5551 - auc: 0.5112\n",
            "Epoch 6/15\n",
            "12723/12723 [==============================] - 4s 316us/step - loss: 0.6884 - acc: 0.5550 - auc: 0.5098\n",
            "Epoch 7/15\n",
            "12723/12723 [==============================] - 4s 318us/step - loss: 0.6879 - acc: 0.5554 - auc: 0.5081\n",
            "Epoch 8/15\n",
            "12723/12723 [==============================] - 4s 320us/step - loss: 0.6875 - acc: 0.5561 - auc: 0.5074\n",
            "Epoch 9/15\n",
            "12723/12723 [==============================] - 4s 322us/step - loss: 0.6866 - acc: 0.5568 - auc: 0.5074\n",
            "Epoch 10/15\n",
            "12723/12723 [==============================] - 4s 323us/step - loss: 0.7121 - acc: 0.5650 - auc: 0.5085\n",
            "Epoch 11/15\n",
            "12723/12723 [==============================] - 4s 322us/step - loss: 0.7033 - acc: 0.5569 - auc: 0.5087\n",
            "Epoch 12/15\n",
            "12723/12723 [==============================] - 4s 325us/step - loss: 0.7047 - acc: 0.5562 - auc: 0.5084\n",
            "Epoch 13/15\n",
            "12723/12723 [==============================] - 4s 326us/step - loss: 0.6919 - acc: 0.5551 - auc: 0.5086\n",
            "Epoch 14/15\n",
            "12723/12723 [==============================] - 4s 323us/step - loss: 0.6927 - acc: 0.5554 - auc: 0.5082\n",
            "Epoch 15/15\n",
            "12723/12723 [==============================] - 4s 318us/step - loss: 0.6900 - acc: 0.5559 - auc: 0.5076\n",
            "3181/3181 [==============================] - 5s 2ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 15s 1ms/step - loss: 7.4126 - acc: 0.5380 - auc: 0.5020\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 4s 336us/step - loss: 7.1798 - acc: 0.5543 - auc: 0.5018\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 4s 333us/step - loss: 7.1792 - acc: 0.5546 - auc: 0.5014\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 4s 337us/step - loss: 7.1788 - acc: 0.5546 - auc: 0.5010\n",
            "Epoch 5/15\n",
            "12723/12723 [==============================] - 4s 335us/step - loss: 7.1762 - acc: 0.5547 - auc: 0.5008\n",
            "Epoch 6/15\n",
            "12723/12723 [==============================] - 4s 334us/step - loss: 7.1804 - acc: 0.5544 - auc: 0.5007\n",
            "Epoch 7/15\n",
            "12723/12723 [==============================] - 4s 328us/step - loss: 7.1869 - acc: 0.5540 - auc: 0.5005\n",
            "Epoch 8/15\n",
            "12723/12723 [==============================] - 4s 329us/step - loss: 7.1940 - acc: 0.5536 - auc: 0.5004\n",
            "Epoch 9/15\n",
            "12723/12723 [==============================] - 4s 325us/step - loss: 7.1805 - acc: 0.5544 - auc: 0.5003\n",
            "Epoch 10/15\n",
            "12723/12723 [==============================] - 4s 331us/step - loss: 7.1792 - acc: 0.5545 - auc: 0.5003\n",
            "Epoch 11/15\n",
            "12723/12723 [==============================] - 4s 330us/step - loss: 7.1805 - acc: 0.5545 - auc: 0.5002\n",
            "Epoch 12/15\n",
            "12723/12723 [==============================] - 4s 331us/step - loss: 7.1780 - acc: 0.5547 - auc: 0.5002\n",
            "Epoch 13/15\n",
            "12723/12723 [==============================] - 4s 328us/step - loss: 7.1792 - acc: 0.5546 - auc: 0.5002\n",
            "Epoch 14/15\n",
            "12723/12723 [==============================] - 4s 337us/step - loss: 7.1792 - acc: 0.5546 - auc: 0.5002\n",
            "Epoch 15/15\n",
            "12723/12723 [==============================] - 4s 334us/step - loss: 7.1767 - acc: 0.5547 - auc: 0.5002\n",
            "3181/3181 [==============================] - 5s 2ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 15s 1ms/step - loss: 0.6577 - acc: 0.6359 - auc: 0.5540\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 4s 332us/step - loss: 0.4351 - acc: 0.8165 - auc: 0.7329\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 4s 331us/step - loss: 0.3625 - acc: 0.8577 - auc: 0.8082\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 4s 323us/step - loss: 0.3170 - acc: 0.8792 - auc: 0.8445\n",
            "Epoch 5/15\n",
            "12723/12723 [==============================] - 4s 327us/step - loss: 0.2832 - acc: 0.8937 - auc: 0.8672\n",
            "Epoch 6/15\n",
            "12723/12723 [==============================] - 4s 327us/step - loss: 0.2716 - acc: 0.8980 - auc: 0.8831\n",
            "Epoch 7/15\n",
            "12723/12723 [==============================] - 4s 324us/step - loss: 0.2431 - acc: 0.9113 - auc: 0.8950\n",
            "Epoch 8/15\n",
            "12723/12723 [==============================] - 4s 325us/step - loss: 0.2213 - acc: 0.9213 - auc: 0.9050\n",
            "Epoch 9/15\n",
            "12723/12723 [==============================] - 4s 327us/step - loss: 0.2002 - acc: 0.9260 - auc: 0.9135\n",
            "Epoch 10/15\n",
            "12723/12723 [==============================] - 4s 326us/step - loss: 0.1880 - acc: 0.9340 - auc: 0.9212\n",
            "Epoch 11/15\n",
            "12723/12723 [==============================] - 4s 327us/step - loss: 0.1647 - acc: 0.9407 - auc: 0.9277\n",
            "Epoch 12/15\n",
            "12723/12723 [==============================] - 4s 330us/step - loss: 0.1501 - acc: 0.9492 - auc: 0.9337\n",
            "Epoch 13/15\n",
            "12723/12723 [==============================] - 4s 331us/step - loss: 0.1439 - acc: 0.9508 - auc: 0.9392\n",
            "Epoch 14/15\n",
            "12723/12723 [==============================] - 4s 329us/step - loss: 0.1290 - acc: 0.9543 - auc: 0.9439\n",
            "Epoch 15/15\n",
            "12723/12723 [==============================] - 4s 344us/step - loss: 0.0938 - acc: 0.9690 - auc: 0.9485\n",
            "3181/3181 [==============================] - 5s 2ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 15s 1ms/step - loss: 0.7090 - acc: 0.5975 - auc: 0.5414\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 4s 321us/step - loss: 0.4511 - acc: 0.8089 - auc: 0.6993\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 4s 320us/step - loss: 0.3623 - acc: 0.8569 - auc: 0.7882\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 4s 328us/step - loss: 0.3200 - acc: 0.8792 - auc: 0.8328\n",
            "Epoch 5/15\n",
            "12723/12723 [==============================] - 4s 334us/step - loss: 0.2954 - acc: 0.8911 - auc: 0.8584\n",
            "Epoch 6/15\n",
            "12723/12723 [==============================] - 4s 341us/step - loss: 0.2850 - acc: 0.8935 - auc: 0.8754\n",
            "Epoch 7/15\n",
            "12723/12723 [==============================] - 4s 327us/step - loss: 0.2697 - acc: 0.9002 - auc: 0.8868\n",
            "Epoch 8/15\n",
            "12723/12723 [==============================] - 4s 322us/step - loss: 0.2548 - acc: 0.9076 - auc: 0.8957\n",
            "Epoch 9/15\n",
            "12723/12723 [==============================] - 4s 326us/step - loss: 0.2435 - acc: 0.9120 - auc: 0.9034\n",
            "Epoch 10/15\n",
            "12723/12723 [==============================] - 4s 327us/step - loss: 0.2291 - acc: 0.9192 - auc: 0.9094\n",
            "Epoch 11/15\n",
            "12723/12723 [==============================] - 4s 321us/step - loss: 0.2260 - acc: 0.9220 - auc: 0.9151\n",
            "Epoch 12/15\n",
            "12723/12723 [==============================] - 4s 320us/step - loss: 0.2160 - acc: 0.9209 - auc: 0.9193\n",
            "Epoch 13/15\n",
            "12723/12723 [==============================] - 4s 320us/step - loss: 0.1977 - acc: 0.9312 - auc: 0.9236\n",
            "Epoch 14/15\n",
            "12723/12723 [==============================] - 4s 328us/step - loss: 0.1847 - acc: 0.9360 - auc: 0.9279\n",
            "Epoch 15/15\n",
            "12723/12723 [==============================] - 4s 322us/step - loss: 0.1812 - acc: 0.9375 - auc: 0.9316\n",
            "3181/3181 [==============================] - 5s 2ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Epoch 1/15\n",
            "12724/12724 [==============================] - 16s 1ms/step - loss: 0.7101 - acc: 0.5509 - auc: 0.5181\n",
            "Epoch 2/15\n",
            "12724/12724 [==============================] - 4s 322us/step - loss: 0.5947 - acc: 0.6809 - auc: 0.5603\n",
            "Epoch 3/15\n",
            "12724/12724 [==============================] - 4s 329us/step - loss: 0.3910 - acc: 0.8402 - auc: 0.6998\n",
            "Epoch 4/15\n",
            "12724/12724 [==============================] - 4s 331us/step - loss: 0.3498 - acc: 0.8631 - auc: 0.7788\n",
            "Epoch 5/15\n",
            "12724/12724 [==============================] - 4s 328us/step - loss: 0.3127 - acc: 0.8789 - auc: 0.8200\n",
            "Epoch 6/15\n",
            "12724/12724 [==============================] - 4s 331us/step - loss: 0.3031 - acc: 0.8879 - auc: 0.8456\n",
            "Epoch 7/15\n",
            "12724/12724 [==============================] - 4s 337us/step - loss: 0.2928 - acc: 0.8893 - auc: 0.8623\n",
            "Epoch 8/15\n",
            "12724/12724 [==============================] - 4s 335us/step - loss: 0.2809 - acc: 0.8950 - auc: 0.8748\n",
            "Epoch 9/15\n",
            "12724/12724 [==============================] - 4s 337us/step - loss: 0.2661 - acc: 0.9036 - auc: 0.8846\n",
            "Epoch 10/15\n",
            "12724/12724 [==============================] - 4s 332us/step - loss: 0.2598 - acc: 0.9037 - auc: 0.8927\n",
            "Epoch 11/15\n",
            "12724/12724 [==============================] - 4s 332us/step - loss: 0.2455 - acc: 0.9095 - auc: 0.8991\n",
            "Epoch 12/15\n",
            "12724/12724 [==============================] - 4s 327us/step - loss: 0.2328 - acc: 0.9147 - auc: 0.9047\n",
            "Epoch 13/15\n",
            "12724/12724 [==============================] - 4s 333us/step - loss: 0.2305 - acc: 0.9183 - auc: 0.9098\n",
            "Epoch 14/15\n",
            "12724/12724 [==============================] - 4s 325us/step - loss: 0.2263 - acc: 0.9188 - auc: 0.9142\n",
            "Epoch 15/15\n",
            "12724/12724 [==============================] - 4s 327us/step - loss: 0.2177 - acc: 0.9213 - auc: 0.9180\n",
            "3180/3180 [==============================] - 5s 2ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 16s 1ms/step - loss: 0.9003 - acc: 0.4455 - auc: 0.4972\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 4s 332us/step - loss: 0.8844 - acc: 0.4453 - auc: 0.4997\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 4s 332us/step - loss: 0.8841 - acc: 0.4454 - auc: 0.4998\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 4s 325us/step - loss: 0.8841 - acc: 0.4454 - auc: 0.4999\n",
            "Epoch 5/15\n",
            "12723/12723 [==============================] - 4s 325us/step - loss: 0.8841 - acc: 0.4454 - auc: 0.4999\n",
            "Epoch 6/15\n",
            "12723/12723 [==============================] - 4s 329us/step - loss: 0.8841 - acc: 0.4454 - auc: 0.4999\n",
            "Epoch 7/15\n",
            "12723/12723 [==============================] - 4s 326us/step - loss: 0.8841 - acc: 0.4454 - auc: 0.4999\n",
            "Epoch 8/15\n",
            "12723/12723 [==============================] - 4s 328us/step - loss: 0.8841 - acc: 0.4454 - auc: 0.4999\n",
            "Epoch 9/15\n",
            "12723/12723 [==============================] - 4s 326us/step - loss: 0.8113 - acc: 0.4442 - auc: 0.4999\n",
            "Epoch 10/15\n",
            "12723/12723 [==============================] - 4s 323us/step - loss: 0.1743 - acc: 0.4471 - auc: 0.4998\n",
            "Epoch 11/15\n",
            "12723/12723 [==============================] - 4s 326us/step - loss: 0.1739 - acc: 0.4471 - auc: 0.4998\n",
            "Epoch 12/15\n",
            "12723/12723 [==============================] - 4s 322us/step - loss: 0.1707 - acc: 0.4464 - auc: 0.4999\n",
            "Epoch 13/15\n",
            "12723/12723 [==============================] - 4s 324us/step - loss: 0.1704 - acc: 0.4472 - auc: 0.5005\n",
            "Epoch 14/15\n",
            "12723/12723 [==============================] - 4s 323us/step - loss: 0.1723 - acc: 0.4478 - auc: 0.5009\n",
            "Epoch 15/15\n",
            "12723/12723 [==============================] - 4s 328us/step - loss: 0.1721 - acc: 0.4486 - auc: 0.5009\n",
            "3181/3181 [==============================] - 6s 2ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 16s 1ms/step - loss: 0.1984 - acc: 0.4489 - auc: 0.5122\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 4s 331us/step - loss: 0.1745 - acc: 0.4471 - auc: 0.5144\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 4s 330us/step - loss: 0.1620 - acc: 0.4475 - auc: 0.5278\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 4s 324us/step - loss: 0.1251 - acc: 0.4515 - auc: 0.6147\n",
            "Epoch 5/15\n",
            "12723/12723 [==============================] - 4s 336us/step - loss: 0.1082 - acc: 0.4540 - auc: 0.7006\n",
            "Epoch 6/15\n",
            "12723/12723 [==============================] - 4s 332us/step - loss: 0.0991 - acc: 0.4857 - auc: 0.7571\n",
            "Epoch 7/15\n",
            "12723/12723 [==============================] - 4s 337us/step - loss: 0.0961 - acc: 0.5444 - auc: 0.7941\n",
            "Epoch 8/15\n",
            "12723/12723 [==============================] - 4s 332us/step - loss: 0.0905 - acc: 0.6340 - auc: 0.8209\n",
            "Epoch 9/15\n",
            "12723/12723 [==============================] - 4s 328us/step - loss: 0.0865 - acc: 0.6730 - auc: 0.8406\n",
            "Epoch 10/15\n",
            "12723/12723 [==============================] - 4s 343us/step - loss: 0.0862 - acc: 0.7098 - auc: 0.8558\n",
            "Epoch 11/15\n",
            "12723/12723 [==============================] - 4s 350us/step - loss: 0.0807 - acc: 0.7392 - auc: 0.8682\n",
            "Epoch 12/15\n",
            "12723/12723 [==============================] - 4s 349us/step - loss: 0.0730 - acc: 0.7817 - auc: 0.8788\n",
            "Epoch 13/15\n",
            "12723/12723 [==============================] - 4s 326us/step - loss: 0.0702 - acc: 0.8070 - auc: 0.8883\n",
            "Epoch 14/15\n",
            "12723/12723 [==============================] - 4s 323us/step - loss: 0.0675 - acc: 0.8221 - auc: 0.8962\n",
            "Epoch 15/15\n",
            "12723/12723 [==============================] - 4s 330us/step - loss: 0.0615 - acc: 0.8434 - auc: 0.9034\n",
            "3181/3181 [==============================] - 6s 2ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 16s 1ms/step - loss: 0.2101 - acc: 0.4476 - auc: 0.5126\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 4s 332us/step - loss: 0.1683 - acc: 0.4462 - auc: 0.5407\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 4s 332us/step - loss: 0.1423 - acc: 0.4474 - auc: 0.6112\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 4s 323us/step - loss: 0.1289 - acc: 0.4526 - auc: 0.6807\n",
            "Epoch 5/15\n",
            "12723/12723 [==============================] - 4s 324us/step - loss: 0.1188 - acc: 0.4526 - auc: 0.7318\n",
            "Epoch 6/15\n",
            "12723/12723 [==============================] - 4s 327us/step - loss: 0.1156 - acc: 0.4512 - auc: 0.7657\n",
            "Epoch 7/15\n",
            "12723/12723 [==============================] - 4s 323us/step - loss: 0.1096 - acc: 0.4534 - auc: 0.7909\n",
            "Epoch 8/15\n",
            "12723/12723 [==============================] - 4s 329us/step - loss: 0.1066 - acc: 0.4590 - auc: 0.8095\n",
            "Epoch 9/15\n",
            "12723/12723 [==============================] - 4s 330us/step - loss: 0.1039 - acc: 0.4619 - auc: 0.8241\n",
            "Epoch 10/15\n",
            "12723/12723 [==============================] - 4s 327us/step - loss: 0.1025 - acc: 0.4641 - auc: 0.8361\n",
            "Epoch 11/15\n",
            "12723/12723 [==============================] - 4s 333us/step - loss: 0.1053 - acc: 0.4901 - auc: 0.8454\n",
            "Epoch 12/15\n",
            "12723/12723 [==============================] - 4s 326us/step - loss: 0.0971 - acc: 0.5363 - auc: 0.8526\n",
            "Epoch 13/15\n",
            "12723/12723 [==============================] - 4s 323us/step - loss: 0.0956 - acc: 0.5903 - auc: 0.8601\n",
            "Epoch 14/15\n",
            "12723/12723 [==============================] - 4s 339us/step - loss: 0.0934 - acc: 0.6285 - auc: 0.8668\n",
            "Epoch 15/15\n",
            "12723/12723 [==============================] - 4s 328us/step - loss: 0.0906 - acc: 0.6770 - auc: 0.8727\n",
            "3181/3181 [==============================] - 6s 2ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 16s 1ms/step - loss: 0.2391 - acc: 0.4460 - auc: 0.4942\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 4s 337us/step - loss: 0.1750 - acc: 0.4498 - auc: 0.5005\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 4s 329us/step - loss: 0.1337 - acc: 0.4516 - auc: 0.5730\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 4s 338us/step - loss: 0.1169 - acc: 0.4507 - auc: 0.6866\n",
            "Epoch 5/15\n",
            "12723/12723 [==============================] - 4s 332us/step - loss: 0.1036 - acc: 0.4526 - auc: 0.7518\n",
            "Epoch 6/15\n",
            "12723/12723 [==============================] - 4s 325us/step - loss: 0.1001 - acc: 0.4581 - auc: 0.7937\n",
            "Epoch 7/15\n",
            "12723/12723 [==============================] - 4s 323us/step - loss: 0.0928 - acc: 0.5097 - auc: 0.8217\n",
            "Epoch 8/15\n",
            "12723/12723 [==============================] - 4s 324us/step - loss: 0.0877 - acc: 0.6348 - auc: 0.8432\n",
            "Epoch 9/15\n",
            "12723/12723 [==============================] - 4s 333us/step - loss: 0.0839 - acc: 0.7174 - auc: 0.8594\n",
            "Epoch 10/15\n",
            "12723/12723 [==============================] - 4s 337us/step - loss: 0.0789 - acc: 0.7617 - auc: 0.8727\n",
            "Epoch 11/15\n",
            "12723/12723 [==============================] - 4s 343us/step - loss: 0.0757 - acc: 0.7937 - auc: 0.8832\n",
            "Epoch 12/15\n",
            "12723/12723 [==============================] - 4s 340us/step - loss: 0.0708 - acc: 0.8177 - auc: 0.8925\n",
            "Epoch 13/15\n",
            "12723/12723 [==============================] - 4s 330us/step - loss: 0.0658 - acc: 0.8393 - auc: 0.9006\n",
            "Epoch 14/15\n",
            "12723/12723 [==============================] - 4s 329us/step - loss: 0.0614 - acc: 0.8451 - auc: 0.9075\n",
            "Epoch 15/15\n",
            "12723/12723 [==============================] - 4s 335us/step - loss: 0.0506 - acc: 0.8941 - auc: 0.9145\n",
            "3181/3181 [==============================] - 6s 2ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Epoch 1/15\n",
            "12724/12724 [==============================] - 16s 1ms/step - loss: 0.1880 - acc: 0.4498 - auc: 0.5123\n",
            "Epoch 2/15\n",
            "12724/12724 [==============================] - 4s 333us/step - loss: 0.1614 - acc: 0.4495 - auc: 0.5514\n",
            "Epoch 3/15\n",
            "12724/12724 [==============================] - 4s 323us/step - loss: 0.1184 - acc: 0.4533 - auc: 0.6725\n",
            "Epoch 4/15\n",
            "12724/12724 [==============================] - 4s 328us/step - loss: 0.1070 - acc: 0.4506 - auc: 0.7596\n",
            "Epoch 5/15\n",
            "12724/12724 [==============================] - 4s 330us/step - loss: 0.1014 - acc: 0.4580 - auc: 0.8063\n",
            "Epoch 6/15\n",
            "12724/12724 [==============================] - 4s 332us/step - loss: 0.0969 - acc: 0.5292 - auc: 0.8347\n",
            "Epoch 7/15\n",
            "12724/12724 [==============================] - 4s 343us/step - loss: 0.0953 - acc: 0.5690 - auc: 0.8529\n",
            "Epoch 8/15\n",
            "12724/12724 [==============================] - 4s 325us/step - loss: 0.0905 - acc: 0.6465 - auc: 0.8667\n",
            "Epoch 9/15\n",
            "12724/12724 [==============================] - 4s 330us/step - loss: 0.0880 - acc: 0.6844 - auc: 0.8779\n",
            "Epoch 10/15\n",
            "12724/12724 [==============================] - 4s 319us/step - loss: 0.0865 - acc: 0.7028 - auc: 0.8862\n",
            "Epoch 11/15\n",
            "12724/12724 [==============================] - 4s 322us/step - loss: 0.0830 - acc: 0.7388 - auc: 0.8934\n",
            "Epoch 12/15\n",
            "12724/12724 [==============================] - 4s 326us/step - loss: 0.0809 - acc: 0.7571 - auc: 0.8994\n",
            "Epoch 13/15\n",
            "12724/12724 [==============================] - 4s 336us/step - loss: 0.0777 - acc: 0.7786 - auc: 0.9050\n",
            "Epoch 14/15\n",
            "12724/12724 [==============================] - 4s 340us/step - loss: 0.0766 - acc: 0.7822 - auc: 0.9096\n",
            "Epoch 15/15\n",
            "12724/12724 [==============================] - 4s 349us/step - loss: 0.0716 - acc: 0.8136 - auc: 0.9142\n",
            "3180/3180 [==============================] - 6s 2ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Warstwa 3\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 17s 1ms/step - loss: 0.6602 - acc: 0.6205 - auc: 0.5422\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 4s 342us/step - loss: 0.4060 - acc: 0.8368 - auc: 0.7288\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 4s 342us/step - loss: 0.3414 - acc: 0.8668 - auc: 0.8140\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 4s 342us/step - loss: 0.3094 - acc: 0.8821 - auc: 0.8505\n",
            "Epoch 5/15\n",
            "12723/12723 [==============================] - 4s 340us/step - loss: 0.2953 - acc: 0.8891 - auc: 0.8708\n",
            "Epoch 6/15\n",
            "12723/12723 [==============================] - 4s 340us/step - loss: 0.2860 - acc: 0.8953 - auc: 0.8833\n",
            "Epoch 7/15\n",
            "12723/12723 [==============================] - 4s 346us/step - loss: 0.2708 - acc: 0.9013 - auc: 0.8928\n",
            "Epoch 8/15\n",
            "12723/12723 [==============================] - 4s 349us/step - loss: 0.2738 - acc: 0.8992 - auc: 0.8995\n",
            "Epoch 9/15\n",
            "12723/12723 [==============================] - 5s 391us/step - loss: 0.2540 - acc: 0.9113 - auc: 0.9049\n",
            "Epoch 10/15\n",
            "12723/12723 [==============================] - 5s 404us/step - loss: 0.2494 - acc: 0.9089 - auc: 0.9101\n",
            "Epoch 11/15\n",
            "12723/12723 [==============================] - 4s 348us/step - loss: 0.2424 - acc: 0.9137 - auc: 0.9137\n",
            "Epoch 12/15\n",
            "12723/12723 [==============================] - 4s 343us/step - loss: 0.2398 - acc: 0.9154 - auc: 0.9173\n",
            "Epoch 13/15\n",
            "12723/12723 [==============================] - 4s 336us/step - loss: 0.2363 - acc: 0.9156 - auc: 0.9201\n",
            "Epoch 14/15\n",
            "12723/12723 [==============================] - 4s 344us/step - loss: 0.2309 - acc: 0.9179 - auc: 0.9225\n",
            "Epoch 15/15\n",
            "12723/12723 [==============================] - 4s 340us/step - loss: 0.2387 - acc: 0.9161 - auc: 0.9248\n",
            "3181/3181 [==============================] - 6s 2ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Warstwa 3\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 17s 1ms/step - loss: 0.7079 - acc: 0.5464 - auc: 0.4848\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 4s 344us/step - loss: 0.6872 - acc: 0.5543 - auc: 0.5001\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 4s 345us/step - loss: 0.6091 - acc: 0.6708 - auc: 0.5324\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 4s 344us/step - loss: 0.4326 - acc: 0.8205 - auc: 0.6370\n",
            "Epoch 5/15\n",
            "12723/12723 [==============================] - 4s 343us/step - loss: 0.3656 - acc: 0.8512 - auc: 0.7180\n",
            "Epoch 6/15\n",
            "12723/12723 [==============================] - 4s 346us/step - loss: 0.3349 - acc: 0.8692 - auc: 0.7670\n",
            "Epoch 7/15\n",
            "12723/12723 [==============================] - 4s 351us/step - loss: 0.3151 - acc: 0.8807 - auc: 0.8006\n",
            "Epoch 8/15\n",
            "12723/12723 [==============================] - 4s 342us/step - loss: 0.3067 - acc: 0.8854 - auc: 0.8236\n",
            "Epoch 9/15\n",
            "12723/12723 [==============================] - 4s 346us/step - loss: 0.2947 - acc: 0.8915 - auc: 0.8406\n",
            "Epoch 10/15\n",
            "12723/12723 [==============================] - 4s 335us/step - loss: 0.2841 - acc: 0.8917 - auc: 0.8537\n",
            "Epoch 11/15\n",
            "12723/12723 [==============================] - 4s 347us/step - loss: 0.2796 - acc: 0.8972 - auc: 0.8641\n",
            "Epoch 12/15\n",
            "12723/12723 [==============================] - 5s 357us/step - loss: 0.2756 - acc: 0.8981 - auc: 0.8724\n",
            "Epoch 13/15\n",
            "12723/12723 [==============================] - 4s 352us/step - loss: 0.2686 - acc: 0.9014 - auc: 0.8793\n",
            "Epoch 14/15\n",
            "12723/12723 [==============================] - 4s 351us/step - loss: 0.2615 - acc: 0.9054 - auc: 0.8852\n",
            "Epoch 15/15\n",
            "12723/12723 [==============================] - 4s 348us/step - loss: 0.2543 - acc: 0.9069 - auc: 0.8905\n",
            "3181/3181 [==============================] - 6s 2ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Warstwa 3\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 17s 1ms/step - loss: 0.7023 - acc: 0.5454 - auc: 0.5024\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 5s 360us/step - loss: 0.6219 - acc: 0.6402 - auc: 0.5318\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 4s 351us/step - loss: 0.4286 - acc: 0.8167 - auc: 0.6668\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 5s 356us/step - loss: 0.3570 - acc: 0.8555 - auc: 0.7545\n",
            "Epoch 5/15\n",
            "12723/12723 [==============================] - 5s 360us/step - loss: 0.3261 - acc: 0.8731 - auc: 0.8035\n",
            "Epoch 6/15\n",
            "12723/12723 [==============================] - 5s 367us/step - loss: 0.3033 - acc: 0.8809 - auc: 0.8327\n",
            "Epoch 7/15\n",
            "12723/12723 [==============================] - 5s 360us/step - loss: 0.3064 - acc: 0.8824 - auc: 0.8518\n",
            "Epoch 8/15\n",
            "12723/12723 [==============================] - 5s 360us/step - loss: 0.3035 - acc: 0.8841 - auc: 0.8645\n",
            "Epoch 9/15\n",
            "12723/12723 [==============================] - 5s 367us/step - loss: 0.2789 - acc: 0.8931 - auc: 0.8747\n",
            "Epoch 10/15\n",
            "12723/12723 [==============================] - 5s 378us/step - loss: 0.2755 - acc: 0.8949 - auc: 0.8829\n",
            "Epoch 11/15\n",
            "12723/12723 [==============================] - 5s 370us/step - loss: 0.2653 - acc: 0.9022 - auc: 0.8896\n",
            "Epoch 12/15\n",
            "12723/12723 [==============================] - 5s 370us/step - loss: 0.2625 - acc: 0.9052 - auc: 0.8956\n",
            "Epoch 13/15\n",
            "12723/12723 [==============================] - 5s 363us/step - loss: 0.2592 - acc: 0.9024 - auc: 0.9001\n",
            "Epoch 14/15\n",
            "12723/12723 [==============================] - 5s 358us/step - loss: 0.2556 - acc: 0.9065 - auc: 0.9043\n",
            "Epoch 15/15\n",
            "12723/12723 [==============================] - 5s 373us/step - loss: 0.2547 - acc: 0.9076 - auc: 0.9077\n",
            "3181/3181 [==============================] - 6s 2ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Warstwa 3\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 18s 1ms/step - loss: 0.7188 - acc: 0.5456 - auc: 0.5008\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 5s 363us/step - loss: 0.6863 - acc: 0.5668 - auc: 0.5144\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 5s 370us/step - loss: 0.4845 - acc: 0.7839 - auc: 0.5941\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 5s 372us/step - loss: 0.3765 - acc: 0.8463 - auc: 0.7068\n",
            "Epoch 5/15\n",
            "12723/12723 [==============================] - 5s 367us/step - loss: 0.3295 - acc: 0.8737 - auc: 0.7703\n",
            "Epoch 6/15\n",
            "12723/12723 [==============================] - 5s 369us/step - loss: 0.3064 - acc: 0.8834 - auc: 0.8092\n",
            "Epoch 7/15\n",
            "12723/12723 [==============================] - 5s 372us/step - loss: 0.2995 - acc: 0.8869 - auc: 0.8341\n",
            "Epoch 8/15\n",
            "12723/12723 [==============================] - 5s 360us/step - loss: 0.2875 - acc: 0.8950 - auc: 0.8515\n",
            "Epoch 9/15\n",
            "12723/12723 [==============================] - 5s 365us/step - loss: 0.2769 - acc: 0.8978 - auc: 0.8645\n",
            "Epoch 10/15\n",
            "12723/12723 [==============================] - 5s 365us/step - loss: 0.2719 - acc: 0.9020 - auc: 0.8744\n",
            "Epoch 11/15\n",
            "12723/12723 [==============================] - 5s 370us/step - loss: 0.2690 - acc: 0.9002 - auc: 0.8818\n",
            "Epoch 12/15\n",
            "12723/12723 [==============================] - 5s 358us/step - loss: 0.2622 - acc: 0.9042 - auc: 0.8886\n",
            "Epoch 13/15\n",
            "12723/12723 [==============================] - 5s 372us/step - loss: 0.2530 - acc: 0.9084 - auc: 0.8943\n",
            "Epoch 14/15\n",
            "12723/12723 [==============================] - 5s 372us/step - loss: 0.2431 - acc: 0.9131 - auc: 0.8994\n",
            "Epoch 15/15\n",
            "12723/12723 [==============================] - 5s 367us/step - loss: 0.2335 - acc: 0.9153 - auc: 0.9040\n",
            "3181/3181 [==============================] - 6s 2ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Warstwa 3\n",
            "Epoch 1/15\n",
            "12724/12724 [==============================] - 18s 1ms/step - loss: 0.6438 - acc: 0.6339 - auc: 0.5444\n",
            "Epoch 2/15\n",
            "12724/12724 [==============================] - 5s 368us/step - loss: 0.4205 - acc: 0.8280 - auc: 0.7326\n",
            "Epoch 3/15\n",
            "12724/12724 [==============================] - 5s 363us/step - loss: 0.3451 - acc: 0.8673 - auc: 0.8144\n",
            "Epoch 4/15\n",
            "12724/12724 [==============================] - 5s 376us/step - loss: 0.3174 - acc: 0.8791 - auc: 0.8503\n",
            "Epoch 5/15\n",
            "12724/12724 [==============================] - 5s 371us/step - loss: 0.2984 - acc: 0.8893 - auc: 0.8708\n",
            "Epoch 6/15\n",
            "12724/12724 [==============================] - 5s 368us/step - loss: 0.2966 - acc: 0.8891 - auc: 0.8830\n",
            "Epoch 7/15\n",
            "12724/12724 [==============================] - 5s 364us/step - loss: 0.2794 - acc: 0.8982 - auc: 0.8916\n",
            "Epoch 8/15\n",
            "12724/12724 [==============================] - 5s 365us/step - loss: 0.2767 - acc: 0.8991 - auc: 0.8988\n",
            "Epoch 9/15\n",
            "12724/12724 [==============================] - 5s 377us/step - loss: 0.2646 - acc: 0.9040 - auc: 0.9038\n",
            "Epoch 10/15\n",
            "12724/12724 [==============================] - 5s 371us/step - loss: 0.2581 - acc: 0.9047 - auc: 0.9085\n",
            "Epoch 11/15\n",
            "12724/12724 [==============================] - 5s 378us/step - loss: 0.2516 - acc: 0.9097 - auc: 0.9126\n",
            "Epoch 12/15\n",
            "12724/12724 [==============================] - 5s 372us/step - loss: 0.2490 - acc: 0.9079 - auc: 0.9159\n",
            "Epoch 13/15\n",
            "12724/12724 [==============================] - 5s 367us/step - loss: 0.2411 - acc: 0.9128 - auc: 0.9188\n",
            "Epoch 14/15\n",
            "12724/12724 [==============================] - 5s 371us/step - loss: 0.2316 - acc: 0.9162 - auc: 0.9217\n",
            "Epoch 15/15\n",
            "12724/12724 [==============================] - 5s 381us/step - loss: 0.2313 - acc: 0.9165 - auc: 0.9242\n",
            "3180/3180 [==============================] - 7s 2ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Warstwa 3\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 19s 1ms/step - loss: 0.1771 - acc: 0.4467 - auc: 0.5226\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 5s 366us/step - loss: 0.1431 - acc: 0.4454 - auc: 0.5907\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 5s 372us/step - loss: 0.1128 - acc: 0.4453 - auc: 0.7251\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 5s 374us/step - loss: 0.1007 - acc: 0.4481 - auc: 0.7964\n",
            "Epoch 5/15\n",
            "12723/12723 [==============================] - 5s 380us/step - loss: 0.0961 - acc: 0.4822 - auc: 0.8353\n",
            "Epoch 6/15\n",
            "12723/12723 [==============================] - 5s 379us/step - loss: 0.0917 - acc: 0.5970 - auc: 0.8583\n",
            "Epoch 7/15\n",
            "12723/12723 [==============================] - 5s 381us/step - loss: 0.0896 - acc: 0.6430 - auc: 0.8735\n",
            "Epoch 8/15\n",
            "12723/12723 [==============================] - 5s 372us/step - loss: 0.0877 - acc: 0.6927 - auc: 0.8846\n",
            "Epoch 9/15\n",
            "12723/12723 [==============================] - 5s 374us/step - loss: 0.0867 - acc: 0.7044 - auc: 0.8933\n",
            "Epoch 10/15\n",
            "12723/12723 [==============================] - 5s 378us/step - loss: 0.0841 - acc: 0.7468 - auc: 0.9000\n",
            "Epoch 11/15\n",
            "12723/12723 [==============================] - 5s 380us/step - loss: 0.0836 - acc: 0.7459 - auc: 0.9053\n",
            "Epoch 12/15\n",
            "12723/12723 [==============================] - 5s 406us/step - loss: 0.0804 - acc: 0.7677 - auc: 0.9097\n",
            "Epoch 13/15\n",
            "12723/12723 [==============================] - 5s 387us/step - loss: 0.0815 - acc: 0.7632 - auc: 0.9137\n",
            "Epoch 14/15\n",
            "12723/12723 [==============================] - 5s 373us/step - loss: 0.0799 - acc: 0.7660 - auc: 0.9169\n",
            "Epoch 15/15\n",
            "12723/12723 [==============================] - 5s 377us/step - loss: 0.0780 - acc: 0.7759 - auc: 0.9198\n",
            "3181/3181 [==============================] - 7s 2ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Warstwa 3\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 20s 2ms/step - loss: 0.1781 - acc: 0.4469 - auc: 0.5097\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 5s 385us/step - loss: 0.1532 - acc: 0.4454 - auc: 0.5653\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 5s 378us/step - loss: 0.1142 - acc: 0.4490 - auc: 0.6910\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 5s 379us/step - loss: 0.1052 - acc: 0.4487 - auc: 0.7736\n",
            "Epoch 5/15\n",
            "12723/12723 [==============================] - 5s 394us/step - loss: 0.0994 - acc: 0.4552 - auc: 0.8162\n",
            "Epoch 6/15\n",
            "12723/12723 [==============================] - 5s 387us/step - loss: 0.0996 - acc: 0.4662 - auc: 0.8425\n",
            "Epoch 7/15\n",
            "12723/12723 [==============================] - 5s 384us/step - loss: 0.1006 - acc: 0.4647 - auc: 0.8564\n",
            "Epoch 8/15\n",
            "12723/12723 [==============================] - 5s 382us/step - loss: 0.0951 - acc: 0.5755 - auc: 0.8678\n",
            "Epoch 9/15\n",
            "12723/12723 [==============================] - 5s 378us/step - loss: 0.0944 - acc: 0.5930 - auc: 0.8763\n",
            "Epoch 10/15\n",
            "12723/12723 [==============================] - 5s 380us/step - loss: 0.0924 - acc: 0.6358 - auc: 0.8832\n",
            "Epoch 11/15\n",
            "12723/12723 [==============================] - 5s 381us/step - loss: 0.0912 - acc: 0.6535 - auc: 0.8889\n",
            "Epoch 12/15\n",
            "12723/12723 [==============================] - 5s 391us/step - loss: 0.0881 - acc: 0.7006 - auc: 0.8937\n",
            "Epoch 13/15\n",
            "12723/12723 [==============================] - 5s 385us/step - loss: 0.0888 - acc: 0.7017 - auc: 0.8981\n",
            "Epoch 14/15\n",
            "12723/12723 [==============================] - 5s 386us/step - loss: 0.0881 - acc: 0.7159 - auc: 0.9017\n",
            "Epoch 15/15\n",
            "12723/12723 [==============================] - 5s 392us/step - loss: 0.0862 - acc: 0.7134 - auc: 0.9047\n",
            "3181/3181 [==============================] - 7s 2ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Warstwa 3\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 20s 2ms/step - loss: 0.1982 - acc: 0.4486 - auc: 0.4996\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 5s 389us/step - loss: 0.1743 - acc: 0.4488 - auc: 0.5173\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 5s 394us/step - loss: 0.1748 - acc: 0.4484 - auc: 0.5204\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 5s 384us/step - loss: 0.1697 - acc: 0.4469 - auc: 0.5251\n",
            "Epoch 5/15\n",
            "12723/12723 [==============================] - 5s 385us/step - loss: 0.1561 - acc: 0.4467 - auc: 0.5433\n",
            "Epoch 6/15\n",
            "12723/12723 [==============================] - 5s 394us/step - loss: 0.1609 - acc: 0.4485 - auc: 0.5803\n",
            "Epoch 7/15\n",
            "12723/12723 [==============================] - 5s 384us/step - loss: 0.1515 - acc: 0.4464 - auc: 0.5969\n",
            "Epoch 8/15\n",
            "12723/12723 [==============================] - 5s 392us/step - loss: 0.1418 - acc: 0.4454 - auc: 0.6214\n",
            "Epoch 9/15\n",
            "12723/12723 [==============================] - 5s 380us/step - loss: 0.1333 - acc: 0.4454 - auc: 0.6489\n",
            "Epoch 10/15\n",
            "12723/12723 [==============================] - 5s 387us/step - loss: 0.1240 - acc: 0.4454 - auc: 0.6759\n",
            "Epoch 11/15\n",
            "12723/12723 [==============================] - 5s 383us/step - loss: 0.1205 - acc: 0.4454 - auc: 0.7005\n",
            "Epoch 12/15\n",
            "12723/12723 [==============================] - 5s 392us/step - loss: 0.1145 - acc: 0.4460 - auc: 0.7223\n",
            "Epoch 13/15\n",
            "12723/12723 [==============================] - 5s 389us/step - loss: 0.1102 - acc: 0.4457 - auc: 0.7423\n",
            "Epoch 14/15\n",
            "12723/12723 [==============================] - 5s 391us/step - loss: 0.1090 - acc: 0.4512 - auc: 0.7591\n",
            "Epoch 15/15\n",
            "12723/12723 [==============================] - 5s 390us/step - loss: 0.1064 - acc: 0.4541 - auc: 0.7736\n",
            "3181/3181 [==============================] - 7s 2ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Warstwa 3\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 20s 2ms/step - loss: 0.1758 - acc: 0.4479 - auc: 0.5265\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 5s 399us/step - loss: 0.1532 - acc: 0.4464 - auc: 0.5869\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 5s 397us/step - loss: 0.1256 - acc: 0.4493 - auc: 0.6892\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 5s 411us/step - loss: 0.1132 - acc: 0.4479 - auc: 0.7590\n",
            "Epoch 5/15\n",
            "12723/12723 [==============================] - 5s 404us/step - loss: 0.1055 - acc: 0.4523 - auc: 0.8005\n",
            "Epoch 6/15\n",
            "12723/12723 [==============================] - 5s 395us/step - loss: 0.1018 - acc: 0.4658 - auc: 0.8276\n",
            "Epoch 7/15\n",
            "12723/12723 [==============================] - 5s 387us/step - loss: 0.0969 - acc: 0.5040 - auc: 0.8462\n",
            "Epoch 8/15\n",
            "12723/12723 [==============================] - 5s 395us/step - loss: 0.0947 - acc: 0.6171 - auc: 0.8603\n",
            "Epoch 9/15\n",
            "12723/12723 [==============================] - 5s 408us/step - loss: 0.0933 - acc: 0.6514 - auc: 0.8707\n",
            "Epoch 10/15\n",
            "12723/12723 [==============================] - 5s 380us/step - loss: 0.0904 - acc: 0.6777 - auc: 0.8789\n",
            "Epoch 11/15\n",
            "12723/12723 [==============================] - 5s 392us/step - loss: 0.0908 - acc: 0.6785 - auc: 0.8859\n",
            "Epoch 12/15\n",
            "12723/12723 [==============================] - 5s 387us/step - loss: 0.0901 - acc: 0.7150 - auc: 0.8915\n",
            "Epoch 13/15\n",
            "12723/12723 [==============================] - 5s 401us/step - loss: 0.0859 - acc: 0.7356 - auc: 0.8965\n",
            "Epoch 14/15\n",
            "12723/12723 [==============================] - 5s 396us/step - loss: 0.0843 - acc: 0.7604 - auc: 0.9009\n",
            "Epoch 15/15\n",
            "12723/12723 [==============================] - 5s 392us/step - loss: 0.0862 - acc: 0.7549 - auc: 0.9046\n",
            "3181/3181 [==============================] - 7s 2ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Warstwa 3\n",
            "Epoch 1/15\n",
            "12724/12724 [==============================] - 20s 2ms/step - loss: 0.1751 - acc: 0.4475 - auc: 0.5333\n",
            "Epoch 2/15\n",
            "12724/12724 [==============================] - 5s 385us/step - loss: 0.1340 - acc: 0.4473 - auc: 0.6586\n",
            "Epoch 3/15\n",
            "12724/12724 [==============================] - 5s 396us/step - loss: 0.1113 - acc: 0.4500 - auc: 0.7612\n",
            "Epoch 4/15\n",
            "12724/12724 [==============================] - 5s 393us/step - loss: 0.1013 - acc: 0.4499 - auc: 0.8170\n",
            "Epoch 5/15\n",
            "12724/12724 [==============================] - 5s 394us/step - loss: 0.0963 - acc: 0.4767 - auc: 0.8469\n",
            "Epoch 6/15\n",
            "12724/12724 [==============================] - 5s 396us/step - loss: 0.0923 - acc: 0.6202 - auc: 0.8667\n",
            "Epoch 7/15\n",
            "12724/12724 [==============================] - 5s 389us/step - loss: 0.0893 - acc: 0.6546 - auc: 0.8797\n",
            "Epoch 8/15\n",
            "12724/12724 [==============================] - 5s 396us/step - loss: 0.0881 - acc: 0.6870 - auc: 0.8894\n",
            "Epoch 9/15\n",
            "12724/12724 [==============================] - 5s 389us/step - loss: 0.0850 - acc: 0.7449 - auc: 0.8970\n",
            "Epoch 10/15\n",
            "12724/12724 [==============================] - 5s 386us/step - loss: 0.0845 - acc: 0.7409 - auc: 0.9030\n",
            "Epoch 11/15\n",
            "12724/12724 [==============================] - 5s 395us/step - loss: 0.0828 - acc: 0.7677 - auc: 0.9082\n",
            "Epoch 12/15\n",
            "12724/12724 [==============================] - 5s 398us/step - loss: 0.0806 - acc: 0.7733 - auc: 0.9125\n",
            "Epoch 13/15\n",
            "12724/12724 [==============================] - 5s 383us/step - loss: 0.0793 - acc: 0.7818 - auc: 0.9161\n",
            "Epoch 14/15\n",
            "12724/12724 [==============================] - 5s 387us/step - loss: 0.0781 - acc: 0.7925 - auc: 0.9194\n",
            "Epoch 15/15\n",
            "12724/12724 [==============================] - 5s 389us/step - loss: 0.0764 - acc: 0.8023 - auc: 0.9223\n",
            "3180/3180 [==============================] - 7s 2ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 18s 1ms/step - loss: 0.7630 - acc: 0.6276 - auc: 0.5588\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 3s 199us/step - loss: 0.5091 - acc: 0.7622 - auc: 0.6956\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 3s 207us/step - loss: 0.4432 - acc: 0.8023 - auc: 0.7498\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 3s 215us/step - loss: 0.3984 - acc: 0.8321 - auc: 0.7871\n",
            "Epoch 5/15\n",
            "12723/12723 [==============================] - 3s 206us/step - loss: 0.3717 - acc: 0.8478 - auc: 0.8124\n",
            "Epoch 6/15\n",
            "12723/12723 [==============================] - 3s 205us/step - loss: 0.3471 - acc: 0.8602 - auc: 0.8308\n",
            "Epoch 7/15\n",
            "12723/12723 [==============================] - 3s 206us/step - loss: 0.3245 - acc: 0.8710 - auc: 0.8451\n",
            "Epoch 8/15\n",
            "12723/12723 [==============================] - 3s 211us/step - loss: 0.3108 - acc: 0.8772 - auc: 0.8569\n",
            "Epoch 9/15\n",
            "12723/12723 [==============================] - 3s 208us/step - loss: 0.2859 - acc: 0.8899 - auc: 0.8667\n",
            "Epoch 10/15\n",
            "12723/12723 [==============================] - 3s 206us/step - loss: 0.2675 - acc: 0.8979 - auc: 0.8758\n",
            "Epoch 11/15\n",
            "12723/12723 [==============================] - 3s 210us/step - loss: 0.2607 - acc: 0.9013 - auc: 0.8835\n",
            "Epoch 12/15\n",
            "12723/12723 [==============================] - 3s 200us/step - loss: 0.2542 - acc: 0.9059 - auc: 0.8901\n",
            "Epoch 13/15\n",
            "12723/12723 [==============================] - 3s 204us/step - loss: 0.2432 - acc: 0.9080 - auc: 0.8960\n",
            "Epoch 14/15\n",
            "12723/12723 [==============================] - 3s 201us/step - loss: 0.2367 - acc: 0.9131 - auc: 0.9010\n",
            "Epoch 15/15\n",
            "12723/12723 [==============================] - 3s 204us/step - loss: 0.2201 - acc: 0.9211 - auc: 0.9058\n",
            "3181/3181 [==============================] - 7s 2ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 18s 1ms/step - loss: 0.8042 - acc: 0.5674 - auc: 0.5247\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 3s 221us/step - loss: 0.5170 - acc: 0.7596 - auc: 0.6335\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 3s 230us/step - loss: 0.4056 - acc: 0.8299 - auc: 0.7424\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 3s 227us/step - loss: 0.3676 - acc: 0.8515 - auc: 0.7943\n",
            "Epoch 5/15\n",
            "12723/12723 [==============================] - 3s 217us/step - loss: 0.3394 - acc: 0.8656 - auc: 0.8251\n",
            "Epoch 6/15\n",
            "12723/12723 [==============================] - 3s 217us/step - loss: 0.3193 - acc: 0.8743 - auc: 0.8453\n",
            "Epoch 7/15\n",
            "12723/12723 [==============================] - 3s 210us/step - loss: 0.2997 - acc: 0.8824 - auc: 0.8598\n",
            "Epoch 8/15\n",
            "12723/12723 [==============================] - 3s 208us/step - loss: 0.2941 - acc: 0.8881 - auc: 0.8715\n",
            "Epoch 9/15\n",
            "12723/12723 [==============================] - 3s 206us/step - loss: 0.2711 - acc: 0.8992 - auc: 0.8805\n",
            "Epoch 10/15\n",
            "12723/12723 [==============================] - 3s 208us/step - loss: 0.2516 - acc: 0.9082 - auc: 0.8889\n",
            "Epoch 11/15\n",
            "12723/12723 [==============================] - 3s 210us/step - loss: 0.2471 - acc: 0.9092 - auc: 0.8964\n",
            "Epoch 12/15\n",
            "12723/12723 [==============================] - 3s 218us/step - loss: 0.2421 - acc: 0.9124 - auc: 0.9020\n",
            "Epoch 13/15\n",
            "12723/12723 [==============================] - 3s 211us/step - loss: 0.2108 - acc: 0.9236 - auc: 0.9077\n",
            "Epoch 14/15\n",
            "12723/12723 [==============================] - 3s 210us/step - loss: 0.2046 - acc: 0.9234 - auc: 0.9131\n",
            "Epoch 15/15\n",
            "12723/12723 [==============================] - 3s 204us/step - loss: 0.1880 - acc: 0.9336 - auc: 0.9181\n",
            "3181/3181 [==============================] - 7s 2ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 18s 1ms/step - loss: 0.9977 - acc: 0.5594 - auc: 0.5132\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 3s 217us/step - loss: 0.6404 - acc: 0.6384 - auc: 0.5680\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 3s 210us/step - loss: 0.5621 - acc: 0.7086 - auc: 0.6297\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 3s 214us/step - loss: 0.4997 - acc: 0.7616 - auc: 0.6805\n",
            "Epoch 5/15\n",
            "12723/12723 [==============================] - 3s 211us/step - loss: 0.4375 - acc: 0.8040 - auc: 0.7214\n",
            "Epoch 6/15\n",
            "12723/12723 [==============================] - 3s 212us/step - loss: 0.4219 - acc: 0.8136 - auc: 0.7519\n",
            "Epoch 7/15\n",
            "12723/12723 [==============================] - 3s 217us/step - loss: 0.3793 - acc: 0.8410 - auc: 0.7766\n",
            "Epoch 8/15\n",
            "12723/12723 [==============================] - 3s 215us/step - loss: 0.3631 - acc: 0.8514 - auc: 0.7956\n",
            "Epoch 9/15\n",
            "12723/12723 [==============================] - 3s 218us/step - loss: 0.3507 - acc: 0.8549 - auc: 0.8114\n",
            "Epoch 10/15\n",
            "12723/12723 [==============================] - 3s 211us/step - loss: 0.3360 - acc: 0.8666 - auc: 0.8238\n",
            "Epoch 11/15\n",
            "12723/12723 [==============================] - 3s 211us/step - loss: 0.3207 - acc: 0.8759 - auc: 0.8345\n",
            "Epoch 12/15\n",
            "12723/12723 [==============================] - 3s 209us/step - loss: 0.3019 - acc: 0.8816 - auc: 0.8443\n",
            "Epoch 13/15\n",
            "12723/12723 [==============================] - 3s 213us/step - loss: 0.2952 - acc: 0.8863 - auc: 0.8530\n",
            "Epoch 14/15\n",
            "12723/12723 [==============================] - 3s 217us/step - loss: 0.2840 - acc: 0.8907 - auc: 0.8605\n",
            "Epoch 15/15\n",
            "12723/12723 [==============================] - 3s 210us/step - loss: 0.2729 - acc: 0.8968 - auc: 0.8675\n",
            "3181/3181 [==============================] - 7s 2ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 19s 1ms/step - loss: 0.6749 - acc: 0.6304 - auc: 0.5531\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 3s 206us/step - loss: 0.4740 - acc: 0.7895 - auc: 0.7127\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 3s 208us/step - loss: 0.4057 - acc: 0.8235 - auc: 0.7788\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 3s 216us/step - loss: 0.3733 - acc: 0.8438 - auc: 0.8146\n",
            "Epoch 5/15\n",
            "12723/12723 [==============================] - 3s 212us/step - loss: 0.3443 - acc: 0.8610 - auc: 0.8371\n",
            "Epoch 6/15\n",
            "12723/12723 [==============================] - 3s 207us/step - loss: 0.3250 - acc: 0.8698 - auc: 0.8524\n",
            "Epoch 7/15\n",
            "12723/12723 [==============================] - 3s 206us/step - loss: 0.3104 - acc: 0.8774 - auc: 0.8645\n",
            "Epoch 8/15\n",
            "12723/12723 [==============================] - 3s 212us/step - loss: 0.2883 - acc: 0.8889 - auc: 0.8746\n",
            "Epoch 9/15\n",
            "12723/12723 [==============================] - 3s 219us/step - loss: 0.2759 - acc: 0.8936 - auc: 0.8834\n",
            "Epoch 10/15\n",
            "12723/12723 [==============================] - 3s 207us/step - loss: 0.2651 - acc: 0.9005 - auc: 0.8906\n",
            "Epoch 11/15\n",
            "12723/12723 [==============================] - 3s 217us/step - loss: 0.2469 - acc: 0.9054 - auc: 0.8971\n",
            "Epoch 12/15\n",
            "12723/12723 [==============================] - 3s 222us/step - loss: 0.2313 - acc: 0.9139 - auc: 0.9032\n",
            "Epoch 13/15\n",
            "12723/12723 [==============================] - 3s 227us/step - loss: 0.2142 - acc: 0.9206 - auc: 0.9092\n",
            "Epoch 14/15\n",
            "12723/12723 [==============================] - 3s 223us/step - loss: 0.1943 - acc: 0.9295 - auc: 0.9146\n",
            "Epoch 15/15\n",
            "12723/12723 [==============================] - 3s 222us/step - loss: 0.1804 - acc: 0.9342 - auc: 0.9198\n",
            "3181/3181 [==============================] - 7s 2ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Epoch 1/15\n",
            "12724/12724 [==============================] - 19s 2ms/step - loss: 0.7416 - acc: 0.6048 - auc: 0.5246\n",
            "Epoch 2/15\n",
            "12724/12724 [==============================] - 3s 208us/step - loss: 0.5087 - acc: 0.7646 - auc: 0.6703\n",
            "Epoch 3/15\n",
            "12724/12724 [==============================] - 3s 211us/step - loss: 0.4441 - acc: 0.8032 - auc: 0.7460\n",
            "Epoch 4/15\n",
            "12724/12724 [==============================] - 3s 213us/step - loss: 0.3914 - acc: 0.8360 - auc: 0.7851\n",
            "Epoch 5/15\n",
            "12724/12724 [==============================] - 3s 213us/step - loss: 0.3837 - acc: 0.8389 - auc: 0.8107\n",
            "Epoch 6/15\n",
            "12724/12724 [==============================] - 3s 204us/step - loss: 0.3563 - acc: 0.8563 - auc: 0.8283\n",
            "Epoch 7/15\n",
            "12724/12724 [==============================] - 3s 207us/step - loss: 0.3455 - acc: 0.8612 - auc: 0.8417\n",
            "Epoch 8/15\n",
            "12724/12724 [==============================] - 3s 207us/step - loss: 0.3344 - acc: 0.8649 - auc: 0.8521\n",
            "Epoch 9/15\n",
            "12724/12724 [==============================] - 3s 211us/step - loss: 0.3320 - acc: 0.8680 - auc: 0.8603\n",
            "Epoch 10/15\n",
            "12724/12724 [==============================] - 3s 214us/step - loss: 0.3115 - acc: 0.8797 - auc: 0.8668\n",
            "Epoch 11/15\n",
            "12724/12724 [==============================] - 3s 221us/step - loss: 0.3009 - acc: 0.8844 - auc: 0.8735\n",
            "Epoch 12/15\n",
            "12724/12724 [==============================] - 3s 213us/step - loss: 0.2943 - acc: 0.8860 - auc: 0.8791\n",
            "Epoch 13/15\n",
            "12724/12724 [==============================] - 3s 218us/step - loss: 0.2907 - acc: 0.8904 - auc: 0.8841\n",
            "Epoch 14/15\n",
            "12724/12724 [==============================] - 3s 212us/step - loss: 0.2763 - acc: 0.8956 - auc: 0.8885\n",
            "Epoch 15/15\n",
            "12724/12724 [==============================] - 3s 216us/step - loss: 0.2708 - acc: 0.8959 - auc: 0.8927\n",
            "3180/3180 [==============================] - 7s 2ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 19s 2ms/step - loss: 0.1983 - acc: 0.4468 - auc: 0.4996\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 3s 209us/step - loss: 0.1433 - acc: 0.4503 - auc: 0.5937\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 3s 208us/step - loss: 0.1225 - acc: 0.4539 - auc: 0.7120\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 3s 213us/step - loss: 0.1098 - acc: 0.4658 - auc: 0.7757\n",
            "Epoch 5/15\n",
            "12723/12723 [==============================] - 3s 206us/step - loss: 0.1037 - acc: 0.4947 - auc: 0.8124\n",
            "Epoch 6/15\n",
            "12723/12723 [==============================] - 3s 212us/step - loss: 0.0967 - acc: 0.5383 - auc: 0.8373\n",
            "Epoch 7/15\n",
            "12723/12723 [==============================] - 3s 209us/step - loss: 0.0931 - acc: 0.5950 - auc: 0.8558\n",
            "Epoch 8/15\n",
            "12723/12723 [==============================] - 3s 207us/step - loss: 0.0875 - acc: 0.6613 - auc: 0.8692\n",
            "Epoch 9/15\n",
            "12723/12723 [==============================] - 3s 211us/step - loss: 0.0824 - acc: 0.7035 - auc: 0.8807\n",
            "Epoch 10/15\n",
            "12723/12723 [==============================] - 3s 224us/step - loss: 0.0772 - acc: 0.7521 - auc: 0.8905\n",
            "Epoch 11/15\n",
            "12723/12723 [==============================] - 3s 225us/step - loss: 0.0732 - acc: 0.7822 - auc: 0.8992\n",
            "Epoch 12/15\n",
            "12723/12723 [==============================] - 3s 216us/step - loss: 0.0688 - acc: 0.7981 - auc: 0.9059\n",
            "Epoch 13/15\n",
            "12723/12723 [==============================] - 3s 223us/step - loss: 0.0623 - acc: 0.8292 - auc: 0.9130\n",
            "Epoch 14/15\n",
            "12723/12723 [==============================] - 3s 224us/step - loss: 0.0549 - acc: 0.8603 - auc: 0.9188\n",
            "Epoch 15/15\n",
            "12723/12723 [==============================] - 3s 216us/step - loss: 0.0471 - acc: 0.8852 - auc: 0.9250\n",
            "3181/3181 [==============================] - 8s 2ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 20s 2ms/step - loss: 0.8956 - acc: 0.4461 - auc: 0.5009\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 3s 213us/step - loss: 0.8841 - acc: 0.4454 - auc: 0.5004\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 3s 210us/step - loss: 0.3433 - acc: 0.4520 - auc: 0.5015\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 3s 211us/step - loss: 0.1559 - acc: 0.4527 - auc: 0.5151\n",
            "Epoch 5/15\n",
            "12723/12723 [==============================] - 3s 218us/step - loss: 0.1303 - acc: 0.4512 - auc: 0.5653\n",
            "Epoch 6/15\n",
            "12723/12723 [==============================] - 3s 214us/step - loss: 0.1195 - acc: 0.4518 - auc: 0.6181\n",
            "Epoch 7/15\n",
            "12723/12723 [==============================] - 3s 210us/step - loss: 0.1119 - acc: 0.4519 - auc: 0.6603\n",
            "Epoch 8/15\n",
            "12723/12723 [==============================] - 3s 208us/step - loss: 0.1060 - acc: 0.4551 - auc: 0.6938\n",
            "Epoch 9/15\n",
            "12723/12723 [==============================] - 3s 202us/step - loss: 0.1036 - acc: 0.4623 - auc: 0.7206\n",
            "Epoch 10/15\n",
            "12723/12723 [==============================] - 3s 216us/step - loss: 0.1011 - acc: 0.5087 - auc: 0.7422\n",
            "Epoch 11/15\n",
            "12723/12723 [==============================] - 3s 219us/step - loss: 0.0998 - acc: 0.5369 - auc: 0.7600\n",
            "Epoch 12/15\n",
            "12723/12723 [==============================] - 3s 207us/step - loss: 0.0955 - acc: 0.6061 - auc: 0.7756\n",
            "Epoch 13/15\n",
            "12723/12723 [==============================] - 3s 199us/step - loss: 0.0949 - acc: 0.6084 - auc: 0.7885\n",
            "Epoch 14/15\n",
            "12723/12723 [==============================] - 3s 212us/step - loss: 0.0913 - acc: 0.6572 - auc: 0.7999\n",
            "Epoch 15/15\n",
            "12723/12723 [==============================] - 3s 206us/step - loss: 0.0904 - acc: 0.6618 - auc: 0.8098\n",
            "3181/3181 [==============================] - 8s 2ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 20s 2ms/step - loss: 0.1866 - acc: 0.4491 - auc: 0.5041\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 3s 210us/step - loss: 0.1733 - acc: 0.4475 - auc: 0.5249\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 3s 206us/step - loss: 0.1707 - acc: 0.4471 - auc: 0.5390\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 3s 206us/step - loss: 0.1651 - acc: 0.4479 - auc: 0.5552\n",
            "Epoch 5/15\n",
            "12723/12723 [==============================] - 3s 213us/step - loss: 0.1641 - acc: 0.4490 - auc: 0.5713\n",
            "Epoch 6/15\n",
            "12723/12723 [==============================] - 3s 225us/step - loss: 0.1614 - acc: 0.4484 - auc: 0.5842\n",
            "Epoch 7/15\n",
            "12723/12723 [==============================] - 3s 211us/step - loss: 0.1610 - acc: 0.4502 - auc: 0.5947\n",
            "Epoch 8/15\n",
            "12723/12723 [==============================] - 3s 206us/step - loss: 0.1618 - acc: 0.4497 - auc: 0.6034\n",
            "Epoch 9/15\n",
            "12723/12723 [==============================] - 3s 211us/step - loss: 0.1572 - acc: 0.4522 - auc: 0.6103\n",
            "Epoch 10/15\n",
            "12723/12723 [==============================] - 3s 207us/step - loss: 0.1584 - acc: 0.4524 - auc: 0.6184\n",
            "Epoch 11/15\n",
            "12723/12723 [==============================] - 3s 208us/step - loss: 0.1634 - acc: 0.4465 - auc: 0.6209\n",
            "Epoch 12/15\n",
            "12723/12723 [==============================] - 3s 220us/step - loss: 0.1614 - acc: 0.4471 - auc: 0.6238\n",
            "Epoch 13/15\n",
            "12723/12723 [==============================] - 3s 219us/step - loss: 0.1565 - acc: 0.4463 - auc: 0.6267\n",
            "Epoch 14/15\n",
            "12723/12723 [==============================] - 3s 221us/step - loss: 0.1530 - acc: 0.4462 - auc: 0.6323\n",
            "Epoch 15/15\n",
            "12723/12723 [==============================] - 3s 213us/step - loss: 0.1503 - acc: 0.4468 - auc: 0.6385\n",
            "3181/3181 [==============================] - 8s 2ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 20s 2ms/step - loss: 0.2005 - acc: 0.4506 - auc: 0.5315\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 3s 214us/step - loss: 0.1645 - acc: 0.4490 - auc: 0.6254\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 3s 210us/step - loss: 0.1401 - acc: 0.4475 - auc: 0.6651\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 3s 218us/step - loss: 0.1264 - acc: 0.4499 - auc: 0.7147\n",
            "Epoch 5/15\n",
            "12723/12723 [==============================] - 3s 216us/step - loss: 0.1243 - acc: 0.4517 - auc: 0.7496\n",
            "Epoch 6/15\n",
            "12723/12723 [==============================] - 3s 218us/step - loss: 0.1149 - acc: 0.4534 - auc: 0.7744\n",
            "Epoch 7/15\n",
            "12723/12723 [==============================] - 3s 219us/step - loss: 0.1110 - acc: 0.4536 - auc: 0.7962\n",
            "Epoch 8/15\n",
            "12723/12723 [==============================] - 3s 218us/step - loss: 0.1080 - acc: 0.4534 - auc: 0.8132\n",
            "Epoch 9/15\n",
            "12723/12723 [==============================] - 3s 219us/step - loss: 0.1041 - acc: 0.4607 - auc: 0.8264\n",
            "Epoch 10/15\n",
            "12723/12723 [==============================] - 3s 215us/step - loss: 0.1025 - acc: 0.4716 - auc: 0.8376\n",
            "Epoch 11/15\n",
            "12723/12723 [==============================] - 3s 212us/step - loss: 0.0977 - acc: 0.4764 - auc: 0.8469\n",
            "Epoch 12/15\n",
            "12723/12723 [==============================] - 3s 210us/step - loss: 0.0970 - acc: 0.5150 - auc: 0.8551\n",
            "Epoch 13/15\n",
            "12723/12723 [==============================] - 3s 212us/step - loss: 0.0909 - acc: 0.5976 - auc: 0.8632\n",
            "Epoch 14/15\n",
            "12723/12723 [==============================] - 3s 214us/step - loss: 0.0891 - acc: 0.6415 - auc: 0.8702\n",
            "Epoch 15/15\n",
            "12723/12723 [==============================] - 3s 217us/step - loss: 0.0881 - acc: 0.6797 - auc: 0.8761\n",
            "3181/3181 [==============================] - 8s 2ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Epoch 1/15\n",
            "12724/12724 [==============================] - 20s 2ms/step - loss: 0.2370 - acc: 0.4521 - auc: 0.5220\n",
            "Epoch 2/15\n",
            "12724/12724 [==============================] - 3s 211us/step - loss: 0.1558 - acc: 0.4493 - auc: 0.5935\n",
            "Epoch 3/15\n",
            "12724/12724 [==============================] - 3s 210us/step - loss: 0.1404 - acc: 0.4518 - auc: 0.6659\n",
            "Epoch 4/15\n",
            "12724/12724 [==============================] - 3s 210us/step - loss: 0.1321 - acc: 0.4508 - auc: 0.7124\n",
            "Epoch 5/15\n",
            "12724/12724 [==============================] - 3s 218us/step - loss: 0.1215 - acc: 0.4532 - auc: 0.7464\n",
            "Epoch 6/15\n",
            "12724/12724 [==============================] - 3s 228us/step - loss: 0.1137 - acc: 0.4553 - auc: 0.7746\n",
            "Epoch 7/15\n",
            "12724/12724 [==============================] - 3s 215us/step - loss: 0.1093 - acc: 0.4573 - auc: 0.7977\n",
            "Epoch 8/15\n",
            "12724/12724 [==============================] - 3s 208us/step - loss: 0.1039 - acc: 0.4576 - auc: 0.8158\n",
            "Epoch 9/15\n",
            "12724/12724 [==============================] - 3s 215us/step - loss: 0.1023 - acc: 0.4675 - auc: 0.8303\n",
            "Epoch 10/15\n",
            "12724/12724 [==============================] - 3s 224us/step - loss: 0.0986 - acc: 0.4805 - auc: 0.8417\n",
            "Epoch 11/15\n",
            "12724/12724 [==============================] - 3s 212us/step - loss: 0.0943 - acc: 0.5597 - auc: 0.8524\n",
            "Epoch 12/15\n",
            "12724/12724 [==============================] - 3s 216us/step - loss: 0.0920 - acc: 0.6226 - auc: 0.8612\n",
            "Epoch 13/15\n",
            "12724/12724 [==============================] - 3s 214us/step - loss: 0.0879 - acc: 0.6716 - auc: 0.8690\n",
            "Epoch 14/15\n",
            "12724/12724 [==============================] - 3s 208us/step - loss: 0.0826 - acc: 0.7259 - auc: 0.8763\n",
            "Epoch 15/15\n",
            "12724/12724 [==============================] - 3s 211us/step - loss: 0.0799 - acc: 0.7480 - auc: 0.8828\n",
            "3180/3180 [==============================] - 8s 2ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Warstwa 3\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 20s 2ms/step - loss: 0.8842 - acc: 0.5336 - auc: 0.5000\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 3s 216us/step - loss: 0.6861 - acc: 0.5575 - auc: 0.5069\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 3s 213us/step - loss: 0.6114 - acc: 0.6705 - auc: 0.5403\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 3s 227us/step - loss: 0.4959 - acc: 0.7711 - auc: 0.6257\n",
            "Epoch 5/15\n",
            "12723/12723 [==============================] - 3s 223us/step - loss: 0.4099 - acc: 0.8260 - auc: 0.6932\n",
            "Epoch 6/15\n",
            "12723/12723 [==============================] - 3s 224us/step - loss: 0.3811 - acc: 0.8434 - auc: 0.7399\n",
            "Epoch 7/15\n",
            "12723/12723 [==============================] - 3s 219us/step - loss: 0.3527 - acc: 0.8599 - auc: 0.7729\n",
            "Epoch 8/15\n",
            "12723/12723 [==============================] - 3s 214us/step - loss: 0.3368 - acc: 0.8672 - auc: 0.7968\n",
            "Epoch 9/15\n",
            "12723/12723 [==============================] - 3s 215us/step - loss: 0.3247 - acc: 0.8704 - auc: 0.8150\n",
            "Epoch 10/15\n",
            "12723/12723 [==============================] - 3s 221us/step - loss: 0.3075 - acc: 0.8799 - auc: 0.8297\n",
            "Epoch 11/15\n",
            "12723/12723 [==============================] - 3s 214us/step - loss: 0.3098 - acc: 0.8801 - auc: 0.8413\n",
            "Epoch 12/15\n",
            "12723/12723 [==============================] - 3s 225us/step - loss: 0.3035 - acc: 0.8831 - auc: 0.8504\n",
            "Epoch 13/15\n",
            "12723/12723 [==============================] - 3s 215us/step - loss: 0.2954 - acc: 0.8875 - auc: 0.8584\n",
            "Epoch 14/15\n",
            "12723/12723 [==============================] - 3s 216us/step - loss: 0.2806 - acc: 0.8931 - auc: 0.8652\n",
            "Epoch 15/15\n",
            "12723/12723 [==============================] - 3s 211us/step - loss: 0.2801 - acc: 0.8940 - auc: 0.8711\n",
            "3181/3181 [==============================] - 8s 2ms/step\n",
            "Warstwa 1\n",
            "Warstwa 2\n",
            "Warstwa 3\n",
            "Epoch 1/15\n",
            "12723/12723 [==============================] - 20s 2ms/step - loss: 0.7433 - acc: 0.5540 - auc: 0.5083\n",
            "Epoch 2/15\n",
            "12723/12723 [==============================] - 3s 221us/step - loss: 0.5607 - acc: 0.7226 - auc: 0.6001\n",
            "Epoch 3/15\n",
            "12723/12723 [==============================] - 3s 207us/step - loss: 0.4336 - acc: 0.8172 - auc: 0.7128\n",
            "Epoch 4/15\n",
            "12723/12723 [==============================] - 3s 212us/step - loss: 0.3932 - acc: 0.8391 - auc: 0.7713\n",
            "Epoch 5/15\n",
            " 5248/12723 [===========>..................] - ETA: 1s - loss: 0.3820 - acc: 0.8478 - auc: 0.7970Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGXggAs2UY2m",
        "colab_type": "code",
        "outputId": "dc80f1f0-98d9-48c6-bcb4-0cdb6010524c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "source": [
        "print('The parameters of the best model are: ')\n",
        "print(validator66.best_params_)\n",
        "\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The parameters of the best model are: \n",
            "{'batch_size': 32, 'dense_layer_sizes': 128, 'epochs': 15, 'filters': 20, 'hidden_layers': 3, 'kernel_size': (3, 3), 'loss_function': 'binary_crossentropy', 'pool_size': (2, 2)}\n",
            "0.869907 (0.014068) with: {'batch_size': 32, 'dense_layer_sizes': 128, 'epochs': 15, 'filters': 10, 'hidden_layers': 2, 'kernel_size': (3, 3), 'loss_function': 'binary_crossentropy', 'pool_size': (2, 2)}\n",
            "0.671089 (0.122335) with: {'batch_size': 32, 'dense_layer_sizes': 128, 'epochs': 15, 'filters': 10, 'hidden_layers': 2, 'kernel_size': (3, 3), 'loss_function': functools.partial(<function weighted_binary_crossentropy at 0x7fddec2d7268>, weights_10=array([0.9, 0.1])), 'pool_size': (2, 2)}\n",
            "0.752012 (0.161275) with: {'batch_size': 32, 'dense_layer_sizes': 128, 'epochs': 15, 'filters': 10, 'hidden_layers': 3, 'kernel_size': (3, 3), 'loss_function': 'binary_crossentropy', 'pool_size': (2, 2)}\n",
            "0.710827 (0.093366) with: {'batch_size': 32, 'dense_layer_sizes': 128, 'epochs': 15, 'filters': 10, 'hidden_layers': 3, 'kernel_size': (3, 3), 'loss_function': functools.partial(<function weighted_binary_crossentropy at 0x7fddec2d7268>, weights_10=array([0.9, 0.1])), 'pool_size': (2, 2)}\n",
            "0.758426 (0.166309) with: {'batch_size': 32, 'dense_layer_sizes': 128, 'epochs': 15, 'filters': 20, 'hidden_layers': 2, 'kernel_size': (3, 3), 'loss_function': 'binary_crossentropy', 'pool_size': (2, 2)}\n",
            "0.674233 (0.127986) with: {'batch_size': 32, 'dense_layer_sizes': 128, 'epochs': 15, 'filters': 20, 'hidden_layers': 2, 'kernel_size': (3, 3), 'loss_function': functools.partial(<function weighted_binary_crossentropy at 0x7fddec2d7268>, weights_10=array([0.9, 0.1])), 'pool_size': (2, 2)}\n",
            "0.904049 (0.006086) with: {'batch_size': 32, 'dense_layer_sizes': 128, 'epochs': 15, 'filters': 20, 'hidden_layers': 3, 'kernel_size': (3, 3), 'loss_function': 'binary_crossentropy', 'pool_size': (2, 2)}\n",
            "0.687814 (0.123917) with: {'batch_size': 32, 'dense_layer_sizes': 128, 'epochs': 15, 'filters': 20, 'hidden_layers': 3, 'kernel_size': (3, 3), 'loss_function': functools.partial(<function weighted_binary_crossentropy at 0x7fddec2d7268>, weights_10=array([0.9, 0.1])), 'pool_size': (2, 2)}\n",
            "0.871227 (0.006594) with: {'batch_size': 64, 'dense_layer_sizes': 128, 'epochs': 15, 'filters': 10, 'hidden_layers': 2, 'kernel_size': (3, 3), 'loss_function': 'binary_crossentropy', 'pool_size': (2, 2)}\n",
            "0.671152 (0.116912) with: {'batch_size': 64, 'dense_layer_sizes': 128, 'epochs': 15, 'filters': 10, 'hidden_layers': 2, 'kernel_size': (3, 3), 'loss_function': functools.partial(<function weighted_binary_crossentropy at 0x7fddec2d7268>, weights_10=array([0.9, 0.1])), 'pool_size': (2, 2)}\n",
            "0.888141 (0.004962) with: {'batch_size': 64, 'dense_layer_sizes': 128, 'epochs': 15, 'filters': 10, 'hidden_layers': 3, 'kernel_size': (3, 3), 'loss_function': 'binary_crossentropy', 'pool_size': (2, 2)}\n",
            "0.745410 (0.021864) with: {'batch_size': 64, 'dense_layer_sizes': 128, 'epochs': 15, 'filters': 10, 'hidden_layers': 3, 'kernel_size': (3, 3), 'loss_function': functools.partial(<function weighted_binary_crossentropy at 0x7fddec2d7268>, weights_10=array([0.9, 0.1])), 'pool_size': (2, 2)}\n",
            "0.820485 (0.132884) with: {'batch_size': 64, 'dense_layer_sizes': 128, 'epochs': 15, 'filters': 20, 'hidden_layers': 2, 'kernel_size': (3, 3), 'loss_function': 'binary_crossentropy', 'pool_size': (2, 2)}\n",
            "0.635123 (0.157508) with: {'batch_size': 64, 'dense_layer_sizes': 128, 'epochs': 15, 'filters': 20, 'hidden_layers': 2, 'kernel_size': (3, 3), 'loss_function': functools.partial(<function weighted_binary_crossentropy at 0x7fddec2d7268>, weights_10=array([0.9, 0.1])), 'pool_size': (2, 2)}\n",
            "0.695108 (0.172173) with: {'batch_size': 64, 'dense_layer_sizes': 128, 'epochs': 15, 'filters': 20, 'hidden_layers': 3, 'kernel_size': (3, 3), 'loss_function': 'binary_crossentropy', 'pool_size': (2, 2)}\n",
            "0.725541 (0.060771) with: {'batch_size': 64, 'dense_layer_sizes': 128, 'epochs': 15, 'filters': 20, 'hidden_layers': 3, 'kernel_size': (3, 3), 'loss_function': functools.partial(<function weighted_binary_crossentropy at 0x7fddec2d7268>, weights_10=array([0.9, 0.1])), 'pool_size': (2, 2)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXE3mC5lnkaW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  grid_result.cv_results_['split1_test_score']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZoiIznKfCrX",
        "colab_type": "code",
        "outputId": "30b715f7-8500-4386-f15e-235c228ffabb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "print('The parameters of the best model are: ')\n",
        "print(validator66.best_params_)\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The parameters of the best model are: \n",
            "{'batch_size': 32, 'dense_layer_sizes': 128, 'epochs': 1, 'filters': 10, 'kernel_size': 3, 'pool_size': 2}\n",
            "-0.696088 (0.005621) with: {'batch_size': 32, 'dense_layer_sizes': 128, 'epochs': 1, 'filters': 10, 'kernel_size': 3, 'pool_size': 2}\n",
            "-4.680589 (5.632574) with: {'batch_size': 32, 'dense_layer_sizes': 256, 'epochs': 1, 'filters': 10, 'kernel_size': 3, 'pool_size': 2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsMOoTCLm7im",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build the model\n",
        "#del model\n",
        "#dense_size_candidates = [[32], [64], [32, 32], [64, 64]]\n",
        "#model = make_model(5, 20, 3, 2)\n",
        "#model.fit(X_train, y_train, epochs=5, batch_size=32)\n",
        "\n",
        "my_classifier = KerasClassifier(search_model)\n",
        "validator = GridSearchCV(my_classifier,\n",
        "                         param_grid={'dense_layer_sizes': [128, 256],\n",
        "                                     # epochs is avail for tuning even when not\n",
        "                                     # an argument to model building function\n",
        "                                     'epochs': [10, 30, 50],\n",
        "                                     'filters': [10, 20],\n",
        "                                     'kernel_size': [(3,3)],\n",
        "                                     'pool_size': [(2,2)],\n",
        "                                     'hidden_layers': [1,2,3],\n",
        "                                     'loss_function': ['binary_crossentropy', custom_loss2],\n",
        "                                     'batch_size': [[32], [64]]}, \n",
        "                         scoring='neg_log_loss')\n",
        "\n",
        "my_classifier2 = KerasClassifier(make_model_modified)\n",
        "validator2 = GridSearchCV(my_classifier2,\n",
        "                         param_grid={'dense_layer_sizes': [128,256],\n",
        "                                     # epochs is avail for tuning even when not\n",
        "                                     # an argument to model building function\n",
        "                                     'epochs': [1,2],\n",
        "                                     'filters': [20],\n",
        "                                     'kernel_size': [(3,3)],\n",
        "                                     'pool_size': [(2,2)],\n",
        "                                     'batch_size': [32]}, \n",
        "                         scoring='neg_log_loss', n_jobs=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unF8fvbDwTF1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_frame = pd.DataFrame(y_train)\n",
        "y=y_train.astype('int')\n",
        "grid_result = validator.fit(X_train, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hW98cIwoRGpM",
        "colab_type": "code",
        "outputId": "4202e3fe-7754-4cb6-93d3-2d006285872d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "'''Example of how to use sklearn wrapper\n",
        "Builds simple CNN models on MNIST and uses sklearn's GridSearchCV to find best model\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras import backend as K\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# load training data and do basic data normalization\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print(numpy.shape(x_train))\n",
        "print(numpy.shape(y_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9TJIdqjTikR",
        "colab_type": "code",
        "outputId": "44625f03-27b2-411d-b8e5-8e3347e7827d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "a = y_train>1\n",
        "y_train_binary = a*1\n",
        "print(y_train_binary)\n",
        "print(numpy.shape(x_train))\n",
        "print(numpy.shape(y_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 ... 0 0 0]\n",
            "(60000, 28, 28, 1)\n",
            "(15904,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPxN3JQb51Bw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# convert class vectors to binary class matrices\n",
        "#y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "#y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\n",
        "def make_model(dense_layer_sizes, filters, kernel_size, pool_size):\n",
        "    '''Creates model comprised of 2 convolutional layers followed by dense layers\n",
        "    dense_layer_sizes: List of layer sizes.\n",
        "        This list has one number for each layer\n",
        "    filters: Number of convolutional filters in each convolutional layer\n",
        "    kernel_size: Convolutional kernel size\n",
        "    pool_size: Size of pooling area for max pooling\n",
        "    '''\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters, kernel_size,\n",
        "                     padding='valid',\n",
        "                     input_shape=input_shape, data_format='channels_first'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(filters, kernel_size))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=pool_size))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    for layer_size in dense_layer_sizes:\n",
        "        model.add(Dense(layer_size))\n",
        "        model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1))#(num_classes))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', #'categorical_crossentropy',\n",
        "                  optimizer='adadelta',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "dense_size_candidates = [[32], [64]] #, [32, 32], [64, 64]]\n",
        "my_classifier = KerasClassifier(make_model, batch_size=32)\n",
        "validator = GridSearchCV(my_classifier,\n",
        "                         param_grid={'dense_layer_sizes': dense_size_candidates,\n",
        "                                     # epochs is avail for tuning even when not\n",
        "                                     # an argument to model building function\n",
        "                                     'epochs': [1],\n",
        "                                     'filters': [8],\n",
        "                                     'kernel_size': [3],\n",
        "                                     'pool_size': [2]},\n",
        "                         scoring='neg_log_loss',\n",
        "                         n_jobs=1)\n",
        "y=y_train.astype('int')\n",
        "validator.fit(X_train, y) #_binary)\n",
        "\n",
        "print('The parameters of the best model are: ')\n",
        "print(validator.best_params_)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kswr3l8Z17v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# validator.best_estimator_ returns sklearn-wrapped version of best model.\n",
        "# validator.best_estimator_.model returns the (unwrapped) keras model\n",
        "best_model = validator.best_estimator_.model\n",
        "metric_names = best_model.metrics_names\n",
        "metric_values = best_model.evaluate(x_test, y_test)\n",
        "for metric, value in zip(metric_names, metric_values):\n",
        "    print(metric, ': ', value)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPTbon76RXfF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}