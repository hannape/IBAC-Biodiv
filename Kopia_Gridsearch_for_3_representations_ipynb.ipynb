{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kopia Gridsearch for 3 representations. ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hannape/IBAC-Biodiv/blob/master/Kopia_Gridsearch_for_3_representations_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mq81jmxhMYV",
        "colab_type": "text"
      },
      "source": [
        "Gridsearch dla każdej reprezentacji osobno. Bo na IBACu wszystkie 3 reprezentacje były puszczone na architekturę z mel-spectrogramu (chyba?)\n",
        "\n",
        "Na podstawie hania.dldisc: cnn_gridsearch.ipynb , 03 CNN fit and predict (I2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65s8txmrhL7Y",
        "colab_type": "code",
        "outputId": "3e34416f-26c2-4c91-d460-86dd0691d61f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from __future__ import print_function"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CddWh85JjLPZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import keras\n",
        "import numpy\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras import backend as K\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "import numpy\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from matplotlib import pyplot\n",
        "#K.set_image_dim_ordering('th')\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from keras.datasets import mnist\n",
        "import glob\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from functools import partial, update_wrapper\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAjy6F71jTVn",
        "colab_type": "code",
        "outputId": "eeed68b8-6b8c-433f-8532-8fdde9e1ff80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(667)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(667)\n",
        "import random\n",
        "random.seed()\n",
        "\n",
        "'''\n",
        "#################### Rep 1 - spektro ####################\n",
        "# rep 1  ------- 63 x 148 ------ TRAIN 17.3k\n",
        "X_train1 = numpy.load('drive/My Drive/rep IBAC/rep1/X_train_rep1.npy', allow_pickle=True) # 1 and 0 in order\n",
        "y_train1 = numpy.load('drive/My Drive/rep IBAC/rep1/y_train.npy', allow_pickle=True)\n",
        "'''\n",
        "# rep 1V2 ------- 63 x 148 ------ TRAIN 15.9\n",
        "X_train1 = numpy.load('drive/My Drive/rep IBAC/rep1V2/X_train_rep1.npy', allow_pickle=True) # 1 and 0 in order\n",
        "y_train1 = numpy.load('drive/My Drive/rep IBAC/rep1V2/y_train_rep1.npy', allow_pickle=True)\n",
        "'''\n",
        "# rep 1b ------- 63 x 63 ------\n",
        "X_train1 = numpy.load('drive/My Drive/rep IBAC/rep1b/X_train_rep1b.npy', allow_pickle=True) # 1 and 0 in order\n",
        "y_train1 = numpy.load('drive/My Drive/rep IBAC/rep1b/y_train_rep1b.npy', allow_pickle=True)\n",
        "\n",
        "#################### Rep 3 - mel-spektro ####################\n",
        "\n",
        "# rep 3 ------- 60 x 111 ------ TRAIN 17.3k\n",
        "X_train1 = numpy.load('drive/My Drive/rep IBAC/rep3/X_train_rep3.npy', allow_pickle=True) # 1 and 0 in order\n",
        "y_train1 = numpy.load('drive/My Drive/rep IBAC/rep3/y_train.npy', allow_pickle=True)\n",
        "\n",
        "# rep 3V2 ------- 60 x 111 ------ TRAIN 15.9\n",
        "X_train1 = numpy.load('drive/My Drive/rep IBAC/rep3V2/X_train_rep3.npy', allow_pickle=True) # 1 and 0 in order\n",
        "y_train1 = numpy.load('drive/My Drive/rep IBAC/rep3V2/y_train_rep3.npy', allow_pickle=True)\n",
        "\n",
        "# rep 3b ------- 60 x 63 ------\n",
        "X_train1 = numpy.load('drive/My Drive/rep IBAC/rep3b/X_train_rep3b.npy', allow_pickle=True) # 1 and 0 in order\n",
        "y_train1 = numpy.load('drive/My Drive/rep IBAC/rep3b/y_train_rep3b.npy', allow_pickle=True)\n",
        "\n",
        "# rep 3V3 ------- 60 x 148 ------\n",
        "X_train1 = numpy.load('drive/My Drive/rep IBAC/rep3V3/X_train_rep3V3.npy', allow_pickle=True) # 1 and 0 in order\n",
        "y_train1 = numpy.load('drive/My Drive/rep IBAC/rep3V3/y_train_rep3V3.npy', allow_pickle=True)\n",
        "\n",
        "#################### Rep 5 - mel-spektro ####################\n",
        "\n",
        "# rep 5 ------- 64 x 61 ------ TRAIN 17.3k\n",
        "X_train1 = numpy.load('drive/My Drive/rep IBAC/rep5/X_train_rep5.npy', allow_pickle=True) # 1 and 0 in order\n",
        "y_train1 = numpy.load('drive/My Drive/rep IBAC/rep5/y_train.npy', allow_pickle=True)\n",
        "\n",
        "# rep 5V2 ------- 64 x 61 ------ TRAIN 15.9\n",
        "X_train1 = numpy.load('drive/My Drive/rep IBAC/rep5V2/X_train_rep5.npy', allow_pickle=True) # 1 and 0 in order\n",
        "y_train1 = numpy.load('drive/My Drive/rep IBAC/rep5V2/y_train_rep5.npy', allow_pickle=True)\n",
        "\n",
        "# rep 5b ------- 64 x 149 ------\n",
        "X_train1 = numpy.load('drive/My Drive/rep IBAC/rep5b/X_train_rep5b.npy', allow_pickle=True) # 1 and 0 in order\n",
        "y_train1 = numpy.load('drive/My Drive/rep IBAC/rep5b/y_train_rep5b.npy', allow_pickle=True)\n",
        "'''\n",
        "\n",
        "print('Training set size:')\n",
        "print(np.shape(X_train1))\n",
        "print(np.shape(y_train1))\n"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set size:\n",
            "(15904, 63, 148)\n",
            "(15904,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ST0WDnQSxeLD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "80d3edfb-63af-4786-f917-f846b4e181e2"
      },
      "source": [
        "r = np.shape(X_train1)[1]\n",
        "s = np.shape(X_train1)[2]\n",
        "y_train = y_train1\n",
        "X_train = X_train1.reshape(X_train1.shape[0], 1, r, s).astype('float32')\n",
        "print('Training set size:')\n",
        "print(np.shape(X_train))\n",
        "print(np.shape(y_train))\n",
        "input_shape = (1, r, s)\n",
        "print(input_shape)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set size:\n",
            "(15904, 1, 63, 148)\n",
            "(15904,)\n",
            "(1, 63, 148)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j27RDs6YmWqD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://github.com/keras-team/keras/issues/2115\n",
        "\n",
        "### definiowanie wag \n",
        "for_zeros = 0.1\n",
        "for_ones = 0.9\n",
        "###\n",
        "\n",
        "### SCORERS\n",
        "\n",
        "#def binary_crossentropy_weigted(y_true, y_pred, class_weights):\n",
        "#\ty_pred = K.clip(y_pred, K.epsilon(), 1.0 - K.epsilon())\n",
        "#  \n",
        "#\tloss = K.mean(class_weights*(-y_true * K.log(y_pred) - (1.0 - y_true) * K.log(1.0 - y_pred)),axis=-1)\n",
        "#\treturn loss\n",
        "\n",
        "def weighted_binary_crossentropy( y_true, y_pred, weights_10) :\n",
        "    y_pred = K.clip(y_pred, K.epsilon(), 1.0 - K.epsilon())\n",
        "    logloss = -(y_true * K.log(y_pred) * weights_10[0] + (1 - y_true) * K.log(1 - y_pred) * weights_10[1])\n",
        "    return K.mean(logloss, axis=-1)\n",
        "\n",
        "#custom_loss1 = partial(binary_crossentropy_weigted, class_weights=np.array([for_zeros,for_ones])) ## scoring for model.compile\n",
        "#custom_loss1.__name__ ='binary_crossentropy_weigted'\n",
        "\n",
        "custom_loss2 = partial(weighted_binary_crossentropy, weights_10=np.array([for_ones,for_zeros])) ## scoring for model.compile\n",
        "custom_loss2.__name__ ='weighted_binary_crossentropy'\n",
        "\n",
        "## AUC METRIC\n",
        "def as_keras_metric(method):\n",
        "    import functools\n",
        "    from keras import backend as K\n",
        "    \n",
        "    @functools.wraps(method)\n",
        "    def wrapper(self, args, **kwargs):\n",
        "        \"\"\" Wrapper for turning tensorflow metrics into keras metrics \"\"\"\n",
        "        value, update_op = method(self, args, **kwargs)\n",
        "        K.get_session().run(tf.local_variables_initializer())\n",
        "        with tf.control_dependencies([update_op]):\n",
        "            value = tf.identity(value)\n",
        "        return value\n",
        "    return wrapper\n",
        "  \n",
        "auc_roc = as_keras_metric(tf.metrics.auc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5svLHOfqjgDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def search_model(dense_layer_sizes, filters, kernel_size, pool_size, hidden_layers, loss_function):\n",
        "   \n",
        "    hidden_layers = 1\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters, kernel_size,input_shape=input_shape, activation='relu', data_format='channels_first'))\n",
        "    model.add(MaxPooling2D(pool_size=pool_size))\n",
        "    #model.add(Conv2D(filters, kernel_size, activation='relu'))\n",
        "    #model.add(MaxPooling2D(pool_size=pool_size))\n",
        "    #model.add(Conv2D(filters, kernel_size, activation='relu'))\n",
        "    #model.add(MaxPooling2D(pool_size=pool_size))\n",
        "   \n",
        "    for i in range(hidden_layers):\n",
        "      # Add one hidden layer\n",
        "      model.add(Conv2D(filters, kernel_size, activation='relu'))\n",
        "      model.add(MaxPooling2D(pool_size=pool_size))\n",
        "  \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(dense_layer_sizes, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', #loss_function,\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy',auc_roc])\n",
        "\n",
        "    return model\n",
        "  \n",
        "def make_model_modified(dense_layer_sizes, filters, kernel_size, pool_size):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters, kernel_size,input_shape=input_shape, activation='relu', data_format='channels_first')) # \"channels_first\" corresponds to inputs with shape (batch, channels, height, width)\n",
        "    model.add(MaxPooling2D(pool_size=pool_size))\n",
        "    model.add(Conv2D(filters, kernel_size, activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=pool_size))\n",
        "    model.add(Conv2D(filters, kernel_size, activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=pool_size))\n",
        "   \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(dense_layer_sizes, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "  \n",
        "def probny_model(dense_layer_sizes):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(10, (3,3),input_shape=input_shape, activation='relu', data_format='channels_first')) # \"channels_first\" corresponds to inputs with shape (batch, channels, height, width)\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "   \n",
        "    model.add(Dense(dense_layer_sizes, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model  \n",
        "  \n",
        "def make_model(dense_layer_sizes, filters, kernel_size, pool_size):\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters, kernel_size,\n",
        "                     padding='valid',\n",
        "                     input_shape=input_shape, data_format='channels_first'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(filters, kernel_size))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=pool_size))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    for layer_size in dense_layer_sizes:\n",
        "        model.add(Dense(layer_size))\n",
        "        model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1))#(num_classes))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', #'categorical_crossentropy',\n",
        "                  optimizer='adadelta',\n",
        "                  metrics=['accuracy'])\n",
        "    return model  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYsSf-Oucqxl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "ba29192d-29d7-44ac-f18c-c5e069ec5a6e"
      },
      "source": [
        "y=y_train.astype('int')\n",
        "print(np.shape(X_train))\n",
        "print(np.shape(y_train))"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15904, 1, 63, 148)\n",
            "(15904,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRdAp3bGb7RJ",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "my_classifier3 = KerasClassifier(make_model)\n",
        "validator3 = GridSearchCV(my_classifier3,\n",
        "                         param_grid={'dense_layer_sizes': [128]}, \n",
        "                         scoring='neg_log_loss')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76411ZmN85od",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "dense_size_candidates = [[32], [64]] #, [32, 32], [64, 64]]\n",
        "my_classifier = KerasClassifier(make_model, batch_size=32)\n",
        "\n",
        "validator = GridSearchCV(my_classifier,\n",
        "                         param_grid={'dense_layer_sizes': [[32], [64]],\n",
        "                                     # epochs is avail for tuning even when not\n",
        "                                     # an argument to model building function\n",
        "                                     'epochs': [1],\n",
        "                                     'filters': [8],\n",
        "                                     'kernel_size': [3],\n",
        "                                     'pool_size': [2]},\n",
        "                         scoring='neg_log_loss',\n",
        "                         n_jobs=1)\n",
        "#y2=y_train.astype('int')\n",
        "validator.fit(X_train, y) #_binary)\n",
        "\n",
        "print('The parameters of the best model are: ')\n",
        "print(validator.best_params_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MadBqOqYbAo4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "26efbbcc-c42f-45e8-86c1-d30f831f2dda"
      },
      "source": [
        "my_classifier66 = KerasClassifier(search_model)\n",
        "validator66 = GridSearchCV(my_classifier66,\n",
        "                         param_grid={'dense_layer_sizes': [128, 256],\n",
        "                                     # epochs is avail for tuning even when not\n",
        "                                     # an argument to model building function\n",
        "                                     'epochs': [5], #[10, 30, 50],\n",
        "                                     'filters': [10], #[10, 20],\n",
        "                                     'kernel_size': [(3,3)], #[(3,3)],\n",
        "                                     'pool_size': [(2,2)],#[(2,2)],\n",
        "                                     'hidden_layers': [1,2,3],\n",
        "                                     'loss_function': ['binary_crossentropy', custom_loss2],\n",
        "                                     'batch_size': [32], #[32, 64]\n",
        "                                     }, \n",
        "                         scoring='neg_log_loss', cv = 2)\n",
        "#y=y_train.astype('int')\n",
        "grid_result = validator66.fit(X_train, y)\n",
        "print('The parameters of the best model are: ')\n",
        "print(validator66.best_params_)\n",
        "\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "7952/7952 [==============================] - 12s 2ms/step - loss: 4.6688 - acc: 0.5832 - auc: 0.4942\n",
            "Epoch 2/5\n",
            "7952/7952 [==============================] - 2s 313us/step - loss: 0.5046 - acc: 0.7758 - auc: 0.5752\n",
            "Epoch 3/5\n",
            "7952/7952 [==============================] - 2s 313us/step - loss: 0.4420 - acc: 0.7980 - auc: 0.6638\n",
            "Epoch 4/5\n",
            "7952/7952 [==============================] - 2s 311us/step - loss: 0.4028 - acc: 0.8271 - auc: 0.7166\n",
            "Epoch 5/5\n",
            "7952/7952 [==============================] - 3s 320us/step - loss: 0.3952 - acc: 0.8331 - auc: 0.7511\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:2174: RuntimeWarning: divide by zero encountered in log\n",
            "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:2174: RuntimeWarning: invalid value encountered in multiply\n",
            "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "7952/7952 [==============================] - 13s 2ms/step - loss: 0.7565 - acc: 0.5410 - auc: 0.4789\n",
            "Epoch 2/5\n",
            "7952/7952 [==============================] - 3s 326us/step - loss: 0.6893 - acc: 0.5443 - auc: 0.4881\n",
            "Epoch 3/5\n",
            "7952/7952 [==============================] - 2s 311us/step - loss: 0.6896 - acc: 0.5443 - auc: 0.4956\n",
            "Epoch 4/5\n",
            "7952/7952 [==============================] - 3s 333us/step - loss: 0.6894 - acc: 0.5443 - auc: 0.4964\n",
            "Epoch 5/5\n",
            "7952/7952 [==============================] - 3s 319us/step - loss: 0.6895 - acc: 0.5443 - auc: 0.4981\n",
            "Epoch 1/5\n",
            "7952/7952 [==============================] - 13s 2ms/step - loss: 0.9570 - acc: 0.5571 - auc: 0.4971\n",
            "Epoch 2/5\n",
            "7952/7952 [==============================] - 3s 327us/step - loss: 0.6850 - acc: 0.5649 - auc: 0.4978\n",
            "Epoch 3/5\n",
            "7952/7952 [==============================] - 3s 330us/step - loss: 0.6848 - acc: 0.5649 - auc: 0.4969\n",
            "Epoch 4/5\n",
            "7952/7952 [==============================] - 3s 318us/step - loss: 0.6851 - acc: 0.5649 - auc: 0.4983\n",
            "Epoch 5/5\n",
            "7952/7952 [==============================] - 3s 324us/step - loss: 0.6850 - acc: 0.5649 - auc: 0.4976\n",
            "Epoch 1/5\n",
            "7952/7952 [==============================] - 13s 2ms/step - loss: 0.7999 - acc: 0.5815 - auc: 0.5294\n",
            "Epoch 2/5\n",
            "7952/7952 [==============================] - 3s 322us/step - loss: 0.4945 - acc: 0.7778 - auc: 0.6689\n",
            "Epoch 3/5\n",
            "7952/7952 [==============================] - 3s 331us/step - loss: 0.4085 - acc: 0.8221 - auc: 0.7598\n",
            "Epoch 4/5\n",
            "7952/7952 [==============================] - 3s 322us/step - loss: 0.3834 - acc: 0.8336 - auc: 0.8009\n",
            "Epoch 5/5\n",
            "7952/7952 [==============================] - 3s 321us/step - loss: 0.3674 - acc: 0.8424 - auc: 0.8241\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:2174: RuntimeWarning: divide by zero encountered in log\n",
            "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:2174: RuntimeWarning: invalid value encountered in multiply\n",
            "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "7952/7952 [==============================] - 13s 2ms/step - loss: 7.0113 - acc: 0.5625 - auc: 0.4949\n",
            "Epoch 2/5\n",
            "7952/7952 [==============================] - 3s 316us/step - loss: 7.0132 - acc: 0.5649 - auc: 0.4994\n",
            "Epoch 3/5\n",
            "7952/7952 [==============================] - 3s 316us/step - loss: 7.0132 - acc: 0.5649 - auc: 0.4997\n",
            "Epoch 4/5\n",
            "7952/7952 [==============================] - 3s 319us/step - loss: 7.0132 - acc: 0.5649 - auc: 0.4998\n",
            "Epoch 5/5\n",
            "7952/7952 [==============================] - 3s 319us/step - loss: 7.0132 - acc: 0.5649 - auc: 0.4998\n",
            "Epoch 1/5\n",
            "7952/7952 [==============================] - 14s 2ms/step - loss: 0.9582 - acc: 0.5376 - auc: 0.4762\n",
            "Epoch 2/5\n",
            "7952/7952 [==============================] - 3s 317us/step - loss: 0.6894 - acc: 0.5443 - auc: 0.4909\n",
            "Epoch 3/5\n",
            "7952/7952 [==============================] - 3s 320us/step - loss: 0.6891 - acc: 0.5443 - auc: 0.4954\n",
            "Epoch 4/5\n",
            "7952/7952 [==============================] - 3s 321us/step - loss: 0.6896 - acc: 0.5443 - auc: 0.4975\n",
            "Epoch 5/5\n",
            "7952/7952 [==============================] - 3s 324us/step - loss: 0.6894 - acc: 0.5443 - auc: 0.4978\n",
            "Epoch 1/5\n",
            "7952/7952 [==============================] - 14s 2ms/step - loss: 0.8034 - acc: 0.5638 - auc: 0.5075\n",
            "Epoch 2/5\n",
            "7952/7952 [==============================] - 3s 355us/step - loss: 0.6853 - acc: 0.5649 - auc: 0.4986\n",
            "Epoch 3/5\n",
            "7952/7952 [==============================] - 3s 344us/step - loss: 0.6854 - acc: 0.5649 - auc: 0.4948\n",
            "Epoch 4/5\n",
            "7952/7952 [==============================] - 3s 340us/step - loss: 0.6855 - acc: 0.5649 - auc: 0.4925\n",
            "Epoch 5/5\n",
            "7952/7952 [==============================] - 3s 324us/step - loss: 0.6849 - acc: 0.5649 - auc: 0.4918\n",
            "Epoch 1/5\n",
            "7952/7952 [==============================] - 14s 2ms/step - loss: 7.3172 - acc: 0.5411 - auc: 0.4990\n",
            "Epoch 2/5\n",
            "7952/7952 [==============================] - 3s 327us/step - loss: 7.3494 - acc: 0.5436 - auc: 0.5000\n",
            "Epoch 3/5\n",
            "7952/7952 [==============================] - 3s 329us/step - loss: 7.3449 - acc: 0.5443 - auc: 0.4999\n",
            "Epoch 4/5\n",
            "7952/7952 [==============================] - 3s 325us/step - loss: 7.3376 - acc: 0.5440 - auc: 0.4999\n",
            "Epoch 5/5\n",
            "7952/7952 [==============================] - 3s 327us/step - loss: 2.3847 - acc: 0.5428 - auc: 0.5003\n",
            "Epoch 1/5\n",
            "7952/7952 [==============================] - 14s 2ms/step - loss: 0.7932 - acc: 0.5636 - auc: 0.5060\n",
            "Epoch 2/5\n",
            "7952/7952 [==============================] - 3s 325us/step - loss: 0.6846 - acc: 0.5649 - auc: 0.4981\n",
            "Epoch 3/5\n",
            "7952/7952 [==============================] - 3s 328us/step - loss: 0.6854 - acc: 0.5649 - auc: 0.5022\n",
            "Epoch 4/5\n",
            "7952/7952 [==============================] - 3s 331us/step - loss: 0.6850 - acc: 0.5649 - auc: 0.4993\n",
            "Epoch 5/5\n",
            "7952/7952 [==============================] - 3s 330us/step - loss: 0.6854 - acc: 0.5649 - auc: 0.4980\n",
            "Epoch 1/5\n",
            "7952/7952 [==============================] - 15s 2ms/step - loss: 1.4969 - acc: 0.5326 - auc: 0.4978\n",
            "Epoch 2/5\n",
            "7952/7952 [==============================] - 3s 350us/step - loss: 0.6896 - acc: 0.5443 - auc: 0.4993\n",
            "Epoch 3/5\n",
            "7952/7952 [==============================] - 3s 325us/step - loss: 0.6893 - acc: 0.5443 - auc: 0.4989\n",
            "Epoch 4/5\n",
            "7952/7952 [==============================] - 3s 328us/step - loss: 0.6897 - acc: 0.5443 - auc: 0.4983\n",
            "Epoch 5/5\n",
            "7952/7952 [==============================] - 3s 343us/step - loss: 0.6893 - acc: 0.5443 - auc: 0.4977\n",
            "Epoch 1/5\n",
            "7952/7952 [==============================] - 15s 2ms/step - loss: 0.7848 - acc: 0.5612 - auc: 0.4953\n",
            "Epoch 2/5\n",
            "7952/7952 [==============================] - 3s 343us/step - loss: 0.6847 - acc: 0.5649 - auc: 0.4991\n",
            "Epoch 3/5\n",
            "7952/7952 [==============================] - 3s 343us/step - loss: 0.6848 - acc: 0.5649 - auc: 0.5021\n",
            "Epoch 4/5\n",
            "7952/7952 [==============================] - 3s 341us/step - loss: 0.6854 - acc: 0.5649 - auc: 0.5019\n",
            "Epoch 5/5\n",
            "7952/7952 [==============================] - 3s 343us/step - loss: 0.6848 - acc: 0.5649 - auc: 0.5002\n",
            "Epoch 1/5\n",
            "7952/7952 [==============================] - 15s 2ms/step - loss: 0.7637 - acc: 0.5394 - auc: 0.4862\n",
            "Epoch 2/5\n",
            "7952/7952 [==============================] - 3s 347us/step - loss: 0.6897 - acc: 0.5443 - auc: 0.4974\n",
            "Epoch 3/5\n",
            "7952/7952 [==============================] - 3s 342us/step - loss: 0.6897 - acc: 0.5443 - auc: 0.5002\n",
            "Epoch 4/5\n",
            "7952/7952 [==============================] - 3s 353us/step - loss: 0.6892 - acc: 0.5443 - auc: 0.4993\n",
            "Epoch 5/5\n",
            "7952/7952 [==============================] - 3s 344us/step - loss: 0.6895 - acc: 0.5443 - auc: 0.4995\n",
            "Epoch 1/5\n",
            "7952/7952 [==============================] - 15s 2ms/step - loss: 1.4201 - acc: 0.6391 - auc: 0.5550\n",
            "Epoch 2/5\n",
            "7952/7952 [==============================] - 3s 344us/step - loss: 0.5436 - acc: 0.7378 - auc: 0.6743\n",
            "Epoch 3/5\n",
            "7952/7952 [==============================] - 3s 348us/step - loss: 0.5030 - acc: 0.7582 - auc: 0.7242\n",
            "Epoch 4/5\n",
            "7952/7952 [==============================] - 3s 347us/step - loss: 0.4796 - acc: 0.7740 - auc: 0.7497\n",
            "Epoch 5/5\n",
            "7952/7952 [==============================] - 3s 347us/step - loss: 0.4603 - acc: 0.7853 - auc: 0.7690\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:2174: RuntimeWarning: divide by zero encountered in log\n",
            "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:2174: RuntimeWarning: invalid value encountered in multiply\n",
            "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "7952/7952 [==============================] - 15s 2ms/step - loss: 0.8599 - acc: 0.5386 - auc: 0.4897\n",
            "Epoch 2/5\n",
            "7952/7952 [==============================] - 3s 356us/step - loss: 0.6957 - acc: 0.5444 - auc: 0.4968\n",
            "Epoch 3/5\n",
            "7952/7952 [==============================] - 3s 355us/step - loss: 0.6895 - acc: 0.5443 - auc: 0.5025\n",
            "Epoch 4/5\n",
            "7952/7952 [==============================] - 3s 356us/step - loss: 0.6892 - acc: 0.5443 - auc: 0.5041\n",
            "Epoch 5/5\n",
            "7952/7952 [==============================] - 3s 357us/step - loss: 0.6894 - acc: 0.5443 - auc: 0.5036\n",
            "Epoch 1/5\n",
            "7952/7952 [==============================] - 15s 2ms/step - loss: 0.7158 - acc: 0.5604 - auc: 0.4886\n",
            "Epoch 2/5\n",
            "7952/7952 [==============================] - 3s 347us/step - loss: 0.6858 - acc: 0.5649 - auc: 0.4971\n",
            "Epoch 3/5\n",
            "7952/7952 [==============================] - 3s 355us/step - loss: 0.6853 - acc: 0.5649 - auc: 0.4949\n",
            "Epoch 4/5\n",
            "7952/7952 [==============================] - 3s 348us/step - loss: 0.6838 - acc: 0.5649 - auc: 0.4965\n",
            "Epoch 5/5\n",
            "7952/7952 [==============================] - 3s 335us/step - loss: 0.6842 - acc: 0.5649 - auc: 0.4969\n",
            "Epoch 1/5\n",
            "7952/7952 [==============================] - 15s 2ms/step - loss: 0.6717 - acc: 0.6139 - auc: 0.5669\n",
            "Epoch 2/5\n",
            "7952/7952 [==============================] - 3s 339us/step - loss: 0.5134 - acc: 0.7530 - auc: 0.6918\n",
            "Epoch 3/5\n",
            "7952/7952 [==============================] - 3s 342us/step - loss: 0.4556 - acc: 0.7904 - auc: 0.7534\n",
            "Epoch 4/5\n",
            "7952/7952 [==============================] - 3s 343us/step - loss: 0.4137 - acc: 0.8130 - auc: 0.7862\n",
            "Epoch 5/5\n",
            "7952/7952 [==============================] - 3s 335us/step - loss: 0.3763 - acc: 0.8353 - auc: 0.8105\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:2174: RuntimeWarning: divide by zero encountered in log\n",
            "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:2174: RuntimeWarning: invalid value encountered in multiply\n",
            "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "7952/7952 [==============================] - 16s 2ms/step - loss: 7.0299 - acc: 0.5605 - auc: 0.5039\n",
            "Epoch 2/5\n",
            "7952/7952 [==============================] - 3s 340us/step - loss: 7.0110 - acc: 0.5650 - auc: 0.5010\n",
            "Epoch 3/5\n",
            "7952/7952 [==============================] - 3s 335us/step - loss: 3.6852 - acc: 0.5624 - auc: 0.4991\n",
            "Epoch 4/5\n",
            "7952/7952 [==============================] - 3s 339us/step - loss: 0.6853 - acc: 0.5649 - auc: 0.4975\n",
            "Epoch 5/5\n",
            "7952/7952 [==============================] - 3s 348us/step - loss: 0.7160 - acc: 0.5649 - auc: 0.4984\n",
            "Epoch 1/5\n",
            "7952/7952 [==============================] - 16s 2ms/step - loss: 0.6548 - acc: 0.6567 - auc: 0.5893\n",
            "Epoch 2/5\n",
            "7952/7952 [==============================] - 3s 351us/step - loss: 0.4980 - acc: 0.7665 - auc: 0.7246\n",
            "Epoch 3/5\n",
            "7952/7952 [==============================] - 3s 353us/step - loss: 0.4395 - acc: 0.8018 - auc: 0.7757\n",
            "Epoch 4/5\n",
            "7952/7952 [==============================] - 3s 345us/step - loss: 0.4161 - acc: 0.8105 - auc: 0.8011\n",
            "Epoch 5/5\n",
            "7952/7952 [==============================] - 3s 346us/step - loss: 0.3804 - acc: 0.8366 - auc: 0.8210\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:2174: RuntimeWarning: divide by zero encountered in log\n",
            "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:2174: RuntimeWarning: invalid value encountered in multiply\n",
            "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "7952/7952 [==============================] - 16s 2ms/step - loss: 7.0043 - acc: 0.5644 - auc: 0.4995\n",
            "Epoch 2/5\n",
            "7952/7952 [==============================] - 3s 330us/step - loss: 7.0132 - acc: 0.5649 - auc: 0.5000\n",
            "Epoch 3/5\n",
            "7952/7952 [==============================] - 3s 340us/step - loss: 7.0132 - acc: 0.5649 - auc: 0.5000\n",
            "Epoch 4/5\n",
            "7952/7952 [==============================] - 3s 339us/step - loss: 7.0132 - acc: 0.5649 - auc: 0.5000\n",
            "Epoch 5/5\n",
            "7952/7952 [==============================] - 3s 345us/step - loss: 7.0132 - acc: 0.5649 - auc: 0.5000\n",
            "Epoch 1/5\n",
            "7952/7952 [==============================] - 16s 2ms/step - loss: 7.3210 - acc: 0.5430 - auc: 0.4918\n",
            "Epoch 2/5\n",
            "7952/7952 [==============================] - 3s 328us/step - loss: 7.3456 - acc: 0.5443 - auc: 0.4994\n",
            "Epoch 3/5\n",
            "7952/7952 [==============================] - 3s 334us/step - loss: 7.3456 - acc: 0.5443 - auc: 0.4996\n",
            "Epoch 4/5\n",
            "7952/7952 [==============================] - 3s 343us/step - loss: 7.3459 - acc: 0.5441 - auc: 0.4997\n",
            "Epoch 5/5\n",
            "7952/7952 [==============================] - 3s 370us/step - loss: 7.3456 - acc: 0.5443 - auc: 0.4998\n",
            "Epoch 1/5\n",
            "7952/7952 [==============================] - 16s 2ms/step - loss: 7.1247 - acc: 0.5551 - auc: 0.4928\n",
            "Epoch 2/5\n",
            "7952/7952 [==============================] - 3s 345us/step - loss: 7.0132 - acc: 0.5649 - auc: 0.4991\n",
            "Epoch 3/5\n",
            "7952/7952 [==============================] - 3s 369us/step - loss: 7.0132 - acc: 0.5649 - auc: 0.4995\n",
            "Epoch 4/5\n",
            "7952/7952 [==============================] - 3s 345us/step - loss: 7.0132 - acc: 0.5649 - auc: 0.4996\n",
            "Epoch 5/5\n",
            "7952/7952 [==============================] - 3s 349us/step - loss: 7.0132 - acc: 0.5649 - auc: 0.4997\n",
            "Epoch 1/5\n",
            "7952/7952 [==============================] - 17s 2ms/step - loss: 1.8966 - acc: 0.5379 - auc: 0.4971\n",
            "Epoch 2/5\n",
            "7952/7952 [==============================] - 3s 334us/step - loss: 0.6898 - acc: 0.5443 - auc: 0.5011\n",
            "Epoch 3/5\n",
            "7952/7952 [==============================] - 3s 341us/step - loss: 0.6894 - acc: 0.5443 - auc: 0.5001\n",
            "Epoch 4/5\n",
            "7952/7952 [==============================] - 3s 341us/step - loss: 0.6892 - acc: 0.5443 - auc: 0.5019\n",
            "Epoch 5/5\n",
            "7952/7952 [==============================] - 3s 343us/step - loss: 0.6895 - acc: 0.5443 - auc: 0.5016\n",
            "Epoch 1/5\n",
            "7952/7952 [==============================] - 17s 2ms/step - loss: 0.7548 - acc: 0.5605 - auc: 0.5081\n",
            "Epoch 2/5\n",
            "7952/7952 [==============================] - 3s 355us/step - loss: 0.6842 - acc: 0.5649 - auc: 0.5088\n",
            "Epoch 3/5\n",
            "7952/7952 [==============================] - 3s 344us/step - loss: 0.6844 - acc: 0.5649 - auc: 0.5037\n",
            "Epoch 4/5\n",
            "7952/7952 [==============================] - 3s 344us/step - loss: 0.6847 - acc: 0.5649 - auc: 0.5026\n",
            "Epoch 5/5\n",
            "7952/7952 [==============================] - 3s 336us/step - loss: 0.6848 - acc: 0.5649 - auc: 0.5024\n",
            "Epoch 1/5\n",
            "7952/7952 [==============================] - 17s 2ms/step - loss: 1.5114 - acc: 0.5381 - auc: 0.4982\n",
            "Epoch 2/5\n",
            "7952/7952 [==============================] - 3s 347us/step - loss: 0.6896 - acc: 0.5443 - auc: 0.4968\n",
            "Epoch 3/5\n",
            "7952/7952 [==============================] - 3s 338us/step - loss: 0.6895 - acc: 0.5443 - auc: 0.4975\n",
            "Epoch 4/5\n",
            "7952/7952 [==============================] - 3s 348us/step - loss: 0.6895 - acc: 0.5443 - auc: 0.4976\n",
            "Epoch 5/5\n",
            "7952/7952 [==============================] - 3s 340us/step - loss: 0.6895 - acc: 0.5443 - auc: 0.4974\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "15904/15904 [==============================] - 20s 1ms/step - loss: 0.7842 - acc: 0.5511 - auc: 0.5017\n",
            "Epoch 2/5\n",
            "15904/15904 [==============================] - 5s 346us/step - loss: 0.6874 - acc: 0.5546 - auc: 0.4948\n",
            "Epoch 3/5\n",
            "15904/15904 [==============================] - 5s 345us/step - loss: 0.6877 - acc: 0.5546 - auc: 0.4952\n",
            "Epoch 4/5\n",
            "15904/15904 [==============================] - 6s 355us/step - loss: 0.6875 - acc: 0.5546 - auc: 0.4959\n",
            "Epoch 5/5\n",
            "15904/15904 [==============================] - 5s 335us/step - loss: 0.6875 - acc: 0.5546 - auc: 0.4960\n",
            "The parameters of the best model are: \n",
            "{'batch_size': 32, 'dense_layer_sizes': 128, 'epochs': 5, 'filters': 10, 'hidden_layers': 3, 'kernel_size': (3, 3), 'loss_function': functools.partial(<function weighted_binary_crossentropy at 0x7f9357528e18>, weights_10=array([0.9, 0.1])), 'pool_size': (2, 2)}\n",
            "nan (nan) with: {'batch_size': 32, 'dense_layer_sizes': 128, 'epochs': 5, 'filters': 10, 'hidden_layers': 1, 'kernel_size': (3, 3), 'loss_function': 'binary_crossentropy', 'pool_size': (2, 2)}\n",
            "nan (nan) with: {'batch_size': 32, 'dense_layer_sizes': 128, 'epochs': 5, 'filters': 10, 'hidden_layers': 1, 'kernel_size': (3, 3), 'loss_function': functools.partial(<function weighted_binary_crossentropy at 0x7f9357528e18>, weights_10=array([0.9, 0.1])), 'pool_size': (2, 2)}\n",
            "-8.213073 (7.527436) with: {'batch_size': 32, 'dense_layer_sizes': 128, 'epochs': 5, 'filters': 10, 'hidden_layers': 2, 'kernel_size': (3, 3), 'loss_function': 'binary_crossentropy', 'pool_size': (2, 2)}\n",
            "-0.687818 (0.002776) with: {'batch_size': 32, 'dense_layer_sizes': 128, 'epochs': 5, 'filters': 10, 'hidden_layers': 2, 'kernel_size': (3, 3), 'loss_function': functools.partial(<function weighted_binary_crossentropy at 0x7f9357528e18>, weights_10=array([0.9, 0.1])), 'pool_size': (2, 2)}\n",
            "-0.687787 (0.002082) with: {'batch_size': 32, 'dense_layer_sizes': 128, 'epochs': 5, 'filters': 10, 'hidden_layers': 3, 'kernel_size': (3, 3), 'loss_function': 'binary_crossentropy', 'pool_size': (2, 2)}\n",
            "-0.687575 (0.001866) with: {'batch_size': 32, 'dense_layer_sizes': 128, 'epochs': 5, 'filters': 10, 'hidden_layers': 3, 'kernel_size': (3, 3), 'loss_function': functools.partial(<function weighted_binary_crossentropy at 0x7f9357528e18>, weights_10=array([0.9, 0.1])), 'pool_size': (2, 2)}\n",
            "nan (nan) with: {'batch_size': 32, 'dense_layer_sizes': 256, 'epochs': 5, 'filters': 10, 'hidden_layers': 1, 'kernel_size': (3, 3), 'loss_function': 'binary_crossentropy', 'pool_size': (2, 2)}\n",
            "nan (nan) with: {'batch_size': 32, 'dense_layer_sizes': 256, 'epochs': 5, 'filters': 10, 'hidden_layers': 1, 'kernel_size': (3, 3), 'loss_function': functools.partial(<function weighted_binary_crossentropy at 0x7f9357528e18>, weights_10=array([0.9, 0.1])), 'pool_size': (2, 2)}\n",
            "nan (nan) with: {'batch_size': 32, 'dense_layer_sizes': 256, 'epochs': 5, 'filters': 10, 'hidden_layers': 2, 'kernel_size': (3, 3), 'loss_function': 'binary_crossentropy', 'pool_size': (2, 2)}\n",
            "-15.384349 (0.356159) with: {'batch_size': 32, 'dense_layer_sizes': 256, 'epochs': 5, 'filters': 10, 'hidden_layers': 2, 'kernel_size': (3, 3), 'loss_function': functools.partial(<function weighted_binary_crossentropy at 0x7f9357528e18>, weights_10=array([0.9, 0.1])), 'pool_size': (2, 2)}\n",
            "-8.212764 (7.527745) with: {'batch_size': 32, 'dense_layer_sizes': 256, 'epochs': 5, 'filters': 10, 'hidden_layers': 3, 'kernel_size': (3, 3), 'loss_function': 'binary_crossentropy', 'pool_size': (2, 2)}\n",
            "-0.688269 (0.002291) with: {'batch_size': 32, 'dense_layer_sizes': 256, 'epochs': 5, 'filters': 10, 'hidden_layers': 3, 'kernel_size': (3, 3), 'loss_function': functools.partial(<function weighted_binary_crossentropy at 0x7f9357528e18>, weights_10=array([0.9, 0.1])), 'pool_size': (2, 2)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZoiIznKfCrX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "30b715f7-8500-4386-f15e-235c228ffabb"
      },
      "source": [
        "print('The parameters of the best model are: ')\n",
        "print(validator66.best_params_)\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The parameters of the best model are: \n",
            "{'batch_size': 32, 'dense_layer_sizes': 128, 'epochs': 1, 'filters': 10, 'kernel_size': 3, 'pool_size': 2}\n",
            "-0.696088 (0.005621) with: {'batch_size': 32, 'dense_layer_sizes': 128, 'epochs': 1, 'filters': 10, 'kernel_size': 3, 'pool_size': 2}\n",
            "-4.680589 (5.632574) with: {'batch_size': 32, 'dense_layer_sizes': 256, 'epochs': 1, 'filters': 10, 'kernel_size': 3, 'pool_size': 2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsMOoTCLm7im",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build the model\n",
        "#del model\n",
        "#dense_size_candidates = [[32], [64], [32, 32], [64, 64]]\n",
        "#model = make_model(5, 20, 3, 2)\n",
        "#model.fit(X_train, y_train, epochs=5, batch_size=32)\n",
        "\n",
        "my_classifier = KerasClassifier(search_model)\n",
        "validator = GridSearchCV(my_classifier,\n",
        "                         param_grid={'dense_layer_sizes': [128, 256],\n",
        "                                     # epochs is avail for tuning even when not\n",
        "                                     # an argument to model building function\n",
        "                                     'epochs': [10, 30, 50],\n",
        "                                     'filters': [10, 20],\n",
        "                                     'kernel_size': [(3,3)],\n",
        "                                     'pool_size': [(2,2)],\n",
        "                                     'hidden_layers': [1,2,3],\n",
        "                                     'loss_function': ['binary_crossentropy', custom_loss2],\n",
        "                                     'batch_size': [[32], [64]]}, \n",
        "                         scoring='neg_log_loss')\n",
        "\n",
        "my_classifier2 = KerasClassifier(make_model_modified)\n",
        "validator2 = GridSearchCV(my_classifier2,\n",
        "                         param_grid={'dense_layer_sizes': [128,256],\n",
        "                                     # epochs is avail for tuning even when not\n",
        "                                     # an argument to model building function\n",
        "                                     'epochs': [1,2],\n",
        "                                     'filters': [20],\n",
        "                                     'kernel_size': [(3,3)],\n",
        "                                     'pool_size': [(2,2)],\n",
        "                                     'batch_size': [32]}, \n",
        "                         scoring='neg_log_loss', n_jobs=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unF8fvbDwTF1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_frame = pd.DataFrame(y_train)\n",
        "y=y_train.astype('int')\n",
        "grid_result = validator.fit(X_train, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hW98cIwoRGpM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "4202e3fe-7754-4cb6-93d3-2d006285872d"
      },
      "source": [
        "'''Example of how to use sklearn wrapper\n",
        "Builds simple CNN models on MNIST and uses sklearn's GridSearchCV to find best model\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras import backend as K\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# load training data and do basic data normalization\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print(numpy.shape(x_train))\n",
        "print(numpy.shape(y_train))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9TJIdqjTikR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "44625f03-27b2-411d-b8e5-8e3347e7827d"
      },
      "source": [
        "a = y_train>1\n",
        "y_train_binary = a*1\n",
        "print(y_train_binary)\n",
        "print(numpy.shape(x_train))\n",
        "print(numpy.shape(y_train))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 ... 0 0 0]\n",
            "(60000, 28, 28, 1)\n",
            "(15904,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPxN3JQb51Bw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# convert class vectors to binary class matrices\n",
        "#y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "#y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\n",
        "def make_model(dense_layer_sizes, filters, kernel_size, pool_size):\n",
        "    '''Creates model comprised of 2 convolutional layers followed by dense layers\n",
        "    dense_layer_sizes: List of layer sizes.\n",
        "        This list has one number for each layer\n",
        "    filters: Number of convolutional filters in each convolutional layer\n",
        "    kernel_size: Convolutional kernel size\n",
        "    pool_size: Size of pooling area for max pooling\n",
        "    '''\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters, kernel_size,\n",
        "                     padding='valid',\n",
        "                     input_shape=input_shape, data_format='channels_first'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(filters, kernel_size))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=pool_size))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    for layer_size in dense_layer_sizes:\n",
        "        model.add(Dense(layer_size))\n",
        "        model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1))#(num_classes))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', #'categorical_crossentropy',\n",
        "                  optimizer='adadelta',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "dense_size_candidates = [[32], [64]] #, [32, 32], [64, 64]]\n",
        "my_classifier = KerasClassifier(make_model, batch_size=32)\n",
        "validator = GridSearchCV(my_classifier,\n",
        "                         param_grid={'dense_layer_sizes': dense_size_candidates,\n",
        "                                     # epochs is avail for tuning even when not\n",
        "                                     # an argument to model building function\n",
        "                                     'epochs': [1],\n",
        "                                     'filters': [8],\n",
        "                                     'kernel_size': [3],\n",
        "                                     'pool_size': [2]},\n",
        "                         scoring='neg_log_loss',\n",
        "                         n_jobs=1)\n",
        "y=y_train.astype('int')\n",
        "validator.fit(X_train, y) #_binary)\n",
        "\n",
        "print('The parameters of the best model are: ')\n",
        "print(validator.best_params_)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kswr3l8Z17v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# validator.best_estimator_ returns sklearn-wrapped version of best model.\n",
        "# validator.best_estimator_.model returns the (unwrapped) keras model\n",
        "best_model = validator.best_estimator_.model\n",
        "metric_names = best_model.metrics_names\n",
        "metric_values = best_model.evaluate(x_test, y_test)\n",
        "for metric, value in zip(metric_names, metric_values):\n",
        "    print(metric, ': ', value)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPTbon76RXfF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}