{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01 Train Matrix.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hannape/IBAC-Biodiv/blob/master/01_Train_Matrix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WQNNtYnYG3d",
        "colab_type": "text"
      },
      "source": [
        "Stworzenie macierzy treningowej, zbalansowanej. Dla nagrań z 2016,17,18 powinna mieć pierwszy wymiar 15904\n",
        "\n",
        "Kod wzięty z I2: Copy of 001-SplitRecordingAsFunction_3repr_IBAC.ipynb, wyczyszczony z niepotrzebnych rzeczy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiRCEnbbYCGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## JAKO FUNKCJA\n",
        "\n",
        "!pip install audiosegment\n",
        "!pip install librosa\n",
        "!pip install pydub\n",
        "!pip install webrtcvad\n",
        "!pip install librosa\n",
        "!pip install -q spectrum\n",
        "!pip install pkgconfig libtfr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTXXF4qTYapb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import libtfr\n",
        "import librosa\n",
        "from scipy.io import wavfile\n",
        "from random import choice\n",
        "import librosa\n",
        "from pydub import AudioSegment\n",
        "from pydub.utils import make_chunks\n",
        "import math\n",
        "import audiosegment\n",
        "from pydub import AudioSegment\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "import glob\n",
        "import os\n",
        "import scipy\n",
        "import librosa\n",
        "from librosa import display\n",
        "from librosa.core import power_to_db\n",
        "from librosa.core import amplitude_to_db\n",
        "import IPython.display as ipd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZ2omAqBYchn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/Colab Notebooks')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_yL45UiYg7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Parametry ####\n",
        "             \n",
        "plot_repr = 0          # czy wyrysowywać głosy wszystkie\n",
        "play_sound = 0\n",
        "minimal_duration = 4   # minimalny czas trwania głosu w ms, b zakwalifikowac chunka jako hasbird\n",
        "f_min = 4000           # minimalna częstotliwość analizowana ze spektro\n",
        "f_max = 9500           # maksymalna częstotliwość analizowana ze spektro\n",
        "f_min2 = 4000           # minimalna częstotliwość analizowana ze spektro\n",
        "f_max2 = 9500           # maksymalna częstotliwość analizowana ze spektro\n",
        "n_mels = 60\n",
        "n_mels2 = 80\n",
        "step = 150\n",
        "\n",
        "###################\n",
        "\n",
        "def representations(frame):\n",
        "  \n",
        "      ####### \n",
        "      global result1,result1b,result3,result3b,result5,result5b\n",
        "      \n",
        "      fs = 44100\n",
        "      samples = frame.get_array_of_samples()\n",
        "      samples_float = librosa.util.buf_to_float(samples,n_bytes=2,dtype=np.float32)\n",
        "      audio = np.array(samples_float)\n",
        "      '''\n",
        "      ####### reprezentacja 1  ------- 63 x 148 ------\n",
        "      stft = librosa.stft(audio, n_fft=512, win_length=512, hop_length=150, window= \"hann\") #scipy.signal.get_window(('gaussian',50) ,512) )#scipy.signal.gaussian(512, 2)   ) \n",
        "      stft1 = amplitude_to_db(np.abs(stft)**2)\n",
        "      freqs = librosa.core.fft_frequencies(n_fft=512, sr=44100)\n",
        "      fmin =  min(freqs[(freqs >= f_min)])\n",
        "      i,  = np.where( freqs >= min(freqs[(freqs >= f_min)]))\n",
        "      j,  = np.where( freqs <= max(freqs[(freqs <= f_max)]))\n",
        "      stft1 = stft1[min(i):max(j),]\n",
        "      result1 = stft1\n",
        "      \n",
        "      ####### reprezentacja 1b - spektrogram większy hop length ------- 63 x 63 ------\n",
        "      stft = librosa.stft(audio, n_fft=512, win_length=512, hop_length=355, window= \"hann\") #scipy.signal.get_window(('gaussian',50) ,512) )#scipy.signal.gaussian(512, 2)   ) \n",
        "      stft1 = amplitude_to_db(np.abs(stft)**2)\n",
        "      freqs = librosa.core.fft_frequencies(n_fft=512, sr=44100)\n",
        "      fmin =  min(freqs[(freqs >= f_min)])\n",
        "      i,  = np.where( freqs >= min(freqs[(freqs >= f_min)]))\n",
        "      j,  = np.where( freqs <= max(freqs[(freqs <= f_max)]))\n",
        "      stft1 = stft1[min(i):max(j),]\n",
        "      result1b = stft1\n",
        "      \n",
        "      ####### reprezentacja 3 - mel spektrogram ------- 60 x 111 ------\n",
        "    \n",
        "      # Compute Short-Term Fourier Transform (STFT).\n",
        "      stft = librosa.stft(np.array(samples_float), n_fft=512, win_length=512, hop_length= 200,    window=\"hann\")\n",
        "\n",
        "      # Compute squared magnitude coefficients.\n",
        "      abs2_stft = (stft.real*stft.real) + (stft.imag*stft.imag)\n",
        "      result3 = librosa.feature.melspectrogram(y=None, S=abs2_stft, sr=44100, n_mels= 60, fmin = 4000, fmax=9500, hop_length=512, n_fft=512)\n",
        "      result3 = 0.5 * librosa.amplitude_to_db(result3, ref=1.0)\n",
        "      \n",
        "      ####### reprezentacja 3b - mel spektrogram większy hop length ------- 60 x 63 ------\n",
        "    \n",
        "      # Compute Short-Term Fourier Transform (STFT).\n",
        "      stft = librosa.stft(np.array(samples_float), n_fft=512, win_length=512, hop_length= 355,    window=\"hann\")\n",
        "\n",
        "      # Compute squared magnitude coefficients.\n",
        "      abs2_stft = (stft.real*stft.real) + (stft.imag*stft.imag)\n",
        "      result3 = librosa.feature.melspectrogram(y=None, S=abs2_stft, sr=44100, n_mels= 60, fmin = 4000, fmax=9500, hop_length=512, n_fft=512)\n",
        "      result3b = 0.5 * librosa.amplitude_to_db(result3, ref=1.0)\n",
        "      \n",
        "      '''\n",
        "      ####### reprezentacja 3 V3 - mel spektrogram  ------- 60 x 148 ------\n",
        "    \n",
        "      # Compute Short-Term Fourier Transform (STFT).\n",
        "      stft = librosa.stft(np.array(samples_float), n_fft=512, win_length=512, hop_length= 150,    window=\"hann\")\n",
        "\n",
        "      # Compute squared magnitude coefficients.\n",
        "      abs2_stft = (stft.real*stft.real) + (stft.imag*stft.imag)\n",
        "      result3 = librosa.feature.melspectrogram(y=None, S=abs2_stft, sr=44100, n_mels= 60, fmin = 4000, fmax=9500, hop_length=512, n_fft=512)\n",
        "      result3 = 0.5 * librosa.amplitude_to_db(result3, ref=1.0)\n",
        "      '''\n",
        "      ####### reprezentacja 5 - multitaper ------- 64 x 61 ------\n",
        "      \n",
        "      result5 = libtfr.tfr_spec(audio, N = 512, step = 355, Np = 490, K = 2, tm = 1, flock =0.1, tlock = 10)     \n",
        "      freqs, ind = libtfr.fgrid(fs, 512, fpass=(4000,9500)) \n",
        "      result5 = result5[ind,]; # tylko interesujące nas pasmo\n",
        "      \n",
        "      if(np.isinf(result5).any()):\n",
        "        print(\"inf result B: \" + str(i))\n",
        "        \n",
        "            \n",
        "      ####### reprezentacja 5b - multitaper o większej rozdzielczości ------- 64 x 149 ------\n",
        "      \n",
        "      result5b = libtfr.tfr_spec(audio, N = 512, step = 145, Np = 490, K = 2, tm = 1, flock =0.1, tlock = 10)     \n",
        "      freqs, ind = libtfr.fgrid(fs, 512, fpass=(4000,9500)) \n",
        "      result5b = result5b[ind,]; # tylko interesujące nas pasmo\n",
        "      \n",
        "      if(np.isinf(result5b).any()):\n",
        "        print(\"inf result B: \" + str(i))  \n",
        "      '''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4mTeN4RZvRy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def SplitRecordingFunction(nazwa):\n",
        "\n",
        "  name_wav = nazwa + \".wav\"\n",
        "  name_txt = nazwa + \".txt\" #dot.txt\"  txt przecinkowe\n",
        "\n",
        "  with open((source_labels + name_txt), 'r+') as f:  # zmiana na kropki\n",
        "      text = f.read()\n",
        "      f.seek(0)\n",
        "      f.truncate()\n",
        "      f.write(text.replace(',', '.'))\n",
        "  fs, data = wavfile.read(source_audio + name_wav)   # wypluwa błąd, nie rozumie opisow dodanych przez Audacity pewnie\n",
        "  print(name_wav)\n",
        "  myaudio = audiosegment.from_file(source_audio + name_wav)\n",
        "  channel_count = myaudio.channels    #Get channels\n",
        "  sample_width = myaudio.sample_width #Get sample width\n",
        "  duration_in_ms = len(myaudio) #Length of audio in ms\n",
        "  sample_rate = myaudio.frame_rate\n",
        "  nr_of_chunks =  1 + (duration_in_ms - chunk_length_ms) / (chunk_length_ms - chunk_overlap)\n",
        "\n",
        "  ########## Odczyt labeli z csv, wyczyszczenie zaznaczonych trzasków (t, ?)\n",
        "  \n",
        "  calls_to_cut = ['t', 't?', 'g', 'czapla', 'gh', 'g cz', 'puszczyk','gaski','g?','mewa?','zwierzak?','high freq','g niskie','??? mysz']\n",
        "  \n",
        "  ###### tu nie wycięliśmy 't ' i 't  ', a w teście tak, mam nadzieję że to jest marginalny problem, niech już tak zostanie.\n",
        "  \n",
        "  if (os.stat(source_labels + name_txt).st_size != 0):\n",
        "    y_read = pd.read_csv(source_labels + name_txt,  header=None, sep = \"\\t\")\n",
        "    y_read.columns = [\"start\", \"end\", \"bird\"]\n",
        "    y_read_cleaned = y_read[~y_read['bird'].isin(calls_to_cut)]\n",
        "    print(y_read_cleaned['bird'])\n",
        "    y_read = y_read_cleaned\n",
        "    not_empty = 1\n",
        "  else:\n",
        "    print(source_labels + name_txt)\n",
        "    print(\"bez etykiet!!! : \" + str(name_wav))\n",
        "    not_empty = 0\n",
        "    sum_birds2 = 0\n",
        "    birds_chunks = []\n",
        "    df=pd.DataFrame()\n",
        "  \n",
        "  ########## Wyszukanie pozytywnych fragmentów - fragmentów zawierający głos, ilość takich ramek\n",
        "\n",
        "  image_positive = []\n",
        "  description_positive = []\n",
        "  species=[]\n",
        "  sum_birds=0\n",
        "  has_bird = 1\n",
        "  plot_repr = 0          # czy wyrysowywać głosy wszystkie\n",
        "  play_sound = 1\n",
        "  \n",
        "  if (not_empty):\n",
        "    for i in range(0,math.floor(nr_of_chunks)): #(2300,2600): #math.floor(nr_of_chunks)): \n",
        "      frame_start = i*(chunk_length_ms - chunk_overlap)\n",
        "      frame_end = i*(chunk_length_ms - chunk_overlap)+ chunk_length_ms\n",
        "      frame = myaudio[frame_start : frame_end]\n",
        "      x = range(frame_start,frame_end)\n",
        "\n",
        "      for j in y_read.index.tolist():\n",
        "        bird_start = int(round(y_read.start[j]*1000))\n",
        "        bird_end = int(round(y_read.end[j]*1000))\n",
        "        y = range(bird_start,bird_end)\n",
        "\n",
        "        intersect_start = max(x[0], y[0])\n",
        "        intersect_end = min(x[-1], y[-1])+1\n",
        "        range1 = (range(intersect_start, intersect_end))\n",
        "\n",
        "        if len(range1)> minimal_duration: \n",
        "          sum_birds = sum_birds+1\n",
        "\n",
        "          #representations(frame)  \n",
        "          #image_positive.append(result1)  # nie musi być tutaj, dopiero po usunięciu duplikatów może?\n",
        "          species.append(y_read.bird[j])\n",
        "          description_positive.append([i, frame_start, frame_end, intersect_start, intersect_end, bird_start, bird_end, has_bird, 0, 0])\n",
        "\n",
        "\n",
        "  #representations(frame)  # jeden przykładowy, ostatni,  by poznać wymiary reprezentacji       \n",
        "  \n",
        "  ########## Usunięcie duplikatów, zakładamy że nie więcej niż 2 głosy w ramce\n",
        "\n",
        "  labels = ['Chunk_nr', 'Chunk_start', 'Chunk_end', 'Call_start_chunk','Call_end_chunk','Call_start','Call_end','Has_bird','2nd_call_start','2nd_call_end']\n",
        "  description_pd = pd.DataFrame.from_records(description_positive, columns=labels)   # na lepszy format\n",
        "\n",
        "  duplic = description_pd[description_pd.duplicated(subset='Chunk_nr',keep=False)]   # wypisanie duplikujących sie ramek (ale z innym glosem zawartym)\n",
        "  duplic_index = duplic.drop_duplicates(subset='Chunk_nr',keep='first')['Chunk_nr'].index.tolist() \n",
        "\n",
        "  #print(duplic)\n",
        "  #print(duplic_index)\n",
        "\n",
        "  df = description_pd.drop_duplicates(subset='Chunk_nr',keep='first')  # usuwamy drugie duplikaty z listy\n",
        "  for i in duplic_index:\n",
        "    df['2nd_call_start'][i]= description_pd['Call_start'][i+1]   # dopisujemy drugi głos do ramki\n",
        "    df['2nd_call_end'][i]= description_pd['Call_end'][i+1]\n",
        "     \n",
        "  ########## Macierz wyjściowa obrazów i opisów, same ptaki\n",
        " \n",
        "  #description_positive_no_duplic = df   # mamy opisy, czas na reprezentacje:\n",
        "  rep1 = []\n",
        "  rep3 = []\n",
        "  rep5 = []\n",
        "  spec = []\n",
        "\n",
        "  for i in df.index: #range(0,np.shape(description_positive_no_duplic)[0]):\n",
        "      frame = myaudio[df.Chunk_start[i]:df.Chunk_end[i]]\n",
        "      representations(frame)\n",
        "      #rep1.append(result1)\n",
        "      rep3.append(result3)\n",
        "      #rep5.append(result5)\n",
        "      spec.append(species[i])\n",
        "  #print(np.shape(spec))  \n",
        "  \n",
        "  ########## Indexy pustych ramek\n",
        "\n",
        "  '''\n",
        "  min_chunks = 50  # jeśli głosów w nagraniu jest mniej niż 50, to i tak dobierzemy 50 pustych fragmentów - by choć wziąć próbkę tych warunków\n",
        "  import random\n",
        "  random.seed(667)\n",
        "  sum_birds2 = np.shape(df)[0]  # bez powtórzeń już\n",
        "\n",
        "  if sum_birds2<min_chunks:\n",
        "    sum_birds2 = min_chunks\n",
        "\n",
        "  #print(sum_birds)\n",
        "  birds_chunks = df['Chunk_nr'].tolist()\n",
        "  range_nonbirds = [i for i in range(0, math.floor(nr_of_chunks)) if i not in birds_chunks]\n",
        "  nobirds_chunks = random.sample(range_nonbirds, sum_birds2)  # dobieramy tyle ramek bez ptaków, co mamy z ptakami. Losowo\n",
        "  #print(nobirds_chunks)\n",
        "  '''\n",
        "  \n",
        "  ### Ładujemy chunki z podziałów, by zawsze te same randomowe negatywy były\n",
        "  dane1 = np.load(source_npz + 'Kopia '+nazwa + '_7rep.npz' )\n",
        "  nobirds_chunks = dane1[\"nobirds_chunks\"]\n",
        "  #print(nobirds_chunks)\n",
        "  \n",
        "  ########## Dodanie macierzy z ramkami bez ptaków\n",
        "  description_negative = []\n",
        "\n",
        "  for i in nobirds_chunks: \n",
        "    frame_start = i*(chunk_length_ms - chunk_overlap)\n",
        "    frame_end = i*(chunk_length_ms - chunk_overlap)+ chunk_length_ms\n",
        "    frame = myaudio[frame_start : frame_end]\n",
        "    representations(frame)\n",
        "    #rep1.append(result1)\n",
        "    rep3.append(result3)\n",
        "    #rep5.append(result5)\n",
        "    description_negative.append([i, frame_start, frame_end, 0, 0, 0, 0, 0, 0, 0])\n",
        "\n",
        "  #print(np.shape(rep1))  \n",
        "  print(np.shape(rep3)) \n",
        "  \n",
        "  ########## Złożenie dwóch macierzy i zapis\n",
        "  description_negative_pd = pd.DataFrame.from_records(description_negative, columns=labels)\n",
        "\n",
        "  #final_dataset = np.concatenate([image_positive_no_duplic, np.array(image_negative)])\n",
        "  final_description = pd.concat([df,description_negative_pd])\n",
        "\n",
        "  #np.save((source_out + nazwa + 'balanced_dataset' ),final_dataset)\n",
        "  #np.savez((source_out + nazwa + name_out ), rep1 = rep1, rep3 = rep3, rep5 = rep5,  final_description=final_description, labels=labels, nobirds_chunks=nobirds_chunks,spec = spec) \n",
        "  np.savez((source_out + nazwa + name_out ), rep3 = rep3, final_description=final_description, labels=labels, nobirds_chunks=nobirds_chunks,spec = spec) \n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSwc1Jmrabn-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "################################################################ MAIN\n",
        "\n",
        "source_labels = \"drive/My Drive/labele/2018/\"# 2016_50/\"\n",
        "source_npz = \"drive/My Drive/repr7_2018/\"\n",
        "source_out = \"drive/My Drive/\"\n",
        "source_audio = \"drive/My Drive/nagrania/2018/\"\n",
        "\n",
        "nazwa_list=[]\n",
        "name_out = '_1repV3'\n",
        "\n",
        "a = sorted(os.listdir(source_labels))      ## nie było wcześniej sorted, więc w różnej kolejności były wyliczane\n",
        "for i in range(0,np.shape(a)[0]):\n",
        "  nazwa_list.append(os.path.splitext(a[i])[0])\n",
        "  \n",
        "print(nazwa_list)\n",
        "\n",
        "#### Parametry ####\n",
        "chunk_length_ms = 500\n",
        "chunk_overlap = 150\n",
        "###################  \n",
        "\n",
        "\n",
        "print(np.shape(nazwa_list)[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELJbUP0pbXWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(np.shape(nazwa_list)[0])\n",
        "for i in range(0,np.shape(nazwa_list)[0]):\n",
        "  \n",
        "  print(\"nagranie nr \"+ str(i) + \": \" + str(nazwa_list[i]))\n",
        "  SplitRecordingFunction(nazwa_list[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsORUyGtbNpU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "source_repr = 'drive/My Drive/'\n",
        "folder_main = [ 'repr1V3_2016/','repr1V3_2017/','repr1V3_2018/' ]   ## foldery gdzie są pliki npz z poprzedniego etapu. tyle ile nagrań, każdy zawiera X reprezentacji\n",
        "\n",
        "X_train_all = []\n",
        "y_train_all = []\n",
        "y_train_species_all = []\n",
        "repr_to_check = ['rep3']\n",
        "\n",
        "#for k in range(0, np.size(repr_to_check)):\n",
        "for k in range(0, np.size(folder_main)):\n",
        "  \n",
        "  \n",
        "  repr_nr = repr_to_check[0]\n",
        "  print('-----------' + repr_nr + '-----------')\n",
        "  print('-----------' + folder_main[k] + '-----------')\n",
        "  \n",
        "  # pierwsze dane, by mieć kształt macierzy i kolejno wcztywać następne\n",
        "  records = sorted(os.listdir(source_repr + folder_main[k]))\n",
        "  print(np.shape(records))\n",
        "  \n",
        "  dane1 = np.load(source_repr + folder_main[k] + records[0], allow_pickle=True )\n",
        "  X_train= dane1[repr_nr]\n",
        "  y_train = dane1['final_description'][:,7]\n",
        "  y_train_species = dane1['spec'] \n",
        "  print(records[0])\n",
        "  print(np.shape(X_train))\n",
        "  print(np.shape(y_train))\n",
        "  print(np.shape(y_train_species))\n",
        "  print('Dostepne dane: ' + str(dane1.files))\n",
        "  \n",
        "  for i in range (1,np.size(records)):\n",
        "    print(records[i])\n",
        "    dane1 = np.load(source_repr + folder_main[k] + records[i], allow_pickle=True )\n",
        "    X_train = np.concatenate((X_train,dane1[repr_nr]))\n",
        "    y_train = np.concatenate((y_train,dane1['final_description'][:,7]))\n",
        "    #print(np.shape(y_test_species))\n",
        "    \n",
        "    print(np.shape(X_train))\n",
        "    print(np.shape(y_train))\n",
        "    a = dane1['spec']\n",
        "    #print(len(a.shape))\n",
        "    if (len(a.shape)==2):  # jeśli dwa wymiary\n",
        "       a = np.squeeze(dane1['spec'])  # to squeezujemy\n",
        "  \n",
        "    y_train_species = np.concatenate((y_train_species,a )) \n",
        "    print(np.shape(y_train_species))\n",
        "  \n",
        "  \n",
        "  print(np.shape(X_train))\n",
        "  print(np.shape(y_train))\n",
        "  print(np.shape(y_train_species))\n",
        "  if k==0:\n",
        "      X_train_all = X_train\n",
        "      y_train_all = y_train\n",
        "      y_train_species_all = y_train_species\n",
        "  else: \n",
        "      X_train_all = np.concatenate((X_train_all,X_train))\n",
        "      y_train_all = np.concatenate((y_train_all,y_train))\n",
        "      y_train_species_all = np.concatenate((y_train_all,y_train_species))\n",
        "\n",
        "np.save(('drive/My Drive/X_train_' + repr_nr+ 'V3'), X_train_all)\n",
        "  \n",
        "np.save(('drive/My Drive/y_train_' + repr_nr + 'V3'), y_train_all)\n",
        "np.save(('drive/My Drive/y_train_species_'+ repr_nr+ 'V3'), y_train_species_all)\n",
        "\n",
        "print(np.shape(X_train_all))\n",
        "print(np.shape(y_train_all))\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}